from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
import asyncio
import json
import cv2
import numpy as np
import sys
import os
import base64
import psutil
import gc
import torch
import redis
from celery_app import analyze_image_task

# ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™”: ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
os.environ.setdefault("OMP_NUM_THREADS", "1")
os.environ.setdefault("MKL_NUM_THREADS", "1")
os.environ.setdefault("NUMEXPR_NUM_THREADS", "1")
try:
    torch.set_num_threads(1)
except:
    pass

# holdcheck ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
holdcheck_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'holdcheck')
sys.path.insert(0, holdcheck_path)

# backend ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
backend_path = os.path.dirname(__file__)
sys.path.insert(0, backend_path)

# Redis ì—°ê²° ì„¤ì •
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
redis_client = redis.from_url(REDIS_URL)

from preprocess import preprocess
from clustering import clip_ai_color_clustering, analyze_problem

def get_memory_usage():
    """ğŸ“Š í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (MB ë‹¨ìœ„)"""
    process = psutil.Process()
    memory_info = process.memory_info()
    return {
        'rss': memory_info.rss / 1024 / 1024,  # ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
        'vms': memory_info.vms / 1024 / 1024,  # ê°€ìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
        'percent': process.memory_percent(),    # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ëŒ€ë¹„ ë¹„ìœ¨
        'available': psutil.virtual_memory().available / 1024 / 1024  # ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (MB)
    }

def log_memory_usage(stage_name):
    """ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê·¸ ì¶œë ¥"""
    memory = get_memory_usage()
    print(f"ğŸ“Š [{stage_name}] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
    print(f"   ğŸ”¸ ì‹¤ì œ ë©”ëª¨ë¦¬: {memory['rss']:.1f}MB")
    print(f"   ğŸ”¸ ê°€ìƒ ë©”ëª¨ë¦¬: {memory['vms']:.1f}MB") 
    print(f"   ğŸ”¸ ì‚¬ìš©ë¥ : {memory['percent']:.1f}%")
    print(f"   ğŸ”¸ ì‚¬ìš© ê°€ëŠ¥: {memory['available']:.1f}MB")
    return memory

# ë°ì´í„°ë² ì´ìŠ¤ ë° ë¶„ì„ ëª¨ë“ˆ (ì„ íƒì  ë¡œë“œ)
try:
    from database import save_problem, save_user_feedback, get_model_stats, get_training_data, convert_gpt4_to_training_data
    DB_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Database ëª¨ë“ˆ ì—†ìŒ: {e}")
    DB_AVAILABLE = False

try:
    from gpt4_analyzer import analyze_with_gpt4_vision, get_gpt4_status
    GPT4_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ GPT-4 ëª¨ë“ˆ ì—†ìŒ: {e}")
    GPT4_AVAILABLE = False

try:
    from hybrid_analyzer import hybrid_analyze, get_analysis_method_stats
    HYBRID_AVAILABLE = True
    print("âœ… Hybrid Analyzer ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ Hybrid ëª¨ë“ˆ ì—†ìŒ: {e}")
    HYBRID_AVAILABLE = False

try:
    from ml_trainer import train_difficulty_model, train_type_model
    ML_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ML ëª¨ë“ˆ ì—†ìŒ: {e}")
    ML_AVAILABLE = False

# Pydantic ëª¨ë¸
class FeedbackRequest(BaseModel):
    problem_id: int
    user_difficulty: str
    user_type: str
    user_feedback: str = None

app = FastAPI(title="ClimbMate API", version="1.0.0")

# CORS ì„¤ì • (React ê°œë°œ ì„œë²„ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë„ë©”ì¸ìœ¼ë¡œ ë³€ê²½
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸš€ CRITICAL: FastAPI startup eventë¡œ ëª¨ë¸ ì‚¬ì „ ë¡œë”© (í™•ì‹¤í•˜ê²Œ!)
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ AI ëª¨ë¸ì„ ì‚¬ì „ ë¡œë”©í•˜ì—¬ ì²« ìš”ì²­ ì‹œ ë¨¹í†µ ë°©ì§€"""
    print("")
    print("=" * 80)
    print("ğŸš€ AI ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì‹œì‘... (ì´ ê³¼ì •ì€ ì„œë²„ ì‹œì‘ ì‹œ 1íšŒë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤)")
    print("=" * 80)
    
    try:
        from preprocess import get_yolo_model, get_clip_model
        
        # YOLO ëª¨ë¸ ì‚¬ì „ ë¡œë”©
        print("")
        print("ğŸ“¦ 1/2: YOLO ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì¤‘...")
        log_memory_usage("YOLO ë¡œë”© ì „")
        yolo_model = get_yolo_model()
        log_memory_usage("YOLO ë¡œë”© í›„")
        print("âœ… YOLO ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        
        # CLIP ëª¨ë¸ ì‚¬ì „ ë¡œë”© (338MB â†’ 151MB)
        print("")
        print("ğŸ“¦ 2/2: CLIP ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì¤‘...")
        log_memory_usage("CLIP ë¡œë”© ì „")
        clip_model, clip_preprocess, clip_device = get_clip_model()
        log_memory_usage("CLIP ë¡œë”© í›„")
        print("âœ… CLIP ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        
        print("")
        print("=" * 80)
        print("âœ… ëª¨ë“  AI ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì™„ë£Œ! ì´ì œ ì²« ìš”ì²­ë¶€í„° ë¹ ë¥´ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤.")
        print("=" * 80)
        log_memory_usage("ëª¨ë¸ ë¡œë”© ì™„ë£Œ í›„")
        print("")
        
    except Exception as e:
        print("")
        print("=" * 80)
        print(f"âš ï¸  ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì‹¤íŒ¨: {e}")
        print(f"âš ï¸  ì²« ìš”ì²­ ì‹œ ëª¨ë¸ì´ ë¡œë”©ë©ë‹ˆë‹¤ (ëŠë¦´ ìˆ˜ ìˆìŒ)")
        print("=" * 80)
        print("")
        import traceback
        traceback.print_exc()

@app.get("/")
async def root():
    """í—¬ìŠ¤ì²´í¬"""
    return {"status": "ok", "message": "ClimbMate API is running"}

@app.post("/api/analyze")
async def analyze_image(
    file: UploadFile = File(...),
    wall_angle: str = None
):
    """
    ğŸš€ ë¹„ë™ê¸° í´ë¼ì´ë° ë²½ ì´ë¯¸ì§€ ë¶„ì„ (ì¦‰ì‹œ ì‘ë‹µ + ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)
    
    Parameters:
    - file: ì´ë¯¸ì§€ íŒŒì¼
    - wall_angle: ë²½ ê°ë„ (overhang, slab, face, null)
    
    Returns:
    - task_id: ì‘ì—… ID (ìƒíƒœ í™•ì¸ìš©)
    - status: ì‘ì—… ìƒíƒœ
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        contents = await file.read()
        
        # Base64 ì¸ì½”ë”©
        image_data_base64 = base64.b64encode(contents).decode('utf-8')
        
        # ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •
        params = {
            'conf': 0.4,
            'brightness_normalization': False,
            'brightness_filter': False,
            'min_brightness': 0,
            'max_brightness': 100,
            'saturation_filter': False,
            'min_saturation': 0,
            'mask_refinement': 5,
            'use_clip_ai': True
        }
        
        # Celery ì‘ì—… ì‹œì‘
        task = analyze_image_task.delay(image_data_base64, params)
        
        print(f"ğŸš€ ë¶„ì„ ì‘ì—… ì‹œì‘: {task.id}")
        
        return {
            "task_id": task.id,
            "status": "started",
            "message": "AI ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. /api/analysis-status/{task_id}ë¡œ ì§„í–‰ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”."
        }
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Analysis request failed: {str(e)}")

@app.post("/api/analyze-stream")
async def analyze_image_stream(
    file: UploadFile = File(...),
    wall_angle: str = Form(None),
    conf: float = Form(0.4),
    brightness_normalization: bool = Form(False),
    brightness_filter: bool = Form(False),
    min_brightness: int = Form(0),
    max_brightness: int = Form(100),
    saturation_filter: bool = Form(False),
    min_saturation: int = Form(0),
    mask_refinement: int = Form(5),
    use_clip_ai: bool = Form(True)
):
    """
    ğŸš€ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ (ì¦‰ì‹œ ì‘ë‹µ + ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)
    
    ê¸°ì¡´ ë™ê¸°ì‹ ìŠ¤íŠ¸ë¦¬ë°ì„ ë¹„ë™ê¸°ì‹ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ë‹¤ë¥¸ ìš”ì²­ì„ ë¸”ë¡í‚¹í•˜ì§€ ì•ŠìŒ
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        contents = await file.read()
        
        # Base64 ì¸ì½”ë”©
        image_data_base64 = base64.b64encode(contents).decode('utf-8')
        
        # ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •
        params = {
            'conf': conf,
            'brightness_normalization': brightness_normalization,
            'brightness_filter': brightness_filter,
            'min_brightness': min_brightness,
            'max_brightness': max_brightness,
            'saturation_filter': saturation_filter,
            'min_saturation': min_saturation,
            'mask_refinement': mask_refinement,
            'use_clip_ai': use_clip_ai
        }
        
        # Celery ì‘ì—… ì‹œì‘
        task = analyze_image_task.delay(image_data_base64, params)
        
        print(f"ğŸš€ ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì‘ì—… ì‹œì‘: {task.id}")
        
        return {
            "task_id": task.id,
            "status": "started",
            "message": "AI ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. /api/analysis-status/{task_id}ë¡œ ì§„í–‰ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”."
        }
        
    except Exception as e:
        print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Streaming analysis request failed: {str(e)}")

@app.get("/api/analysis-status/{task_id}")
async def get_analysis_status(task_id: str):
    """
    ğŸš€ ë¶„ì„ ì‘ì—… ìƒíƒœ í™•ì¸ (Celery í‘œì¤€ ë°©ì‹)
    
    Parameters:
    - task_id: ì‘ì—… ID
    
    Returns:
    - status: ì‘ì—… ìƒíƒœ (started, processing, completed, failed)
    - progress: ì§„í–‰ë¥  (0-100)
    - message: ìƒíƒœ ë©”ì‹œì§€
    - result: ë¶„ì„ ê²°ê³¼ (ì™„ë£Œ ì‹œ)
    """
    try:
        # Celery í‘œì¤€ ë°©ì‹ìœ¼ë¡œ ì‘ì—… ìƒíƒœ ì¡°íšŒ
        task = analyze_image_task.AsyncResult(task_id)
        
        if task.state == 'PENDING':
            response_data = {
                "task_id": task_id, 
                "status": "pending", 
                "message": "ë¶„ì„ ëŒ€ê¸° ì¤‘...", 
                "progress": 0
            }
        elif task.state == 'STARTED':
            meta = task.info or {}
            response_data = {
                "task_id": task_id,
                "status": "started",
                "message": meta.get('message', 'ë¶„ì„ ì§„í–‰ ì¤‘...'),
                "progress": meta.get('progress', 0)
            }
        elif task.state == 'PROGRESS':
            meta = task.info or {}
            response_data = {
                "task_id": task_id,
                "status": "progress",
                "message": meta.get('message', 'ë¶„ì„ ì§„í–‰ ì¤‘...'),
                "progress": meta.get('progress', 0)
            }
        elif task.state == 'SUCCESS':
            result = task.result
            response_data = {
                "task_id": task_id,
                "status": "completed",
                "message": "ë¶„ì„ ì™„ë£Œ!",
                "progress": 100,
                "result": result
            }
        elif task.state == 'FAILURE':
            response_data = {
                "task_id": task.id,
                "status": "failed",
                "message": f"ë¶„ì„ ì‹¤íŒ¨: {str(task.info)}",
                "progress": 100
            }
        else:
            response_data = {
                "task_id": task.id, 
                "status": task.state, 
                "message": "ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ", 
                "progress": 0
            }
        
        return response_data
        
    except Exception as e:
        print(f"âŒ ì‘ì—… ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get task status: {str(e)}")

@app.get("/api/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # Redis ì—°ê²° í™•ì¸
        redis_client.ping()
        redis_status = "connected"
    except:
        redis_status = "disconnected"
    
    return {
        "status": "healthy",
        "redis": redis_status,
        "memory": get_memory_usage(),
        "timestamp": psutil.time.time()
    }

# ê¸°ì¡´ APIë“¤ (ë°ì´í„°ë² ì´ìŠ¤, í†µê³„ ë“±)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
@app.get("/api/stats")
async def get_stats():
    """í†µê³„ ì •ë³´ ë°˜í™˜"""
    if not DB_AVAILABLE:
        return {"error": "Database not available"}
    
    try:
        stats = get_model_stats()
        return stats
    except Exception as e:
        return {"error": str(e)}

@app.post("/api/feedback")
async def submit_feedback(feedback: FeedbackRequest):
    """ì‚¬ìš©ì í”¼ë“œë°± ì œì¶œ"""
    if not DB_AVAILABLE:
        raise HTTPException(status_code=500, detail="Database not available")
    
    try:
        result = save_user_feedback(
            feedback.problem_id,
            feedback.user_difficulty,
            feedback.user_type,
            feedback.user_feedback
        )
        return {"status": "success", "result": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/gpt4-status")
async def get_gpt4_status_endpoint():
    """GPT-4 ìƒíƒœ í™•ì¸"""
    if not GPT4_AVAILABLE:
        return {"available": False, "message": "GPT-4 module not available"}
    
    try:
        status = get_gpt4_status()
        return status
    except Exception as e:
        return {"available": False, "error": str(e)}

@app.post("/api/gpt4-analyze")
async def gpt4_analyze(file: UploadFile = File(...)):
    """GPT-4 Visionìœ¼ë¡œ ë¶„ì„"""
    if not GPT4_AVAILABLE:
        raise HTTPException(status_code=500, detail="GPT-4 module not available")
    
    try:
        contents = await file.read()
        result = analyze_with_gpt4_vision(contents)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/hybrid-stats")
async def get_hybrid_stats():
    """í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ í†µê³„"""
    if not HYBRID_AVAILABLE:
        return {"error": "Hybrid analyzer not available"}
    
    try:
        stats = get_analysis_method_stats()
        return stats
    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)