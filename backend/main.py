from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
import asyncio
import json
import cv2
import numpy as np
import sys
import os
import base64
import psutil
import gc
import torch
import redis
from celery_app import analyze_image_task

# ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™”: ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
os.environ.setdefault("OMP_NUM_THREADS", "1")
os.environ.setdefault("MKL_NUM_THREADS", "1")
os.environ.setdefault("NUMEXPR_NUM_THREADS", "1")
try:
    torch.set_num_threads(1)
except:
    pass

# holdcheck ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
holdcheck_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'holdcheck')
sys.path.insert(0, holdcheck_path)

# backend ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
backend_path = os.path.dirname(__file__)
sys.path.insert(0, backend_path)

# Redis ì—°ê²° ì„¤ì •
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
redis_client = redis.from_url(REDIS_URL)

from preprocess import preprocess
from clustering import clip_ai_color_clustering, analyze_problem

def get_memory_usage():
    """ğŸ“Š í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (MB ë‹¨ìœ„)"""
    process = psutil.Process()
    memory_info = process.memory_info()
    return {
        'rss': memory_info.rss / 1024 / 1024,  # ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
        'vms': memory_info.vms / 1024 / 1024,  # ê°€ìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
        'percent': process.memory_percent(),    # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ëŒ€ë¹„ ë¹„ìœ¨
        'available': psutil.virtual_memory().available / 1024 / 1024  # ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (MB)
    }

def log_memory_usage(stage_name):
    """ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê·¸ ì¶œë ¥"""
    memory = get_memory_usage()
    print(f"ğŸ“Š [{stage_name}] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
    print(f"   ğŸ”¸ ì‹¤ì œ ë©”ëª¨ë¦¬: {memory['rss']:.1f}MB")
    print(f"   ğŸ”¸ ê°€ìƒ ë©”ëª¨ë¦¬: {memory['vms']:.1f}MB") 
    print(f"   ğŸ”¸ ì‚¬ìš©ë¥ : {memory['percent']:.1f}%")
    print(f"   ğŸ”¸ ì‚¬ìš© ê°€ëŠ¥: {memory['available']:.1f}MB")
    return memory

# ë°ì´í„°ë² ì´ìŠ¤ ë° ë¶„ì„ ëª¨ë“ˆ (ì„ íƒì  ë¡œë“œ)
try:
    from database import save_problem, save_user_feedback, get_model_stats, get_training_data, convert_gpt4_to_training_data
    DB_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Database ëª¨ë“ˆ ì—†ìŒ: {e}")
    DB_AVAILABLE = False

try:
    from gpt4_analyzer import analyze_with_gpt4_vision, get_gpt4_status
    GPT4_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ GPT-4 ëª¨ë“ˆ ì—†ìŒ: {e}")
    GPT4_AVAILABLE = False

try:
    from hybrid_analyzer import hybrid_analyze, get_analysis_method_stats
    HYBRID_AVAILABLE = True
    print("âœ… Hybrid Analyzer ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ Hybrid ëª¨ë“ˆ ì—†ìŒ: {e}")
    HYBRID_AVAILABLE = False

try:
    from ml_trainer import train_difficulty_model, train_type_model
    ML_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ML ëª¨ë“ˆ ì—†ìŒ: {e}")
    ML_AVAILABLE = False

# Pydantic ëª¨ë¸
class FeedbackRequest(BaseModel):
    problem_id: int
    user_difficulty: str
    user_type: str
    user_feedback: str = None

app = FastAPI(title="ClimbMate API", version="1.0.0")

# CORS ì„¤ì • (React ê°œë°œ ì„œë²„ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë„ë©”ì¸ìœ¼ë¡œ ë³€ê²½
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸš€ CRITICAL: FastAPI startup eventë¡œ ëª¨ë¸ ì‚¬ì „ ë¡œë”© (í™•ì‹¤í•˜ê²Œ!)
# ğŸš¨ ì„ì‹œë¡œ ëª¨ë¸ ì‚¬ì „ ë¡œë”© ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ í•´ê²°ìš©)
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ AI ëª¨ë¸ì„ ì‚¬ì „ ë¡œë”©í•˜ì—¬ ì²« ìš”ì²­ ì‹œ ë¨¹í†µ ë°©ì§€"""
    print("")
    print("=" * 80)
    print("âš ï¸  AI ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì„ì‹œ ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)")
    print("ğŸ“Œ ëª¨ë¸ì€ ì²« ë²ˆì§¸ ìš”ì²­ ì‹œ ë¡œë“œë©ë‹ˆë‹¤")
    print("=" * 80)
    
    # ì„ì‹œ ì£¼ì„ ì²˜ë¦¬
    # try:
    #     from preprocess import get_yolo_model, get_clip_model
    #     
    #     # YOLO ëª¨ë¸ ì‚¬ì „ ë¡œë”©
    #     print("")
    #     print("ğŸ“¦ 1/2: YOLO ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì¤‘...")
    #     log_memory_usage("YOLO ë¡œë”© ì „")
    #     yolo_model = get_yolo_model()
    #     log_memory_usage("YOLO ë¡œë”© í›„")
    #     print("âœ… YOLO ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    #     
    #     # CLIP ëª¨ë¸ ì‚¬ì „ ë¡œë”© (338MB â†’ 151MB)
    #     print("")
    #     print("ğŸ“¦ 2/2: CLIP ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì¤‘...")
    #     log_memory_usage("CLIP ë¡œë”© ì „")
    #     clip_model, clip_preprocess, clip_device = get_clip_model()
    #     log_memory_usage("CLIP ë¡œë”© í›„")
    #     print("âœ… CLIP ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    #     
    #     # ë©”ëª¨ë¦¬ ì •ë¦¬
    #     gc.collect()
    #     
    #     print("")
    #     print("=" * 80)
    #     print("âœ… ëª¨ë“  AI ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì™„ë£Œ! ì´ì œ ì²« ìš”ì²­ë¶€í„° ë¹ ë¥´ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤.")
    #     print("=" * 80)
    #     log_memory_usage("ëª¨ë¸ ë¡œë”© ì™„ë£Œ í›„")
    #     print("")
    #     
    # except Exception as e:
    #     print("")
    #     print("=" * 80)
    #     print(f"âš ï¸  ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì‹¤íŒ¨: {e}")
    #     print(f"âš ï¸  ì²« ìš”ì²­ ì‹œ ëª¨ë¸ì´ ë¡œë”©ë©ë‹ˆë‹¤ (ëŠë¦´ ìˆ˜ ìˆìŒ)")
    #     print("=" * 80)
    #     print("")
    #     import traceback
    #     traceback.print_exc()
    pass  # ì„ì‹œë¡œ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ

@app.get("/")
async def root():
    """í—¬ìŠ¤ì²´í¬"""
    return {"status": "ok", "message": "ClimbMate API is running"}

@app.post("/api/analyze")
async def analyze_image(
    file: UploadFile = File(...),
    wall_angle: str = None
):
    """
    ğŸš€ ë¹„ë™ê¸° í´ë¼ì´ë° ë²½ ì´ë¯¸ì§€ ë¶„ì„ (ì¦‰ì‹œ ì‘ë‹µ + ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)
    
    Parameters:
    - file: ì´ë¯¸ì§€ íŒŒì¼
    - wall_angle: ë²½ ê°ë„ (overhang, slab, face, null)
    
    Returns:
    - task_id: ì‘ì—… ID (ìƒíƒœ í™•ì¸ìš©)
    - status: ì‘ì—… ìƒíƒœ
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        contents = await file.read()
        
        # Base64 ì¸ì½”ë”©
        image_data_base64 = base64.b64encode(contents).decode('utf-8')
        
        # ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •
        params = {
            'conf': 0.4,
            'brightness_normalization': False,
            'brightness_filter': False,
            'min_brightness': 0,
            'max_brightness': 100,
            'saturation_filter': False,
            'min_saturation': 0,
            'mask_refinement': 5,
            'use_clip_ai': True
        }
        
        # Celery ì‘ì—… ì‹œì‘
        task = analyze_image_task.delay(image_data_base64, params)
        
        print(f"ğŸš€ ë¶„ì„ ì‘ì—… ì‹œì‘: {task.id}")
        
        return {
            "task_id": task.id,
            "status": "started",
            "message": "AI ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. /api/analysis-status/{task_id}ë¡œ ì§„í–‰ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”."
        }
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Analysis request failed: {str(e)}")

@app.post("/api/analyze-stream")
async def analyze_image_stream(
    file: UploadFile = File(...),
    wall_angle: str = Form(None),
    conf: float = Form(0.4),
    brightness_normalization: bool = Form(False),
    brightness_filter: bool = Form(False),
    min_brightness: int = Form(0),
    max_brightness: int = Form(100),
    saturation_filter: bool = Form(False),
    min_saturation: int = Form(0),
    mask_refinement: int = Form(5),
    use_clip_ai: bool = Form(True)
):
    """
    ğŸš€ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ (ì¦‰ì‹œ ì‘ë‹µ + ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)
    
    ê¸°ì¡´ ë™ê¸°ì‹ ìŠ¤íŠ¸ë¦¬ë°ì„ ë¹„ë™ê¸°ì‹ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ë‹¤ë¥¸ ìš”ì²­ì„ ë¸”ë¡í‚¹í•˜ì§€ ì•ŠìŒ
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        contents = await file.read()
        
        # Base64 ì¸ì½”ë”©
        image_data_base64 = base64.b64encode(contents).decode('utf-8')
        
        # ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •
        params = {
            'conf': conf,
            'brightness_normalization': brightness_normalization,
            'brightness_filter': brightness_filter,
            'min_brightness': min_brightness,
            'max_brightness': max_brightness,
            'saturation_filter': saturation_filter,
            'min_saturation': min_saturation,
            'mask_refinement': mask_refinement,
            'use_clip_ai': use_clip_ai
        }
        
        # Celery ì‘ì—… ì‹œì‘
        task = analyze_image_task.delay(image_data_base64, params)
        
        print(f"ğŸš€ ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì‘ì—… ì‹œì‘: {task.id}")
        
        return {
            "task_id": task.id,
            "status": "started",
            "message": "AI ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. /api/analysis-status/{task_id}ë¡œ ì§„í–‰ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”."
        }
        
    except Exception as e:
        print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Streaming analysis request failed: {str(e)}")

@app.get("/api/analysis-status/{task_id}")
async def get_analysis_status(task_id: str):
    """
    ğŸš€ ë¶„ì„ ì‘ì—… ìƒíƒœ í™•ì¸ (Celery í‘œì¤€ ë°©ì‹)
    
    Parameters:
    - task_id: ì‘ì—… ID
    
    Returns:
    - status: ì‘ì—… ìƒíƒœ (started, processing, completed, failed)
    - progress: ì§„í–‰ë¥  (0-100)
    - message: ìƒíƒœ ë©”ì‹œì§€
    - result: ë¶„ì„ ê²°ê³¼ (ì™„ë£Œ ì‹œ)
    """
    try:
        # Celery í‘œì¤€ ë°©ì‹ìœ¼ë¡œ ì‘ì—… ìƒíƒœ ì¡°íšŒ
        task = analyze_image_task.AsyncResult(task_id)
        
        if task.state == 'PENDING':
            response_data = {
                "task_id": task_id, 
                "status": "pending", 
                "message": "ë¶„ì„ ëŒ€ê¸° ì¤‘...", 
                "progress": 0
            }
        elif task.state == 'STARTED':
            meta = task.info or {}
            response_data = {
                "task_id": task_id,
                "status": "started",
                "message": meta.get('message', 'ë¶„ì„ ì§„í–‰ ì¤‘...'),
                "progress": meta.get('progress', 0)
            }
        elif task.state == 'PROGRESS':
            meta = task.info or {}
            response_data = {
                "task_id": task_id,
                "status": "progress",
                "message": meta.get('message', 'ë¶„ì„ ì§„í–‰ ì¤‘...'),
                "progress": meta.get('progress', 0)
            }
        elif task.state == 'SUCCESS':
            result = task.result
            response_data = {
                "task_id": task_id,
                "status": "completed",
                "message": "ë¶„ì„ ì™„ë£Œ!",
                "progress": 100,
                "result": result
            }
        elif task.state == 'FAILURE':
            response_data = {
                "task_id": task.id,
                "status": "failed",
                "message": f"ë¶„ì„ ì‹¤íŒ¨: {str(task.info)}",
                "progress": 100
            }
        else:
            response_data = {
                "task_id": task.id, 
                "status": task.state, 
                "message": "ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ", 
                "progress": 0
            }
        
        return response_data
        
    except Exception as e:
        print(f"âŒ ì‘ì—… ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get task status: {str(e)}")

@app.get("/api/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # Redis ì—°ê²° í™•ì¸
        redis_client.ping()
        redis_status = "connected"
    except:
        redis_status = "disconnected"
    
    return {
        "status": "healthy",
        "redis": redis_status,
        "memory": get_memory_usage(),
        "timestamp": psutil.time.time()
    }

# ğŸš€ CLIP ìƒ‰ìƒ ë¶„ì„ API (ì„œë²„ì—ì„œ ì‹¤í–‰)
class ColorAnalysisRequest(BaseModel):
    holds: list
    image_data_base64: str

@app.post("/api/analyze-colors")
async def analyze_colors_with_clip(request: ColorAnalysisRequest):
    """
    ğŸ¨ CLIP ëª¨ë¸ë¡œ í™€ë“œ ìƒ‰ìƒ ë¶„ì„ (ì„œë²„ì—ì„œ ì‹¤í–‰)
    ë¸Œë¼ìš°ì €: YOLOë¡œ í™€ë“œ ê°ì§€ â†’ ì„œë²„: CLIPìœ¼ë¡œ ìƒ‰ìƒ ë¶„ì„
    """
    try:
        from holdcheck.preprocess import get_clip_model, extract_color_with_clip_ai
        
        # ì´ë¯¸ì§€ ë””ì½”ë”© ë° ê²€ì¦
        try:
            image_data = base64.b64decode(request.image_data_base64)
            if len(image_data) < 100:  # ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€
                raise ValueError("Image data too small")
        except Exception as e:
            print(f"âš ï¸ Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=400, detail="Invalid image data")
        
        from PIL import Image
        import io
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ê²€ì¦
        try:
            pil_image = Image.open(io.BytesIO(image_data))
            if pil_image.size[0] < 10 or pil_image.size[1] < 10:  # ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€
                raise ValueError("Image too small")
            image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=400, detail="Invalid image format")
        
        # CLIP ëª¨ë¸ ë¡œë“œ
        clip_model, clip_preprocess, clip_device = get_clip_model()
        
        colored_holds = []
        
        for hold in request.holds:
            try:
                # í™€ë“œ ì˜ì—­ ì¶”ì¶œ
                x, y, w, h = int(hold['x']), int(hold['y']), int(hold['width']), int(hold['height'])
                
                # ê²½ê³„ ì²´í¬
                x = max(0, min(x, image.shape[1] - 1))
                y = max(0, min(y, image.shape[0] - 1))
                w = max(1, min(w, image.shape[1] - x))
                h = max(1, min(h, image.shape[0] - y))
                
                hold_image = image[y:y+h, x:x+w]
                
                if hold_image.size == 0:
                    colored_holds.append({**hold, 'color': 'unknown'})
                    continue
                
                # CLIPìœ¼ë¡œ ìƒ‰ìƒ ë¶„ì„
                color = extract_color_with_clip_ai(hold_image, None, clip_model, clip_preprocess, clip_device)
                
                colored_holds.append({
                    **hold,
                    'color': color
                })
                
            except Exception as e:
                print(f"âš ï¸ í™€ë“œ ìƒ‰ìƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
                colored_holds.append({
                    **hold,
                    'color': 'unknown'
                })
        
        return {
            "success": True,
            "colored_holds": colored_holds,
            "message": f"âœ… CLIPìœ¼ë¡œ {len(colored_holds)}ê°œ í™€ë“œ ìƒ‰ìƒ ë¶„ì„ ì™„ë£Œ"
        }
        
    except Exception as e:
        print(f"âŒ CLIP ìƒ‰ìƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"CLIP color analysis failed: {str(e)}")

# ê¸°ì¡´ APIë“¤ (ë°ì´í„°ë² ì´ìŠ¤, í†µê³„ ë“±)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
@app.post("/api/analyze-openai")
async def analyze_with_openai(
    file: UploadFile = File(...),
    wall_angle: str = Form(None)
):
    """
    ğŸš€ OpenAI Vision APIë¡œ í´ë¼ì´ë° ë²½ ë¶„ì„ (ë¬´ì œí•œ ë™ì‹œ ì²˜ë¦¬)
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        contents = await file.read()
        image_data_base64 = base64.b64encode(contents).decode('utf-8')
        
        # OpenAI Vision API í˜¸ì¶œ
        from openai_analyzer import analyze_climbing_wall_with_openai
        result = await analyze_climbing_wall_with_openai(image_data_base64)
        
        # ë²½ ê°ë„ ì •ë³´ ì¶”ê°€
        if wall_angle and result.get("problems"):
            for problem in result["problems"]:
                problem["wall_angle"] = wall_angle
        
        return result
        
    except Exception as e:
        print(f"âŒ OpenAI ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"OpenAI analysis failed: {str(e)}")

@app.get("/api/openai-status")
async def get_openai_status():
    """OpenAI API ìƒíƒœ í™•ì¸"""
    try:
        from openai_analyzer import get_openai_status
        return get_openai_status()
    except Exception as e:
        return {"available": False, "message": f"OpenAI status check failed: {str(e)}"}


@app.post("/api/feedback")
async def submit_feedback(feedback: FeedbackRequest):
    """ì‚¬ìš©ì í”¼ë“œë°± ì œì¶œ"""
    if not DB_AVAILABLE:
        raise HTTPException(status_code=500, detail="Database not available")
    
    try:
        result = save_user_feedback(
            feedback.problem_id,
            feedback.user_difficulty,
            feedback.user_type,
            feedback.user_feedback
        )
        return {"status": "success", "result": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/gpt4-status")
async def get_gpt4_status_endpoint():
    """GPT-4 ìƒíƒœ í™•ì¸"""
    if not GPT4_AVAILABLE:
        return {"available": False, "message": "GPT-4 module not available"}
    
    try:
        status = get_gpt4_status()
        return status
    except Exception as e:
        return {"available": False, "error": str(e)}

@app.post("/api/gpt4-analyze")
async def gpt4_analyze(file: UploadFile = File(...)):
    """GPT-4 Visionìœ¼ë¡œ ë¶„ì„"""
    if not GPT4_AVAILABLE:
        raise HTTPException(status_code=500, detail="GPT-4 module not available")
    
    try:
        contents = await file.read()
        result = analyze_with_gpt4_vision(contents)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/hybrid-stats")
async def get_hybrid_stats():
    """í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ í†µê³„"""
    if not HYBRID_AVAILABLE:
        return {"error": "Hybrid analyzer not available"}
    
    try:
        stats = get_analysis_method_stats()
        return stats
    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)