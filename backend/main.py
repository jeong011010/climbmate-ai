from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
import asyncio
import json
import cv2
import numpy as np
import sys
import os
import base64

# holdcheck ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
holdcheck_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'holdcheck')
sys.path.insert(0, holdcheck_path)

# backend ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
backend_path = os.path.dirname(__file__)
sys.path.insert(0, backend_path)

from preprocess import preprocess
from clustering import clip_ai_color_clustering, analyze_problem

# ë°ì´í„°ë² ì´ìŠ¤ ë° ë¶„ì„ ëª¨ë“ˆ (ì„ íƒì  ë¡œë“œ)
try:
    from database import save_problem, save_user_feedback, get_model_stats, get_training_data, convert_gpt4_to_training_data
    DB_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Database ëª¨ë“ˆ ì—†ìŒ: {e}")
    DB_AVAILABLE = False

try:
    from gpt4_analyzer import analyze_with_gpt4_vision, get_gpt4_status
    GPT4_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ GPT-4 ëª¨ë“ˆ ì—†ìŒ: {e}")
    GPT4_AVAILABLE = False

try:
    from hybrid_analyzer import hybrid_analyze, get_analysis_method_stats
    HYBRID_AVAILABLE = True
    print("âœ… Hybrid Analyzer ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ Hybrid ëª¨ë“ˆ ì—†ìŒ: {e}")
    HYBRID_AVAILABLE = False

try:
    from ml_trainer import train_difficulty_model, train_type_model
    ML_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ML ëª¨ë“ˆ ì—†ìŒ: {e}")
    ML_AVAILABLE = False

# Pydantic ëª¨ë¸
class FeedbackRequest(BaseModel):
    problem_id: int
    user_difficulty: str
    user_type: str
    user_feedback: str = None

app = FastAPI(title="ClimbMate API", version="1.0.0")

# ğŸš€ ì„±ëŠ¥ ìµœì í™”: ì‹œì‘ ì‹œ CLIP ëª¨ë¸ ë¯¸ë¦¬ ë¡œë”©
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    try:
        print("ğŸš€ ì„œë²„ ì‹œì‘ ì™„ë£Œ")
        print("âš¡ CLIP ëª¨ë¸ì€ ì²« ìš”ì²­ ì‹œ ìë™ ë¡œë”©ë©ë‹ˆë‹¤ (ë©”ëª¨ë¦¬ ìµœì í™”)")
        # CLIP ëª¨ë¸ì€ ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€ë¥¼ ìœ„í•´ ì²« ìš”ì²­ ì‹œ lazy loading
        # clustering.pyì™€ preprocess.pyì˜ get_clip_model()ì—ì„œ ìë™ ìºì‹±
    except Exception as e:
        print(f"âš ï¸ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")

# CORS ì„¤ì • (React ê°œë°œ ì„œë²„ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë„ë©”ì¸ìœ¼ë¡œ ë³€ê²½
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """í—¬ìŠ¤ì²´í¬"""
    return {"status": "ok", "message": "ClimbMate API is running"}

@app.post("/api/analyze")
async def analyze_image(
    file: UploadFile = File(...),
    wall_angle: str = None
):
    """
    í´ë¼ì´ë° ë²½ ì´ë¯¸ì§€ ë¶„ì„
    
    Parameters:
    - file: ì´ë¯¸ì§€ íŒŒì¼
    - wall_angle: ë²½ ê°ë„ (overhang, slab, face, null)
    
    Returns:
    - problems: ë°œê²¬ëœ ë¬¸ì œ ëª©ë¡
    - statistics: í†µê³„ ì •ë³´
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸° ë° í¬ê¸° ìµœì í™”
        contents = await file.read()
        nparr = np.frombuffer(contents, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if image is None:
            raise HTTPException(status_code=400, detail="Invalid image file")
        
        # ğŸš€ ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (ì†ë„ í–¥ìƒ)
        height, width = image.shape[:2]
        if width > 1200:  # ë„ˆë¬´ í° ì´ë¯¸ì§€ëŠ” ë¦¬ì‚¬ì´ì¦ˆ
            scale = 1200 / width
            new_width = 1200
            new_height = int(height * scale)
            image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            print(f"ğŸ“ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ: {width}x{height} â†’ {new_width}x{new_height}")
        
        # ğŸš€ ìµœì í™”: ì „ì²˜ë¦¬ (í™€ë“œ ê°ì§€)
        print(f"ğŸ” í™€ë“œ ê°ì§€ ì‹œì‘...")
        # ë°°í¬ í™˜ê²½ì— ë”°ë¥¸ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        if os.path.exists("/app/holdcheck/roboflow_weights/weights.pt"):
            model_path = "/app/holdcheck/roboflow_weights/weights.pt"  # Docker í™˜ê²½
        else:
            model_path = "/Users/kimjazz/Desktop/project/climbmate/holdcheck/roboflow_weights/weights.pt"  # ë¡œì»¬ í™˜ê²½
        
        hold_data_raw, masks = preprocess(
            image,
            model_path=model_path,
            mask_refinement=0,  # ë§ˆìŠ¤í¬ ì •ì œ ìµœì†Œí™” (ì†ë„ ìš°ì„ )
            conf=0.5,  # ë” í™•ì‹¤í•œ í™€ë“œë§Œ (ë…¸ì´ì¦ˆ ê°ì†Œ)
            use_clip_ai=True
        )
        
        if not hold_data_raw:
            return JSONResponse(
                status_code=200,
                content={
                    "problems": [],
                    "statistics": {"total_holds": 0, "total_problems": 0},
                    "message": "í™€ë“œë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                }
            )
        
        print(f"âœ… {len(hold_data_raw)}ê°œ í™€ë“œ ê°ì§€ ì™„ë£Œ")
        
        # ê·¸ë£¹í•‘ (ìƒ‰ìƒ ê¸°ë°˜)
        print(f"ğŸ¨ ìƒ‰ìƒ ê·¸ë£¹í•‘ ì‹œì‘...")
        hold_data = clip_ai_color_clustering(
            hold_data_raw,
            None,
            image,
            masks,
            eps=0.3,
            use_dbscan=False
        )
        
        # ê·¸ë£¹ë³„ ì •ë¦¬
        problems = {}
        for hold in hold_data:
            group = hold.get('group')
            if group is None:
                continue
            
            if group not in problems:
                clip_color = hold.get('clip_color_name', 'unknown')
                rgb = hold.get('dominant_rgb', [128, 128, 128])
                
                problems[group] = {
                    'id': group,
                    'color_name': clip_color,
                    'color_rgb': rgb,
                    'holds': [],
                    'hold_count': 0,
                    'analysis': None
                }
            
            problems[group]['holds'].append({
                'id': hold['id'],
                'center': hold['center'],
                'area': hold['area'],
                'rgb': hold.get('dominant_rgb', [128, 128, 128])
            })
        
        # ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”© (GPT-4 ë° DB ì €ì¥ìš©)
        _, buffer = cv2.imencode('.jpg', image)
        image_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # í™€ë“œ ìˆ˜ ì—…ë°ì´íŠ¸ ë° ë¶„ì„
        for group_id, problem in problems.items():
            problem['hold_count'] = len(problem['holds'])
            
            # 3ê°œ ì´ìƒì¸ ë¬¸ì œë§Œ ë¶„ì„
            if problem['hold_count'] >= 3:
                print(f"ğŸ¤– ë¬¸ì œ {group_id} ë¶„ì„ ì¤‘...")
                
                # ê¸°ë³¸ í†µê³„ ê¸°ë°˜ ë¶„ì„ (ë°±ì—…ìš©)
                rule_analysis = analyze_problem(
                    hold_data,
                    group_id,
                    wall_angle if wall_angle != "null" else None
                )
                
                # ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
                print(f"   ğŸ” HYBRID_AVAILABLE: {HYBRID_AVAILABLE}")
                print(f"   ğŸ” GPT4_AVAILABLE: {GPT4_AVAILABLE}")
                print(f"   ğŸ” OPENAI_API_KEY ì¡´ì¬: {bool(os.getenv('OPENAI_API_KEY'))}")
                if HYBRID_AVAILABLE:
                    print(f"   ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œì‘...")
                    hybrid_result = await hybrid_analyze(
                        image_base64=image_base64,
                        holds_data=problem['holds'],
                        wall_angle=wall_angle if wall_angle != "null" else None,
                        rule_based_analysis=rule_analysis
                    )
                    
                    # í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ë¥¼ ê¸°ì¡´ ë¶„ì„ êµ¬ì¡°ì— í†µí•©
                    rule_analysis['difficulty']['grade'] = hybrid_result['difficulty']['grade']
                    rule_analysis['difficulty']['confidence'] = hybrid_result['difficulty']['confidence']
                    rule_analysis['climb_type']['primary_type'] = hybrid_result['type']['primary_type']
                    rule_analysis['climb_type']['confidence'] = hybrid_result['type']['confidence']
                    rule_analysis['analysis_method'] = hybrid_result['method_used']
                    
                    if 'gpt4_reasoning' in hybrid_result:
                        rule_analysis['gpt4_reasoning'] = hybrid_result['gpt4_reasoning']
                
                problem['analysis'] = rule_analysis
                
                # DBì— ì €ì¥ (ê°€ëŠ¥í•œ ê²½ìš°)
                if DB_AVAILABLE:
                    try:
                        gpt4_save_data = {
                            'difficulty': rule_analysis['difficulty']['grade'],
                            'type': rule_analysis['climb_type']['primary_type'],
                            'confidence': rule_analysis['difficulty']['confidence'],
                            'method': rule_analysis.get('analysis_method', 'rule_based'),
                            'reasoning': rule_analysis.get('gpt4_reasoning', '')
                        }
                        
                        problem_id = save_problem(
                            image_base64=image_base64,
                            holds_data=problem['holds'],
                            gpt4_result=gpt4_save_data,
                            wall_angle=wall_angle if wall_angle != "null" else None,
                            image_width=image.shape[1],
                            image_height=image.shape[0],
                            statistics=rule_analysis.get('statistics', {})
                        )
                        problem['db_id'] = problem_id
                        print(f"âœ… ë¬¸ì œ {group_id} â†’ DB ID {problem_id}")
                    except Exception as e:
                        print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {e}")
                        problem['db_id'] = None
        
        print(f"âœ… {len(problems)}ê°œ ë¬¸ì œ ë¶„ì„ ì™„ë£Œ")
        
        # ğŸ¨ ì£¼ì„ ì´ë¯¸ì§€ ìƒì„± (ìƒ‰ìƒë³„ë¡œ í™€ë“œ í‘œì‹œ)
        annotated_image = image.copy()
        
        # ìƒ‰ìƒ ë§¤í•‘ (BGR)
        color_map_bgr = {
            'black': (50, 50, 50), 'white': (240, 240, 240), 'gray': (128, 128, 128),
            'red': (0, 0, 255), 'orange': (0, 165, 255), 'yellow': (0, 255, 255),
            'green': (0, 255, 0), 'blue': (255, 0, 0), 'purple': (255, 0, 255),
            'pink': (203, 192, 255), 'brown': (42, 42, 165), 
            'mint': (170, 255, 170), 'lime': (0, 255, 127)
        }
        
        for problem in problems.values():
            color_name = problem['color_name']
            bgr_color = color_map_bgr.get(color_name, (128, 128, 128))
            
            for hold in problem['holds']:
                hold_id = hold['id']
                if hold_id < len(masks):
                    mask = (masks[hold_id] * 255).astype(np.uint8)
                    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(annotated_image, contours, -1, bgr_color, 3)
                    
                    # ì¤‘ì‹¬ì— ë²ˆí˜¸ í‘œì‹œ
                    center = tuple(map(int, hold['center']))
                    cv2.putText(annotated_image, str(hold_id), center, 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, bgr_color, 2)
        
        # Base64 ì¸ì½”ë”©
        _, buffer = cv2.imencode('.jpg', annotated_image)
        annotated_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # í†µê³„
        total_holds = len(hold_data_raw)
        analyzable_problems = sum(1 for p in problems.values() if p['hold_count'] >= 3)
        h, w = image.shape[:2]
        
        return JSONResponse(
            status_code=200,
            content={
                "problems": list(problems.values()),
                "statistics": {
                    "total_holds": total_holds,
                    "total_problems": len(problems),
                    "analyzable_problems": analyzable_problems
                },
                "image_width": w,
                "image_height": h,
                "annotated_image_base64": annotated_base64,
                "message": f"{len(problems)}ê°œì˜ ë¬¸ì œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤."
            }
        )
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

# ğŸš€ CLIP ìƒ‰ìƒ ë¶„ì„ API (ì„œë²„ì—ì„œ ì‹¤í–‰)
class ColorAnalysisRequest(BaseModel):
    holds: list
    image_data_base64: str

@app.post("/api/analyze-colors")
async def analyze_colors_with_clip(request: ColorAnalysisRequest):
    """
    ğŸ¨ CLIP ëª¨ë¸ë¡œ í™€ë“œ ìƒ‰ìƒ ë¶„ì„ (ì„œë²„ì—ì„œ ì‹¤í–‰)
    ë¸Œë¼ìš°ì €: YOLOë¡œ í™€ë“œ ê°ì§€ â†’ ì„œë²„: CLIPìœ¼ë¡œ ìƒ‰ìƒ ë¶„ì„
    """
    try:
        from holdcheck.preprocess import get_clip_model, extract_color_with_clip_ai
        
        # ì´ë¯¸ì§€ ë””ì½”ë”© ë° ê²€ì¦
        try:
            image_data = base64.b64decode(request.image_data_base64)
            if len(image_data) < 100:
                raise ValueError("Image data too small")
        except Exception as e:
            print(f"âš ï¸ Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=400, detail="Invalid image data")
        
        from PIL import Image
        import io
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ê²€ì¦
        try:
            pil_image = Image.open(io.BytesIO(image_data))
            if pil_image.size[0] < 10 or pil_image.size[1] < 10:
                raise ValueError("Image too small")
            image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=400, detail="Invalid image format")
        
        colored_holds = []
        
        for hold in request.holds:
            try:
                # í™€ë“œ ì˜ì—­ ì¶”ì¶œ
                x, y, w, h = int(hold['x']), int(hold['y']), int(hold['width']), int(hold['height'])
                
                # ê²½ê³„ ì²´í¬
                x = max(0, min(x, image.shape[1] - 1))
                y = max(0, min(y, image.shape[0] - 1))
                w = max(1, min(w, image.shape[1] - x))
                h = max(1, min(h, image.shape[0] - y))
                
                hold_image = image[y:y+h, x:x+w]
                
                if hold_image.size == 0:
                    colored_holds.append({**hold, 'color': 'unknown'})
                    continue
                
                # CLIPìœ¼ë¡œ ìƒ‰ìƒ ë¶„ì„
                color = extract_color_with_clip_ai(hold_image, None)
                
                colored_holds.append({
                    **hold,
                    'color': color
                })
                
            except Exception as e:
                print(f"âš ï¸ í™€ë“œ ìƒ‰ìƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
                colored_holds.append({
                    **hold,
                    'color': 'unknown'
                })
        
        return {
            "success": True,
            "colored_holds": colored_holds,
            "message": f"âœ… CLIPìœ¼ë¡œ {len(colored_holds)}ê°œ í™€ë“œ ìƒ‰ìƒ ë¶„ì„ ì™„ë£Œ"
        }
        
    except Exception as e:
        print(f"âŒ CLIP ìƒ‰ìƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"CLIP color analysis failed: {str(e)}")

if DB_AVAILABLE:
    @app.post("/api/feedback")
    async def submit_feedback(feedback: FeedbackRequest):
        """ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥"""
        try:
            save_user_feedback(
                problem_id=feedback.problem_id,
                user_difficulty=feedback.user_difficulty,
                user_type=feedback.user_type,
                user_feedback=feedback.user_feedback
            )
            
            stats = get_model_stats()
            
            return JSONResponse(
                status_code=200,
                content={
                    "message": "í”¼ë“œë°± ì €ì¥ ì™„ë£Œ! ê°ì‚¬í•©ë‹ˆë‹¤ ğŸ™",
                    "stats": stats
                }
            )
        except Exception as e:
            print(f"âŒ í”¼ë“œë°± ì €ì¥ ì˜¤ë¥˜: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/api/stats")
    async def get_stats():
        """ëª¨ë¸ ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        try:
            stats = get_model_stats()
            gpt4_status = get_gpt4_status() if GPT4_AVAILABLE else {'available': False}
            method_stats = get_analysis_method_stats() if HYBRID_AVAILABLE else {}
            
            return JSONResponse(
                status_code=200,
                content={
                    "stats": stats,
                    "gpt4_status": gpt4_status,
                    "method_stats": method_stats
                }
            )
        except Exception as e:
            print(f"âŒ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            raise HTTPException(status_code=500, detail=str(e))

if ML_AVAILABLE and DB_AVAILABLE:
    @app.post("/api/train")
    async def train_models():
        """ìì²´ ML ëª¨ë¸ í•™ìŠµ"""
        try:
            stats = get_model_stats()
            
            if not stats['ready_for_training']:
                return JSONResponse(
                    status_code=400,
                    content={
                        "success": False,
                        "message": f"ìµœì†Œ 50ê°œì˜ ê²€ì¦ëœ ë°ì´í„° í•„ìš” (í˜„ì¬: {stats['verified_problems']}ê°œ)"
                    }
                )
            
            # í›ˆë ¨ ë°ì´í„° ë¡œë“œ
            training_data = get_training_data()
            
            # ë‚œì´ë„ ëª¨ë¸ í•™ìŠµ
            diff_test_acc, diff_cv_acc = train_difficulty_model(training_data)
            
            # ìœ í˜• ëª¨ë¸ í•™ìŠµ
            type_test_acc, type_cv_acc = train_type_model(training_data)
            
            return JSONResponse(
                status_code=200,
                content={
                    "success": True,
                    "message": "ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! ğŸ‰",
                    "results": {
                        "difficulty_model": {
                            "test_accuracy": round(diff_test_acc * 100, 1),
                            "cv_accuracy": round(diff_cv_acc * 100, 1)
                        },
                        "type_model": {
                            "test_accuracy": round(type_test_acc * 100, 1),
                            "cv_accuracy": round(type_cv_acc * 100, 1)
                        },
                        "training_samples": len(training_data)
                    }
                }
            )
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/convert-gpt4")
async def convert_gpt4_to_training():
    """GPT-4 ë¶„ì„ ê²°ê³¼ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ë³€í™˜"""
    if not DB_AVAILABLE:
        raise HTTPException(status_code=503, detail="ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        converted_count = convert_gpt4_to_training_data()
        return {
            "message": f"GPT-4 ê²°ê³¼ {converted_count}ê±´ì„ í›ˆë ¨ ë°ì´í„°ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤",
            "converted_count": converted_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë³€í™˜ ì‹¤íŒ¨: {str(e)}")

async def send_progress_update(message: str, progress: int, step: str = None, **kwargs):
    """SSE ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì „ì†¡"""
    data = {
        "message": message,
        "progress": progress,
        "step": step,
        **kwargs
    }
    # JSON ì¸ì½”ë”© ì‹œ í•œê¸€ê³¼ íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
    json_str = json.dumps(data, ensure_ascii=False, separators=(',', ':'))
    # SSE í˜•ì‹ ê°•í™”: ê° ì¤„ë§ˆë‹¤ ëª…í™•í•œ êµ¬ë¶„ì
    sse_message = f"data: {json_str}\n\n"
    print(f"ğŸ“¡ SSE ì „ì†¡: {message} ({progress}%) - {len(json_str)} bytes")
    return sse_message

@app.post("/api/analyze-stream")
async def analyze_image_stream(
    file: UploadFile = File(...),
    wall_angle: str = None
):
    """
    ë¹„ë™ê¸° ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘ (ì‘ì—… íì— ì¶”ê°€)
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        contents = await file.read()
        image_base64 = base64.b64encode(contents).decode('utf-8')
        
        # ë¹„ë™ê¸° ì‘ì—… íì— ì¶”ê°€
        from ai_tasks import analyze_image_async
        task = analyze_image_async.delay(image_base64, wall_angle)
        
        return {
            "task_id": task.id,
            "status": "PENDING",
            "message": "ğŸš€ ë¶„ì„ ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì‘ì—… ì‹œì‘ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/analyze-status/{task_id}")
async def get_analysis_status(task_id: str):
    """
    ë¶„ì„ ì‘ì—… ìƒíƒœ í™•ì¸
    """
    try:
        from ai_tasks import analyze_image_async
        task = analyze_image_async.AsyncResult(task_id)
        
        if task.state == 'PENDING':
            response = {
                'status': task.state,
                'progress': 0,
                'message': 'ì‘ì—… ëŒ€ê¸° ì¤‘...'
            }
        elif task.state == 'PROGRESS':
            response = {
                'status': task.state,
                'progress': task.info.get('progress', 0),
                'message': task.info.get('message', ''),
                'step': task.info.get('step', ''),
                **task.info
            }
        elif task.state == 'SUCCESS':
            response = {
                'status': task.state,
                'progress': 100,
                'message': 'âœ… ë¶„ì„ ì™„ë£Œ!',
                'result': task.result
            }
        else:  # FAILURE
            response = {
                'status': task.state,
                'progress': 0,
                'message': task.info.get('message', 'ë¶„ì„ ì‹¤íŒ¨'),
                'error': task.info.get('error', '')
            }
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/gpt4-analyze")
async def gpt4_analyze(request: dict):
    """
    GPT-4 ë¬¸ì œ ë¶„ì„ API
    """
    try:
        image_base64 = request.get('image_base64')
        holds = request.get('holds')
        wall_angle = request.get('wall_angle')
        
        if not image_base64 or not holds:
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ì™€ í™€ë“œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # GPT-4 ë¶„ì„ ì‹¤í–‰
        analysis = analyze_with_gpt4_vision(image_base64, holds, wall_angle)
        
        return {
            "success": True,
            "analysis": analysis
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPT-4 ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/analyze-sync")
async def analyze_image_sync(
    file: UploadFile = File(...),
    wall_angle: str = None
):
    """
    í´ë¼ì´ë° ë²½ ì´ë¯¸ì§€ ë¶„ì„ (ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì „ì†¡)
    
    Parameters:
    - file: ì´ë¯¸ì§€ íŒŒì¼
    - wall_angle: ë²½ ê°ë„ (overhang, slab, face, null)
    
    Returns:
    - SSE ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì‹¤ì‹œê°„ ì§„í–‰ë¥  ë° ê²°ê³¼ ì „ì†¡
    """
    async def generate():
        try:
            # 1ë‹¨ê³„: ì´ë¯¸ì§€ ì—…ë¡œë“œ
            yield await send_progress_update("ğŸ“¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¤‘...", 5, "upload")
            
            # ì´ë¯¸ì§€ ì½ê¸°
            contents = await file.read()
            nparr = np.frombuffer(contents, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                yield await send_progress_update("âŒ ì˜ëª»ëœ ì´ë¯¸ì§€ íŒŒì¼", 0, "error")
                return
            
            # 2ë‹¨ê³„: í™€ë“œ ê°ì§€ ì‹œì‘
            yield await send_progress_update("ğŸ” í™€ë“œ ê°ì§€ ì¤‘...", 10, "detection")
            
            # ğŸš€ ìµœì í™”: ì „ì²˜ë¦¬ (í™€ë“œ ê°ì§€)
            # ë°°í¬ í™˜ê²½ì— ë”°ë¥¸ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
            if os.path.exists("/app/holdcheck/roboflow_weights/weights.pt"):
                model_path = "/app/holdcheck/roboflow_weights/weights.pt"  # Docker í™˜ê²½
            else:
                model_path = "/Users/kimjazz/Desktop/project/climbmate/holdcheck/roboflow_weights/weights.pt"  # ë¡œì»¬ í™˜ê²½
            
            hold_data_raw, masks = preprocess(
                image,
                model_path=model_path,
                mask_refinement=1,  # ì†ë„ ìš°ì„ 
                conf=0.4,  # í™•ì‹¤í•œ í™€ë“œë§Œ
                use_clip_ai=True
            )
            
            if not hold_data_raw:
                yield await send_progress_update("âŒ í™€ë“œë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤", 0, "error")
                return
            
            # í™€ë“œ ê°ì§€ ì™„ë£Œ
            yield await send_progress_update(f"âœ… {len(hold_data_raw)}ê°œ í™€ë“œ ê°ì§€ ì™„ë£Œ", 30, "detection_complete", holds_count=len(hold_data_raw))
            
            # 3ë‹¨ê³„: ìƒ‰ìƒ ê·¸ë£¹í•‘
            yield await send_progress_update("ğŸ¨ ìƒ‰ìƒ ë¶„ë¥˜ ì¤‘...", 40, "clustering")
            
            hold_data = clip_ai_color_clustering(
                hold_data_raw,
                None,
                image,
                masks,
                eps=0.3,
                use_dbscan=False
            )
            
            # ê·¸ë£¹ë³„ ì •ë¦¬
            problems = {}
            print(f"ğŸ” í™€ë“œ ë°ì´í„° ë¶„ì„: {len(hold_data)}ê°œ í™€ë“œ")
            
            for i, hold in enumerate(hold_data):
                if i < 5:  # ì²˜ìŒ 5ê°œë§Œ ë¡œê·¸
                    print(f"  í™€ë“œ {i}: {type(hold)} - group: {hold.get('group')}")
                
                group = hold.get('group')
                if group is None:
                    continue
                
                if group not in problems:
                    clip_color = hold.get('clip_color_name', 'unknown')
                    rgb = hold.get('dominant_rgb', [128, 128, 128])
                    
                    problems[group] = {
                        'id': group,
                        'color_name': clip_color,
                        'color_rgb': rgb,
                        'holds': [],
                        'hold_count': 0,
                        'analysis': None
                    }
                
                problems[group]['holds'].append({
                    'id': hold['id'],
                    'center': hold['center'],
                    'area': hold['area'],
                    'rgb': hold.get('dominant_rgb', [128, 128, 128])
                })
            
            print(f"ğŸ” ìƒì„±ëœ ë¬¸ì œ ê·¸ë£¹: {len(problems)}ê°œ")
            for group_id, problem in problems.items():
                print(f"  ê·¸ë£¹ {group_id}: {len(problem['holds'])}ê°œ í™€ë“œ")
            
            # ìƒ‰ìƒ ë¶„ë¥˜ ì™„ë£Œ
            yield await send_progress_update(f"âœ… {len(problems)}ê°œ ë¬¸ì œ ë¶„ë¥˜ ì™„ë£Œ", 60, "clustering_complete", problems_count=len(problems))
            
            # ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
            _, buffer = cv2.imencode('.jpg', image)
            image_base64 = base64.b64encode(buffer).decode('utf-8')
            
            # 4ë‹¨ê³„: ë¬¸ì œ ë¶„ì„
            yield await send_progress_update("ğŸ¤– AI ë¬¸ì œ ë¶„ì„ ì¤‘...", 70, "analysis")
            
            # í™€ë“œ ìˆ˜ ì—…ë°ì´íŠ¸ ë° ë¶„ì„
            for group_id, problem in problems.items():
                problem['hold_count'] = len(problem['holds'])
                
                # 3ê°œ ì´ìƒì¸ ë¬¸ì œë§Œ ë¶„ì„
                if problem['hold_count'] >= 3:
                    print(f"ğŸ¤– ë¬¸ì œ {group_id} ë¶„ì„ ì¤‘...")
                    
                    # ê¸°ë³¸ í†µê³„ ê¸°ë°˜ ë¶„ì„ (ë°±ì—…ìš©)
                    rule_analysis = analyze_problem(
                        hold_data,
                        group_id,
                        wall_angle if wall_angle != "null" else None
                    )
                    
                    # analyze_problemì´ Noneì„ ë°˜í™˜í•  ìˆ˜ ìˆìŒ
                    if rule_analysis is None:
                        print(f"   âš ï¸ ê·œì¹™ ê¸°ë°˜ ë¶„ì„ ì‹¤íŒ¨ (í™€ë“œ ë¶€ì¡±): {group_id}")
                        rule_analysis = {
                            'difficulty': {'grade': 'V?', 'confidence': 0.0},
                            'climb_type': {'primary_type': 'ë¶„ì„ ë¶ˆê°€', 'confidence': 0.0},
                            'statistics': {}
                        }
                    
                    # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ (GPT-4 + ML)
                    if HYBRID_AVAILABLE:
                        try:
                            print(f"   ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œì‘ - GPT4_AVAILABLE: {GPT4_AVAILABLE}, API_KEY: {bool(os.getenv('OPENAI_API_KEY'))}")
                            hybrid_result = await hybrid_analyze(
                                image_base64=image_base64,
                                holds_data=problem['holds'],
                                wall_angle=wall_angle if wall_angle != "null" else None,
                                rule_based_analysis=rule_analysis
                            )
                            
                            print(f"   ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼: {hybrid_result}")
                            
                            # í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ë¥¼ ê¸°ì¡´ ë¶„ì„ êµ¬ì¡°ì— í†µí•©
                            rule_analysis['difficulty']['grade'] = hybrid_result['difficulty']['grade']
                            rule_analysis['difficulty']['confidence'] = hybrid_result['difficulty']['confidence']
                            rule_analysis['climb_type']['primary_type'] = hybrid_result['type']['primary_type']
                            rule_analysis['climb_type']['confidence'] = hybrid_result['type']['confidence']
                            rule_analysis['analysis_method'] = hybrid_result['method_used']
                            
                            if 'gpt4_reasoning' in hybrid_result:
                                rule_analysis['gpt4_reasoning'] = hybrid_result['gpt4_reasoning']
                            
                            problem['analysis'] = rule_analysis
                            problem['gpt4_reasoning'] = hybrid_result.get('gpt4_reasoning', '')
                            problem['gpt4_confidence'] = hybrid_result.get('gpt4_confidence', 0.8)
                            print(f"   ğŸ” GPT-4 ë°ì´í„° í™•ì¸: reasoning='{problem['gpt4_reasoning']}', confidence={problem['gpt4_confidence']}")
                        except Exception as e:
                            print(f"âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ ì‚¬ìš©: {e}")
                            problem['analysis'] = rule_analysis
                    else:
                        print(f"   âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‚¬ìš© ë¶ˆê°€ - HYBRID_AVAILABLE: {HYBRID_AVAILABLE}")
                        problem['analysis'] = rule_analysis
            
            # ë¶„ì„ ì™„ë£Œ
            yield await send_progress_update("âœ… AI ë¶„ì„ ì™„ë£Œ", 90, "analysis_complete")
            
            # 5ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬
            yield await send_progress_update("ğŸ“Š ê²°ê³¼ ì •ë¦¬ ì¤‘...", 95, "finalizing")
            
            # ë¬¸ì œ ëª©ë¡ì„ ë°°ì—´ë¡œ ë³€í™˜ (None ê°’ í•„í„°ë§)
            problems_list = [p for p in problems.values() if p is not None]
            
            # í†µê³„ ê³„ì‚°
            total_holds = len(hold_data_raw)
            total_problems = len(problems_list)
            analyzable_problems = len([p for p in problems_list if p and p.get('hold_count', 0) >= 3])
            
            statistics = {
                "total_holds": total_holds,
                "total_problems": total_problems,
                "analyzable_problems": analyzable_problems
            }
            
            # ì£¼ì„ ë‹¬ë¦° ì´ë¯¸ì§€ ìƒì„±
            annotated_image = None
            if masks is not None:
                try:
                    # ì›ë³¸ ì´ë¯¸ì§€ì— í™€ë“œ ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
                    overlay = image.copy()
                    colors = [
                        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
                        (255, 0, 255), (0, 255, 255), (128, 0, 0), (0, 128, 0),
                        (0, 0, 128), (128, 128, 0), (128, 0, 128), (0, 128, 128)
                    ]
                    
                    for i, mask in enumerate(masks):
                        if i < len(colors):
                            color = colors[i % len(colors)]
                            overlay[mask > 0.5] = color
                    
                    # ì˜¤ë²„ë ˆì´ë¥¼ ì›ë³¸ì— ë¸”ë Œë”©
                    annotated = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)
                    
                    # Base64ë¡œ ì¸ì½”ë”©
                    _, buffer = cv2.imencode('.jpg', annotated)
                    annotated_image = base64.b64encode(buffer).decode('utf-8')
                except Exception as e:
                    print(f"âš ï¸ ì£¼ì„ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ìµœì¢… ê²°ê³¼ ì „ì†¡
            result = {
                "problems": problems_list,
                "statistics": statistics,
                "hold_data": hold_data,
                "annotated_image_base64": annotated_image
            }
            
            # ê²°ê³¼ë¥¼ ë‹¨ê³„ë³„ë¡œ ì „ì†¡ (í° ë°ì´í„°ëŠ” ì²­í¬ë¡œ ë¶„í• )
            print(f"ğŸ“Š í†µê³„ ë°ì´í„° ì „ì†¡: {statistics}")
            yield await send_progress_update("ğŸ“Š í†µê³„ ë°ì´í„° ì „ì†¡", 96, "result_stats", statistics=statistics)
            
            # í™€ë“œ ë°ì´í„°ì—ì„œ í”„ë¡ íŠ¸ì—”ë“œì— í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
            def clean_hold_data(holds):
                """í”„ë¡ íŠ¸ì—”ë“œ ì „ì†¡ìš© í™€ë“œ ë°ì´í„° ì •ë¦¬ - í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ"""
                cleaned = []
                for hold in holds:
                    cleaned_hold = {
                        'id': hold['id'],
                        'center': hold['center'],
                        'area': hold['area'],
                        'rgb': hold.get('dominant_rgb', [128, 128, 128]),
                        'color': hold.get('clip_color_name', 'unknown')
                    }
                    cleaned.append(cleaned_hold)
                return cleaned
            
            hold_data_clean = clean_hold_data(hold_data)
            
            # í™€ë“œ ë°ì´í„° ì „ì†¡ (ì²« ì»¤ë°‹ ë•Œì²˜ëŸ¼ ì œí•œ ì—†ì´)
            print(f"ğŸ” í™€ë“œ ë°ì´í„° ì „ì†¡ ì‹œì‘: {len(hold_data_clean)}ê°œ")
            yield await send_progress_update(f"ğŸ” í™€ë“œ ë°ì´í„° ì „ì†¡ ì™„ë£Œ", 96, "result_holds", hold_data=hold_data_clean)
            
            # ë¬¸ì œ ë°ì´í„°ì—ì„œ í”„ë¡ íŠ¸ì—”ë“œì— í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
            def clean_problem_data(problems):
                """í”„ë¡ íŠ¸ì—”ë“œ ì „ì†¡ìš© ë¬¸ì œ ë°ì´í„° ì •ë¦¬ - í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ"""
                cleaned = []
                for problem in problems:
                    # None ì²´í¬ ì¶”ê°€
                    if problem is None:
                        print("âš ï¸ None ë¬¸ì œ ë°œê²¬, ê±´ë„ˆëœ€")
                        continue
                    
                    # í•„ìˆ˜ í•„ë“œ ì²´í¬
                    if not isinstance(problem, dict):
                        print(f"âš ï¸ ì˜ëª»ëœ ë¬¸ì œ ë°ì´í„° íƒ€ì…: {type(problem)}")
                        continue
                    
                    analysis = problem.get('analysis', {})
                    difficulty = analysis.get('difficulty', {}) if analysis else {}
                    climb_type = analysis.get('climb_type', {}) if analysis else {}
                    
                    cleaned_problem = {
                        'id': problem.get('id', 'unknown'),
                        'color_name': problem.get('color_name', 'unknown'),
                        'color_rgb': problem.get('color_rgb', [128, 128, 128]),
                        'holds': problem.get('holds', []),
                        'hold_count': problem.get('hold_count', 0),
                        'difficulty': {
                            'grade': difficulty.get('grade', 'V?') if difficulty else 'V?',
                            'level': difficulty.get('level', 'ë¯¸ë¶„ì„') if difficulty else 'ë¯¸ë¶„ì„',
                            'confidence': difficulty.get('confidence', 0.0) if difficulty else 0.0,
                            'factors': difficulty.get('factors', {}) if difficulty else {}
                        },
                        'climb_type': {
                            'primary_type': climb_type.get('primary_type', 'ì¼ë°˜') if climb_type else 'ì¼ë°˜',
                            'types': climb_type.get('types', []) if climb_type else [],
                            'confidence': climb_type.get('confidence', 0.0) if climb_type else 0.0
                        },
                        'gpt4_reasoning': problem.get('gpt4_reasoning', ''),
                        'gpt4_confidence': problem.get('gpt4_confidence', 0.0),
                        'gpt4_movements': problem.get('gpt4_movements', []),
                        'gpt4_challenges': problem.get('gpt4_challenges', []),
                        'gpt4_tips': problem.get('gpt4_tips', [])
                    }
                    cleaned.append(cleaned_problem)
                return cleaned
            
            print(f"ğŸ” ì›ë³¸ ë¬¸ì œ ëª©ë¡: {len(problems_list)}ê°œ")
            for i, p in enumerate(problems_list):
                print(f"  ë¬¸ì œ {i+1}: {type(p)} - {p is not None}")
                if p is not None and isinstance(p, dict):
                    print(f"    - id: {p.get('id')}, color: {p.get('color_name')}, holds: {len(p.get('holds', []))}")
                    print(f"    - analysis: {type(p.get('analysis'))} - {p.get('analysis') is not None}")
                else:
                    print(f"    - âš ï¸ ë¬¸ì œ ë°ì´í„°ê°€ Noneì´ê±°ë‚˜ dictê°€ ì•„ë‹˜!")
            
            problems_clean = clean_problem_data(problems_list)
            
            # ë¬¸ì œ ë°ì´í„° ì „ì†¡
            print(f"ğŸ¯ ì •ë¦¬ëœ ë¬¸ì œ ë°ì´í„° ì „ì†¡: {len(problems_clean)}ê°œ")
            for i, problem in enumerate(problems_clean):
                if problem and isinstance(problem, dict):
                    print(f"  ë¬¸ì œ {i+1} ({problem.get('color_name', 'unknown')}): difficulty={problem.get('difficulty', {}).get('grade', 'V?')}, type={problem.get('climb_type', {}).get('primary_type', 'ì¼ë°˜')}")
            yield await send_progress_update("ğŸ¯ ë¬¸ì œ ë°ì´í„° ì „ì†¡", 98, "result_problems", problems=problems_clean)
            
            # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì „ì†¡
            if annotated_image:
                print(f"ğŸ–¼ï¸ ì£¼ì„ ì´ë¯¸ì§€ ì „ì†¡ ì‹œì‘: {len(annotated_image)}bytes")
                chunk_size = 50000  # 50KBì”© ì „ì†¡
                for i in range(0, len(annotated_image), chunk_size):
                    chunk = annotated_image[i:i+chunk_size]
                    chunk_num = i // chunk_size + 1
                    total_chunks = (len(annotated_image) + chunk_size - 1) // chunk_size
                    print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²­í¬ {chunk_num}/{total_chunks} ì „ì†¡: {len(chunk)}bytes")
                    yield await send_progress_update(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì „ì†¡ ({chunk_num}/{total_chunks})", 99 + (chunk_num * 0.1), "result_image_chunk", image_chunk=chunk, chunk_info={"current": chunk_num, "total": total_chunks})
            
            # ì™„ë£Œ - ìµœì¢… ê²°ê³¼ í¬í•¨
            yield await send_progress_update("âœ… ë¶„ì„ ì™„ë£Œ!", 100, "complete", 
                                           problems=problems_clean, 
                                           statistics=statistics, 
                                           annotated_image_base64=annotated_image)
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì˜¤ë¥˜: {e}")
            yield await send_progress_update(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}", 0, "error")
    
    headers = {
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "Content-Type": "text/event-stream; charset=utf-8",
        "X-Accel-Buffering": "no",
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Headers": "Cache-Control, Accept",
        "Access-Control-Allow-Methods": "POST, GET, OPTIONS",
        "Transfer-Encoding": "chunked"
    }
    print("ğŸ“¡ SSE ì‘ë‹µ í—¤ë” ì„¤ì •:", headers)
    # SSE ìŠ¤íŠ¸ë¦¼ í”ŒëŸ¬ì‹œ ê°•í™”
    return StreamingResponse(
        generate(), 
        media_type="text/event-stream", 
        headers=headers,
        # ìŠ¤íŠ¸ë¦¼ ì¦‰ì‹œ ì „ì†¡ì„ ìœ„í•œ ì„¤ì •
        background=None
    )

@app.get("/api/health")
async def health_check():
    """ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "models": {
            "yolo": "loaded",
            "clip": "loaded"
        }
    }

@app.get("/api/gpt4-status")
async def gpt4_status_check():
    """GPT-4 ìƒíƒœ í™•ì¸ (ë””ë²„ê¹…ìš©)"""
    try:
        if not GPT4_AVAILABLE:
            return {
                "available": False,
                "reason": "GPT4_AVAILABLE = False",
                "api_key_set": bool(os.getenv('OPENAI_API_KEY')),
                "details": "GPT-4 ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            }
        
        if not os.getenv('OPENAI_API_KEY'):
            return {
                "available": False,
                "reason": "API í‚¤ ì—†ìŒ",
                "api_key_set": False,
                "details": "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }
        
        # GPT-4 ìƒíƒœ í™•ì¸
        if HYBRID_AVAILABLE:
            from hybrid_analyzer import get_analysis_method_stats
            stats = get_analysis_method_stats()
            return {
                "available": stats.get('gpt4_available', False),
                "reason": "ì •ìƒ",
                "api_key_set": True,
                "details": f"GPT-4 ì‚¬ìš© ê°€ëŠ¥: {stats.get('gpt4_available', False)}",
                "recommended_method": stats.get('recommended_method', 'unknown'),
                "hybrid_available": HYBRID_AVAILABLE
            }
        else:
            return {
                "available": False,
                "reason": "í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ê¸° ì—†ìŒ",
                "api_key_set": bool(os.getenv('OPENAI_API_KEY')),
                "details": "HYBRID_AVAILABLE = False",
                "hybrid_available": False
            }
            
    except Exception as e:
        return {
            "available": False,
            "reason": f"ì˜¤ë¥˜: {str(e)}",
            "api_key_set": bool(os.getenv('OPENAI_API_KEY')),
            "details": f"ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        }

@app.post("/api/test-gpt4")
async def test_gpt4():
    """GPT-4 ê°„ë‹¨ í…ŒìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)"""
    try:
        if not GPT4_AVAILABLE:
            return {
                "success": False,
                "message": "GPT-4 ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "details": "GPT4_AVAILABLE = False"
            }
        
        if not os.getenv('OPENAI_API_KEY'):
            return {
                "success": False,
                "message": "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "details": "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”"
            }
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (1x1 í”½ì…€)
        import numpy as np
        test_image = np.ones((100, 100, 3), dtype=np.uint8) * 128  # íšŒìƒ‰ ì´ë¯¸ì§€
        _, buffer = cv2.imencode('.jpg', test_image)
        test_image_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # ê°„ë‹¨í•œ í™€ë“œ ë°ì´í„°
        test_holds = [
            {
                'id': 0,
                'center': [50, 50],
                'area': 1000,
                'color_name': 'blue'
            }
        ]
        
        # GPT-4 í…ŒìŠ¤íŠ¸ í˜¸ì¶œ
        from gpt4_analyzer import analyze_with_gpt4_vision
        result = analyze_with_gpt4_vision(test_image_base64, test_holds, "face")
        
        return {
            "success": True,
            "message": "GPT-4 í…ŒìŠ¤íŠ¸ ì„±ê³µ",
            "result": result,
            "details": f"ë‚œì´ë„: {result.get('difficulty')}, ìœ í˜•: {result.get('type')}, ì‹ ë¢°ë„: {result.get('confidence')}"
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"GPT-4 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}",
            "details": str(e)
        }

if __name__ == "__main__":
    import uvicorn
    # ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì›Œì»¤ ì„¤ì •
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        workers=2,  # 2ê°œ ì›Œì»¤ë¡œ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬
        loop="asyncio",  # ë¹„ë™ê¸° ë£¨í”„ ìµœì í™”
        access_log=True,  # ì ‘ê·¼ ë¡œê·¸ í™œì„±í™”
        log_level="info"
    )

