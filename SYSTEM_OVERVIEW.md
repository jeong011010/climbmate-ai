# 🎯 ClimbMate 시스템 개요

## 🏗️ 아키텍처

```
┌─────────────────────────────────────────────────┐
│                   사용자                         │
│              (모바일/웹 브라우저)                │
└─────────────┬───────────────────────────────────┘
              │
              ↓
┌─────────────────────────────────────────────────┐
│            프론트엔드 (React PWA)                │
│  - 이미지 업로드/촬영                            │
│  - 결과 시각화                                   │
│  - 피드백 UI                                     │
└─────────────┬───────────────────────────────────┘
              │ HTTP/REST API
              ↓
┌─────────────────────────────────────────────────┐
│            백엔드 (FastAPI)                      │
│                                                  │
│  ┌──────────────────────────────────────────┐  │
│  │      하이브리드 분석 시스템               │  │
│  │                                           │  │
│  │  1순위: 자체 ML 모델 (50+ 데이터)       │  │
│  │    ↓ (신뢰도 낮으면)                     │  │
│  │  2순위: GPT-4 Vision                     │  │
│  │    ↓ (실패하면)                          │  │
│  │  3순위: 규칙 기반 분석                   │  │
│  └──────────────────────────────────────────┘  │
│                                                  │
│  ┌──────────────────────────────────────────┐  │
│  │   YOLO v8 + CLIP AI (홀드 감지/색상)   │  │
│  └──────────────────────────────────────────┘  │
└─────────────┬───────────────────────────────────┘
              │
              ↓
┌─────────────────────────────────────────────────┐
│          데이터 저장소 (SQLite)                  │
│  - 이미지 데이터                                 │
│  - 홀드 정보                                     │
│  - AI 예측 결과                                  │
│  - 사용자 피드백                                 │
│  - 학습된 모델                                   │
└─────────────────────────────────────────────────┘
```

---

## 🔄 데이터 플로우

### 1️⃣ 이미지 업로드
```
사용자 → 프론트엔드 → 백엔드
                        ↓
                     YOLO v8 감지
                        ↓
                     CLIP AI 색상 분류
                        ↓
                     홀드 그룹화
```

### 2️⃣ 난이도/유형 분석
```
홀드 데이터 → 하이브리드 분석기
              ↓
     ┌────────┴────────┐
     │                 │
  ML 모델?          GPT-4?
     │                 │
     ↓                 ↓
  있음/신뢰도 높음   사용 가능?
     │                 │
     ↓                 ↓
  ML 예측          GPT-4 예측
     │                 │
     └────────┬────────┘
              ↓
         규칙 기반 (백업)
              ↓
          최종 결과
```

### 3️⃣ 사용자 피드백
```
분석 결과 표시 → 사용자 피드백
                     ↓
                 DB에 저장
                     ↓
              검증 데이터 축적
                     ↓
           (50개 이상 → 자동 학습)
                     ↓
              자체 모델 사용
```

---

## 📊 학습 단계별 동작

### Phase 1: 초기 (0-50 피드백)
```
입력: 사진
↓
YOLO → CLIP → GPT-4 Vision
↓
출력: 난이도 V? (GPT-4)
↓
사용자 피드백 → DB 저장
```

**특징:**
- ✅ GPT-4로 높은 정확도
- ❌ 비용 발생 (~$1/100건)
- ✅ 데이터 수집 중

### Phase 2: 학습 (50-100 피드백)
```
입력: 사진
↓
YOLO → CLIP → 하이브리드
↓
자체 모델 (신뢰도 낮으면 GPT-4)
↓
출력: 난이도 V? (ML 또는 GPT-4)
↓
사용자 피드백 → 재학습
```

**특징:**
- ✅ ML 모델 등장
- ✅ 비용 감소 (~$0.5/100건)
- ✅ 정확도 검증 중

### Phase 3: 독립 (100+ 피드백)
```
입력: 사진
↓
YOLO → CLIP → 자체 ML 모델
↓
출력: 난이도 V? (90%+ 자체 모델)
↓
(낮은 신뢰도만 GPT-4)
```

**특징:**
- ✅ 완전 독립 운영
- ✅ 초저비용 (~$0.1/100건)
- ✅ 빠른 응답 속도

---

## 🤖 AI 모델 상세

### 1. YOLOv8-seg (홀드 감지)
- **입력**: 클라이밍 벽 이미지
- **출력**: 홀드 세그멘테이션 마스크
- **성능**: ~0.4 confidence로 95%+ 정확도

### 2. CLIP AI (색상 분류)
- **입력**: 홀드 이미지 패치
- **출력**: 색상 라벨 (13가지)
- **성능**: ~85% 정확도

### 3. GPT-4 Vision (난이도/유형)
- **입력**: 전체 이미지 + 홀드 통계
- **출력**: V-grade + 유형 + 근거
- **성능**: ~75-85% 정확도 (추정)

### 4. 자체 ML 모델 (학습 후)
- **알고리즘**: Gradient Boosting
- **특징**: 25개 (크기, 거리, 배치 등)
- **성능**: 데이터에 따라 향상

---

## 💾 데이터베이스 스키마

### climbing_problems 테이블
```sql
- id: 고유 ID
- image_base64: 이미지 데이터
- holds_data: 홀드 정보 (JSON)
- num_holds: 홀드 개수

- gpt4_difficulty: GPT-4 예측 난이도
- gpt4_type: GPT-4 예측 유형
- gpt4_confidence: 신뢰도

- user_difficulty: 사용자 피드백 난이도
- user_type: 사용자 피드백 유형
- is_verified: 검증 여부

- wall_angle: 벽 각도
- avg_hold_size: 평균 홀드 크기
- max_hold_distance: 최대 거리
... (25개 통계 필드)
```

---

## 🎨 특징 벡터 (25차원)

ML 모델이 사용하는 특징들:

1. **홀드 기본 정보** (5개)
   - 개수, 평균/최소/최대 크기, 크기 분산

2. **거리 정보** (4개)
   - 최대/평균 거리, 연속 거리, 거리 분산

3. **공간 분포** (6개)
   - 높이 범위, 수평 범위, 이동 비율
   - 수평/수직 분산, 밀도

4. **홀드 특성** (5개)
   - 작은 홀드 비율, 큰 홀드 비율
   - 극소형 비율, 큰 점프 비율
   - 색상 다양성

5. **위치 정보** (5개)
   - 평균 X/Y 위치, 높이 변화
   - 연속 거리 분산, 크기 범위

---

## 📈 성능 메트릭

### 추적 항목
- **데이터 축적**: 전체/검증/미검증
- **GPT-4 정확도**: 난이도/유형 각각
- **자체 모델 정확도**: 테스트/CV
- **분석 방법**: ML/GPT-4/규칙 비율
- **응답 시간**: 평균/최대

### 목표 지표
- **50 피드백**: 자체 모델 학습 시작
- **100 피드백**: ML 정확도 70%+
- **200 피드백**: ML 정확도 80%+
- **500 피드백**: GPT-4 의존도 <10%

---

## 🔐 보안 & 개인정보

### 데이터 처리
- ✅ 이미지는 Base64로 DB 저장
- ✅ 로컬 SQLite (외부 서버 없음)
- ✅ 개인정보 미수집

### API 키 관리
- ✅ 환경변수로만 관리
- ✅ 코드에 하드코딩 금지
- ✅ .gitignore에 .env 추가

---

## 🎯 비즈니스 로직

### 왜 하이브리드 방식인가?

**문제:**
- 공개 클라이밍 데이터셋 없음
- 처음부터 정확한 모델 불가능
- GPT-4만 사용하면 비용 부담

**해결:**
1. **초기**: GPT-4로 정확도 확보
2. **중기**: 사용자 피드백으로 데이터 축적
3. **장기**: 자체 모델로 독립 운영

**결과:**
- ✅ 초기부터 정확한 분석
- ✅ 점진적 비용 감소
- ✅ 장기적으로 완전 무료

---

## 📱 PWA 기능

### 설치
- 홈 화면에 추가 가능
- 네이티브 앱처럼 실행

### 오프라인
- Service Worker 캐싱
- 이전 분석 결과 저장

### 모바일 최적화
- 카메라 직접 사용
- 터치 최적화 UI
- 바텀시트 인터페이스

---

## 🚀 다음 개선 사항

### 우선순위 높음
- [ ] 50개 피드백 수집
- [ ] 자체 모델 첫 학습
- [ ] 정확도 모니터링 대시보드

### 우선순위 중간
- [ ] 벽 각도 자동 감지 (이미지 분석)
- [ ] 홀드 타입 세부 분류 (크림프/쥬그 등)
- [ ] 다중 문제 동시 선택

### 우선순위 낮음
- [ ] 사용자 계정 시스템
- [ ] 소셜 공유 기능
- [ ] 문제 저장/북마크

---

**현재 상태: ✅ 배포 준비 완료**

모든 시스템이 통합되어 즉시 사용 가능합니다!

