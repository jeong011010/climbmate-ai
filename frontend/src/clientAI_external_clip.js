/**
 * ğŸš€ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ AI ì²˜ë¦¬ (YOLO + ì™¸ë¶€ CLIP API)
 * YOLOëŠ” ë¸Œë¼ìš°ì €ì—ì„œ, CLIPì€ ì™¸ë¶€ APIì—ì„œ ì‹¤í–‰
 */

class ClientAIAnalyzer {
  constructor() {
    this.yoloSession = null;
    this.isLoaded = false;
    this.ort = null;
    this.huggingFaceToken = null; // Hugging Face API í† í°
  }

  /**
   * ONNX Runtime ë¡œë“œ
   */
  async loadONNXRuntime() {
    if (this.ort) return this.ort;
    
    console.log('ğŸ“¦ ONNX Runtime ë¡œë”© ì¤‘...');
    const ort = await import('onnxruntime-web');
    this.ort = ort;
    console.log('âœ… ONNX Runtime ë¡œë“œ ì™„ë£Œ');
    return ort;
  }

  /**
   * AI ëª¨ë¸ë“¤ì„ ì‚¬ìš©ì ë¸Œë¼ìš°ì €ì— ë¡œë“œ
   */
  async loadModels() {
    if (this.isLoaded) {
      console.log('âœ… ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
      return;
    }

    try {
      const ort = await this.loadONNXRuntime();
      
      console.log('ğŸš€ AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë”© ì‹œì‘...');
      console.log('â³ YOLOë§Œ ë¸Œë¼ìš°ì €ì—ì„œ ë¡œë“œ (104MB)');
      
      // YOLO ëª¨ë¸ë§Œ ë¡œë“œ
      try {
        console.log('  ğŸ“¦ YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (104MB)');
        this.yoloSession = await ort.InferenceSession.create('/models/yolo.onnx');
        console.log('  âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ');
      } catch (error) {
        console.warn('  âš ï¸ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error.message);
        this.yoloSession = null;
      }
      
      this.isLoaded = true;
      
      if (this.yoloSession) {
        console.log('ğŸ‰ YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! CLIPì€ ì™¸ë¶€ API ì‚¬ìš©');
        return true;
      } else {
        console.log('âš ï¸  YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - ëª¨ì˜ ëª¨ë“œë¡œ ì „í™˜');
        return false;
      }
      
    } catch (error) {
      console.error('âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error);
      this.isLoaded = true;
      return false;
    }
  }

  /**
   * ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
   */
  async imageToTensor(imageElement, targetSize) {
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    
    canvas.width = targetSize;
    canvas.height = targetSize;
    
    ctx.drawImage(imageElement, 0, 0, targetSize, targetSize);
    
    const imageData = ctx.getImageData(0, 0, targetSize, targetSize);
    const { data } = imageData;
    
    const tensor = new Float32Array(3 * targetSize * targetSize);
    
    for (let i = 0; i < targetSize * targetSize; i++) {
      tensor[i] = data[i * 4] / 255.0;
      tensor[targetSize * targetSize + i] = data[i * 4 + 1] / 255.0;
      tensor[2 * targetSize * targetSize + i] = data[i * 4 + 2] / 255.0;
    }
    
    return tensor;
  }

  /**
   * YOLOë¡œ í™€ë“œ ê°ì§€
   */
  async detectHoldsWithYOLO(imageElement) {
    if (!this.yoloSession) {
      return this.detectHoldsMock(imageElement);
    }

    try {
      console.log('ğŸ” YOLOë¡œ í™€ë“œ ê°ì§€ ì¤‘...');
      
      const inputTensor = await this.imageToTensor(imageElement, 640);
      
      const feeds = {
        'images': new this.ort.Tensor('float32', inputTensor, [1, 3, 640, 640])
      };
      
      const results = await this.yoloSession.run(feeds);
      const outputData = results[Object.keys(results)[0]].data;
      
      const holds = this.processYOLOOutput(outputData, imageElement.width, imageElement.height);
      
      console.log(`âœ… YOLO: ${holds.length}ê°œ í™€ë“œ ê°ì§€ ì™„ë£Œ`);
      return holds;
      
    } catch (error) {
      console.error('âŒ YOLO ì¶”ë¡  ì‹¤íŒ¨:', error);
      return this.detectHoldsMock(imageElement);
    }
  }

  /**
   * YOLO ì¶œë ¥ ì²˜ë¦¬
   */
  processYOLOOutput(data, originalWidth, originalHeight) {
    const holds = [];
    const numDetections = Math.min(100, data.length / 6);
    
    for (let i = 0; i < numDetections; i++) {
      const offset = i * 6;
      const confidence = data[offset + 4];
      
      if (confidence > 0.5) {
        const xCenter = data[offset] * originalWidth / 640;
        const yCenter = data[offset + 1] * originalHeight / 640;
        const width = data[offset + 2] * originalWidth / 640;
        const height = data[offset + 3] * originalHeight / 640;
        
        holds.push({
          x: Math.max(0, xCenter - width / 2),
          y: Math.max(0, yCenter - height / 2),
          width: Math.min(width, originalWidth),
          height: Math.min(height, originalHeight),
          confidence: confidence
        });
      }
    }
    
    return holds.slice(0, 20);
  }

  /**
   * Hugging Face CLIP APIë¡œ ìƒ‰ìƒ ë¶„ì„
   */
  async analyzeColorsWithHuggingFace(imageElement, holds) {
    try {
      console.log('ğŸ¨ Hugging Face CLIP APIë¡œ ìƒ‰ìƒ ë¶„ì„ ì¤‘...');
      
      const coloredHolds = [];
      
      for (const hold of holds) {
        // í™€ë“œ ì˜ì—­ ì¶”ì¶œ
        const holdCanvas = this.extractHoldRegion(imageElement, hold, 224);
        const imageData = holdCanvas.toDataURL('image/jpeg', 0.8);
        
        // Hugging Face CLIP API í˜¸ì¶œ
        const response = await fetch('https://api-inference.huggingface.co/models/openai/clip-vit-base-patch32', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.huggingFaceToken || 'YOUR_HF_TOKEN'}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            inputs: {
              image: imageData,
              text: ['red', 'blue', 'yellow', 'green', 'purple', 'orange', 'pink', 'white', 'black']
            }
          })
        });
        
        if (!response.ok) {
          throw new Error(`Hugging Face API error: ${response.status}`);
        }
        
        const result = await response.json();
        
        // ê²°ê³¼ì—ì„œ ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ìƒ‰ìƒ ì„ íƒ
        const bestColor = result.scores ? 
          result.labels[result.scores.indexOf(Math.max(...result.scores))] : 
          'unknown';
        
        coloredHolds.push({
          ...hold,
          color: bestColor
        });
      }
      
      console.log('âœ… Hugging Face CLIP: ìƒ‰ìƒ ë¶„ì„ ì™„ë£Œ');
      return coloredHolds;
      
    } catch (error) {
      console.error('âŒ Hugging Face CLIP API ì‹¤íŒ¨:', error);
      return this.analyzeColorsMock(holds);
    }
  }

  /**
   * í™€ë“œ ì˜ì—­ ì¶”ì¶œ
   */
  extractHoldRegion(imageElement, hold, targetSize) {
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    
    canvas.width = targetSize;
    canvas.height = targetSize;
    
    ctx.drawImage(
      imageElement,
      hold.x, hold.y, hold.width, hold.height,
      0, 0, targetSize, targetSize
    );
    
    return canvas;
  }

  /**
   * ëª¨ì˜ í™€ë“œ ê°ì§€
   */
  detectHoldsMock(imageElement) {
    console.log('ğŸ” ëª¨ì˜ í™€ë“œ ê°ì§€ ì¤‘...');
    
    const holds = [];
    const numHolds = 8 + Math.floor(Math.random() * 8);
    
    for (let i = 0; i < numHolds; i++) {
      holds.push({
        x: Math.random() * imageElement.width * 0.8,
        y: Math.random() * imageElement.height * 0.8,
        width: 30 + Math.random() * 40,
        height: 30 + Math.random() * 40,
        confidence: 0.7 + Math.random() * 0.3
      });
    }
    
    return holds;
  }

  /**
   * ëª¨ì˜ ìƒ‰ìƒ ë¶„ì„
   */
  analyzeColorsMock(holds) {
    console.log('ğŸ¨ ëª¨ì˜ ìƒ‰ìƒ ë¶„ì„ ì¤‘...');
    
    const colors = ['red', 'blue', 'yellow', 'green', 'purple', 'orange', 'pink'];
    
    return holds.map(hold => ({
      ...hold,
      color: colors[Math.floor(Math.random() * colors.length)]
    }));
  }

  /**
   * í™€ë“œë¥¼ ìƒ‰ìƒë³„ë¡œ ê·¸ë£¹í™”
   */
  groupByColor(holds) {
    const groups = {};
    
    for (const hold of holds) {
      if (!groups[hold.color]) {
        groups[hold.color] = [];
      }
      groups[hold.color].push(hold);
    }
    
    return groups;
  }

  /**
   * ìƒ‰ìƒ ê·¸ë£¹ì—ì„œ ë¬¸ì œ ìƒì„±
   */
  generateProblems(colorGroups) {
    const problems = [];
    let problemId = 1;
    
    for (const [color, holds] of Object.entries(colorGroups)) {
      if (holds.length >= 3) {
        const avgConfidence = holds.reduce((sum, h) => sum + h.confidence, 0) / holds.length;
        
        problems.push({
          id: problemId++,
          name: `${(color || 'unknown').toUpperCase()} ë£¨íŠ¸`,
          color: color || 'unknown',
          difficulty: this.calculateDifficulty(holds),
          type: this.guessType(holds),
          confidence: avgConfidence,
          holds: holds.map(h => ({
            x: Math.round(h.x),
            y: Math.round(h.y),
            width: Math.round(h.width),
            height: Math.round(h.height),
            color: h.color || 'unknown',
            confidence: h.confidence
          })),
          statistics: {
            total_holds: holds.length,
            avg_confidence: avgConfidence.toFixed(2)
          }
        });
      }
    }
    
    return problems;
  }

  /**
   * ë‚œì´ë„ ê³„ì‚°
   */
  calculateDifficulty(holds) {
    const count = holds.length;
    
    if (count <= 4) return 'V1-V2';
    if (count <= 7) return 'V3-V4';
    if (count <= 10) return 'V5-V6';
    return 'V7+';
  }

  /**
   * ë¬¸ì œ ìœ í˜• ì¶”ì¸¡
   */
  guessType(holds) {
    const types = ['Balance', 'Power', 'Technique', 'Endurance', 'Coordination'];
    return types[Math.floor(Math.random() * types.length)];
  }

  /**
   * ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤
   */
  async analyzeImage(imageFile) {
    try {
      console.log('ğŸš€ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ AI ë¶„ì„ ì‹œì‘...');
      
      // ëª¨ë¸ ë¡œë”© (YOLOë§Œ)
      const modelsLoaded = await this.loadModels();
      
      // ì´ë¯¸ì§€ ë¡œë“œ
      const imageElement = await this.loadImage(imageFile);
      
      // YOLOë¡œ í™€ë“œ ê°ì§€
      const holds = await this.detectHoldsWithYOLO(imageElement);
      
      // Hugging Face CLIP APIë¡œ ìƒ‰ìƒ ë¶„ì„
      const coloredHolds = await this.analyzeColorsWithHuggingFace(imageElement, holds);
      
      // ìƒ‰ìƒë³„ ê·¸ë£¹í™”
      const colorGroups = this.groupByColor(coloredHolds);
      
      // ë¬¸ì œ ìƒì„±
      const problems = this.generateProblems(colorGroups);
      
      const result = {
        problems: problems,
        statistics: {
          total_holds: coloredHolds.length,
          total_problems: problems.length,
          color_groups: Object.keys(colorGroups).length,
          analysis_method: modelsLoaded ? 'client_yolo_external_clip' : 'client_side_mock'
        },
        message: `í´ë¼ì´ì–¸íŠ¸ ë¶„ì„ ì™„ë£Œ ${modelsLoaded ? '(YOLO + ì™¸ë¶€ CLIP API)' : '(ëª¨ì˜ ë°ì´í„°)'}`,
        note: modelsLoaded 
          ? 'âœ… ë¸Œë¼ìš°ì €ì—ì„œ YOLO ì‹¤í–‰ + ì™¸ë¶€ CLIP API ì‚¬ìš©'
          : 'âš ï¸ AI ëª¨ë¸ íŒŒì¼ì´ ì—†ì–´ ëª¨ì˜ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.'
      };
      
      console.log('âœ… í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ ë¶„ì„ ì™„ë£Œ!', result);
      return result;
      
    } catch (error) {
      console.error('âŒ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ ë¶„ì„ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * ì´ë¯¸ì§€ ë¡œë“œ í—¬í¼
   */
  loadImage(file) {
    return new Promise((resolve, reject) => {
      const img = new Image();
      img.onload = () => resolve(img);
      img.onerror = () => reject(new Error('ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨'));
      
      if (file instanceof File || file instanceof Blob) {
        img.src = URL.createObjectURL(file);
      } else {
        reject(new Error('ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ íŒŒì¼'));
      }
    });
  }
}

export default ClientAIAnalyzer;
