"""
PyTorch YOLO + CLIP ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜
ONNX Runtime Webìœ¼ë¡œ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰
"""
import os
import sys
import torch

def export_yolo_to_onnx():
    """YOLO ëª¨ë¸ì„ ONNXë¡œ ë‚´ë³´ë‚´ê¸°"""
    print("=" * 80)
    print("ğŸ”„ YOLO ëª¨ë¸ â†’ ONNX ë³€í™˜")
    print("=" * 80)
    
    try:
        from ultralytics import YOLO
        
        # ì»¤ìŠ¤í…€ YOLO ëª¨ë¸ ë¡œë“œ
        yolo_path = "holdcheck/roboflow_weights/weights.pt"
        if not os.path.exists(yolo_path):
            print(f"âš ï¸  ì»¤ìŠ¤í…€ ëª¨ë¸ ì—†ìŒ: {yolo_path}")
            yolo_path = "yolov8n.pt"
            print(f"ğŸ“¦ YOLOv8n ë‹¤ìš´ë¡œë“œ ë° ì‚¬ìš©")
        else:
            print(f"ğŸ“‚ ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš©: {yolo_path}")
        
        model = YOLO(yolo_path)
        
        # ONNXë¡œ ë‚´ë³´ë‚´ê¸°
        print(f"ğŸ”„ ONNX ë³€í™˜ ì¤‘... (img_size=640)")
        output_dir = "frontend/public/models"
        os.makedirs(output_dir, exist_ok=True)
        
        # export() ë©”ì„œë“œ ì‚¬ìš©
        model.export(
            format="onnx",
            imgsz=640,
            simplify=True,
            dynamic=True
        )
        
        # ìƒì„±ëœ ONNX íŒŒì¼ ì°¾ê¸°
        onnx_files = [f for f in os.listdir('.') if f.endswith('.onnx')]
        if onnx_files:
            src_file = onnx_files[0]
            dst_file = os.path.join(output_dir, "yolo.onnx")
            
            if os.path.exists(src_file):
                os.rename(src_file, dst_file)
                size = os.path.getsize(dst_file) / (1024 * 1024)
                print(f"âœ… YOLO ONNX ë³€í™˜ ì™„ë£Œ!")
                print(f"ğŸ“¦ íŒŒì¼: {dst_file} ({size:.1f}MB)")
                return True
        
        print(f"âŒ ONNX íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
        return False
            
    except Exception as e:
        print(f"âŒ YOLO ë³€í™˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def export_clip_to_onnx():
    """CLIP ëª¨ë¸ì„ ONNXë¡œ ë‚´ë³´ë‚´ê¸°"""
    print("\n" + "=" * 80)
    print("ğŸ”„ CLIP ëª¨ë¸ â†’ ONNX ë³€í™˜")
    print("=" * 80)
    
    try:
        import clip
        
        # CLIP ëª¨ë¸ ë¡œë“œ
        print("ğŸ“¦ CLIP ëª¨ë¸ ë¡œë“œ ì¤‘... (ViT-B/32)")
        device = "cpu"
        model, preprocess = clip.load("ViT-B/32", device=device)
        model.eval()
        
        # Visual encoderë§Œ ë‚´ë³´ë‚´ê¸°
        print("ğŸ”„ Visual Encoder ONNX ë³€í™˜ ì¤‘...")
        
        dummy_input = torch.randn(1, 3, 224, 224)
        output_path = "frontend/public/models/clip.onnx"
        
        torch.onnx.export(
            model.visual,
            dummy_input,
            output_path,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            },
            opset_version=13,
            do_constant_folding=True
        )
        
        if os.path.exists(output_path):
            size = os.path.getsize(output_path) / (1024 * 1024)
            print(f"âœ… CLIP ONNX ë³€í™˜ ì™„ë£Œ!")
            print(f"ğŸ“¦ íŒŒì¼: {output_path} ({size:.1f}MB)")
            return True
        else:
            print(f"âŒ ONNX íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        print(f"âŒ CLIP ë³€í™˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_model_info():
    """ëª¨ë¸ ì •ë³´ JSON ìƒì„±"""
    print("\n" + "=" * 80)
    print("ğŸ“ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ìƒì„±")
    print("=" * 80)
    
    import json
    
    model_info = {
        "yolo": {
            "format": "onnx",
            "path": "/models/yolo.onnx",
            "input_shape": [1, 3, 640, 640],
            "description": "ì»¤ìŠ¤í…€ YOLO í™€ë“œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸",
            "runtime": "onnxruntime-web"
        },
        "clip": {
            "format": "onnx",
            "path": "/models/clip.onnx",
            "input_shape": [1, 3, 224, 224],
            "model": "ViT-B/32",
            "description": "CLIP ìƒ‰ìƒ ë¶„ì„ ëª¨ë¸ (Visual Encoder)",
            "runtime": "onnxruntime-web"
        },
        "usage": {
            "library": "onnxruntime-web",
            "install": "npm install onnxruntime-web",
            "note": "ONNX Runtime Webì„ ì‚¬ìš©í•˜ì—¬ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰"
        }
    }
    
    info_path = "frontend/public/models/model_info.json"
    os.makedirs(os.path.dirname(info_path), exist_ok=True)
    
    with open(info_path, 'w', encoding='utf-8') as f:
        json.dump(model_info, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ëª¨ë¸ ì •ë³´ ìƒì„±: {info_path}")
    return True

if __name__ == "__main__":
    print("\n")
    print("=" * 80)
    print("ğŸš€ ClimbMate AI ëª¨ë¸ ONNX ë³€í™˜")
    print("=" * 80)
    print("\n")
    
    # YOLO ë³€í™˜
    yolo_success = export_yolo_to_onnx()
    
    # CLIP ë³€í™˜
    clip_success = export_clip_to_onnx()
    
    # ëª¨ë¸ ì •ë³´ ìƒì„±
    info_success = create_model_info()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n")
    print("=" * 80)
    print("ğŸ“Š ë³€í™˜ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    print(f"  YOLO: {'âœ… ì„±ê³µ' if yolo_success else 'âŒ ì‹¤íŒ¨'}")
    print(f"  CLIP: {'âœ… ì„±ê³µ' if clip_success else 'âŒ ì‹¤íŒ¨'}")
    print(f"  Info: {'âœ… ì„±ê³µ' if info_success else 'âŒ ì‹¤íŒ¨'}")
    print("=" * 80)
    
    if yolo_success and clip_success:
        print("\nğŸ‰ ëª¨ë“  ëª¨ë¸ ë³€í™˜ ì™„ë£Œ!")
        print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. npm install onnxruntime-web")
        print("  2. clientAI.jsì—ì„œ ONNX Runtime ì‚¬ìš©")
        print("  3. frontend ì¬ë¹Œë“œ ë° ë°°í¬")
        print("\n")
    else:
        print("\nâš ï¸  ë³€í™˜ ì‹¤íŒ¨ - ìˆ˜ë™ìœ¼ë¡œ í™•ì¸ í•„ìš”")
        print("\n")
    
    sys.exit(0 if (yolo_success and clip_success) else 1)

