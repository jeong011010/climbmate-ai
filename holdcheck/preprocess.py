import cv2
import numpy as np
import os
import json
from ultralytics import YOLO
import torch
import clip
from PIL import Image
import psutil
import gc

# ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™”: ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
os.environ.setdefault("OMP_NUM_THREADS", "1")
os.environ.setdefault("MKL_NUM_THREADS", "1")
os.environ.setdefault("NUMEXPR_NUM_THREADS", "1")
try:
    torch.set_num_threads(1)
except:
    pass

def get_memory_usage():
    """ğŸ“Š í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (MB ë‹¨ìœ„)"""
    process = psutil.Process()
    memory_info = process.memory_info()
    return {
        'rss': memory_info.rss / 1024 / 1024,  # ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
        'vms': memory_info.vms / 1024 / 1024,  # ê°€ìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
        'percent': process.memory_percent(),    # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ëŒ€ë¹„ ë¹„ìœ¨
        'available': psutil.virtual_memory().available / 1024 / 1024  # ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (MB)
    }

def log_memory_usage(stage_name):
    """ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê·¸ ì¶œë ¥"""
    memory = get_memory_usage()
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì— ë”°ë¥¸ ê²½ê³ 
    if memory['percent'] > 90:
        print(f"ğŸš¨ [CRITICAL] [{stage_name}] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 90%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!")
        print(f"   ğŸ”´ ì‹¤ì œ ë©”ëª¨ë¦¬: {memory['rss']:.1f}MB ({memory['percent']:.1f}%)")
        print(f"   âš ï¸  OOM ìœ„í—˜! ì»¨í…Œì´ë„ˆê°€ ì¢…ë£Œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    elif memory['percent'] > 80:
        print(f"âš ï¸  [WARNING] [{stage_name}] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 80%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!")
        print(f"   ğŸŸ¡ ì‹¤ì œ ë©”ëª¨ë¦¬: {memory['rss']:.1f}MB ({memory['percent']:.1f}%)")
    else:
        print(f"ğŸ“Š [{stage_name}] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
        print(f"   ğŸ”¸ ì‹¤ì œ ë©”ëª¨ë¦¬: {memory['rss']:.1f}MB ({memory['percent']:.1f}%)")
    
    print(f"   ğŸ”¸ ê°€ìƒ ë©”ëª¨ë¦¬: {memory['vms']:.1f}MB")
    print(f"   ğŸ”¸ ì‚¬ìš© ê°€ëŠ¥: {memory['available']:.1f}MB")
    return memory

def convert_to_json_safe(data):
    """ğŸš€ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë°ì´í„° ë³€í™˜"""
    if isinstance(data, np.integer):
        return int(data)
    elif isinstance(data, np.floating):
        return float(data)
    elif isinstance(data, np.ndarray):
        return data.tolist()
    elif isinstance(data, dict):
        return {key: convert_to_json_safe(value) for key, value in data.items()}
    elif isinstance(data, list):
        return [convert_to_json_safe(item) for item in data]
    elif isinstance(data, tuple):
        return [convert_to_json_safe(item) for item in data]
    else:
        return data
from sklearn.cluster import KMeans

# -------------------------------
# ğŸš€ ëª¨ë¸ ì‹±ê¸€í†¤ (ìºì‹±) - ì„±ëŠ¥ ìµœì í™”
# -------------------------------
_clip_model = None
_clip_preprocess = None
_clip_device = None
_yolo_model = None
_yolo_model_path = None

def get_yolo_model(model_path="/app/holdcheck/roboflow_weights/weights.pt"):
    """ğŸš€ YOLO ëª¨ë¸ì„ ì‹±ê¸€í†¤ìœ¼ë¡œ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½ + ì†ë„ í–¥ìƒ)"""
    global _yolo_model, _yolo_model_path
    
    if _yolo_model is None or _yolo_model_path != model_path:
        print(f"ğŸ” YOLO ëª¨ë¸ ë¡œë”© ì¤‘... ({model_path})")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ë¡œë”© ì „)
        memory_before = log_memory_usage("YOLO ë¡œë”© ì „")
        
        # ê²½ëŸ‰ YOLO ëª¨ë¸ ì‚¬ìš© (nano ë²„ì „)
        if not os.path.exists(model_path):
            print(f"âš ï¸ ì»¤ìŠ¤í…€ ëª¨ë¸ ì—†ìŒ: {model_path}")
            print("ğŸ“¦ ê²½ëŸ‰ YOLOv8n ëª¨ë¸ ì‚¬ìš©")
            _yolo_model = YOLO('yolov8n.pt')  # nano ë²„ì „ (6MB vs 50MB)
        else:
            print(f"ğŸ“¦ ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš©: {model_path}")
            _yolo_model = YOLO(model_path)
        _yolo_model_path = model_path
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ë¡œë”© í›„)
        memory_after = log_memory_usage("YOLO ë¡œë”© í›„")
        
        # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ ê³„ì‚°
        memory_increase = memory_after['rss'] - memory_before['rss']
        print(f"ğŸ“Š YOLO ëª¨ë¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: +{memory_increase:.1f}MB")
        
        print(f"âœ… YOLO ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    
    return _yolo_model

def get_clip_model():
    """ğŸ¤– CLIP ëª¨ë¸ì„ ì‹±ê¸€í†¤ìœ¼ë¡œ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½)"""
    global _clip_model, _clip_preprocess, _clip_device
    
    if _clip_model is None:
        print("ğŸ¤– CLIP ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ë¡œë”© ì „)
        memory_before = log_memory_usage("CLIP ë¡œë”© ì „")
        
        _clip_device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëª¨ë¸ ì„ íƒ (ê¸°ë³¸ê°’: ê°€ë²¼ìš´ ViT-B/16)
        clip_model_name = os.getenv("CLIP_MODEL", "ViT-B/32")  # ìµœê²½ëŸ‰ ëª¨ë¸ (ê·¹í•œ ë©”ëª¨ë¦¬ ì ˆì•½)
        print(f"ğŸ“Š ì‚¬ìš©í•  CLIP ëª¨ë¸: {clip_model_name}")
        
        _clip_model, _clip_preprocess = clip.load(clip_model_name, device=_clip_device)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ë¡œë”© í›„)
        memory_after = log_memory_usage("CLIP ë¡œë”© í›„")
        
        # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ ê³„ì‚°
        memory_increase = memory_after['rss'] - memory_before['rss']
        print(f"ğŸ“Š CLIP ëª¨ë¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: +{memory_increase:.1f}MB")
        
        print(f"âœ… CLIP ëª¨ë¸ ë¡œë”© ì™„ë£Œ (Device: {_clip_device})")
    
    return _clip_model, _clip_preprocess, _clip_device

# -------------------------------
# ğŸ¤– CLIP AI ê¸°ë°˜ ìƒ‰ìƒ ì¶”ì¶œ
# -------------------------------
def extract_color_with_clip_ai(image, mask):
    """
    ğŸ¤– CLIP AIë¥¼ ì‚¬ìš©í•´ì„œ í™€ë“œì˜ ìƒ‰ìƒì„ ì§ì ‘ ì¶”ì¶œ
    
    Args:
        image: ì›ë³¸ ì´ë¯¸ì§€ (BGR)
        mask: í™€ë“œ ë§ˆìŠ¤í¬ (0/1)
    
    Returns:
        color_name: ì¸ì‹ëœ ìƒ‰ìƒ ì´ë¦„ (ì˜ˆ: "yellow", "red")
        confidence: ì‹ ë¢°ë„ (0~1)
        rgb: ëŒ€í‘œ RGB ê°’
        hsv: ëŒ€í‘œ HSV ê°’
        clip_features: CLIP íŠ¹ì§• ë²¡í„° (512ì°¨ì›)
    """
    model, preprocess, device = get_clip_model()
    
    # í™€ë“œ ì˜ì—­ ì¶”ì¶œ
    y_coords, x_coords = np.where(mask > 0)
    if len(y_coords) == 0:
        return "unknown", 0.0, [128, 128, 128], [0, 0, 128], np.zeros(512)
    
    y_min, y_max = y_coords.min(), y_coords.max()
    x_min, x_max = x_coords.min(), x_coords.max()
    
    # í™€ë“œ í¬ë¡­
    hold_image = image[y_min:y_max+1, x_min:x_max+1]
    hold_pil = Image.fromarray(cv2.cvtColor(hold_image, cv2.COLOR_BGR2RGB))
    
    # ğŸ”§ ë§ˆìŠ¤í¬ ì¹¨ë²” ë°©ì§€: mask_core ìƒì„±
    mask_area = mask[y_min:y_max+1, x_min:x_max+1]
    kernel_size = max(3, min(mask_area.shape) // 10)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    mask_core = cv2.erode((mask_area * 255).astype(np.uint8), kernel, iterations=2)
    mask_core = (mask_core > 127).astype(np.float32)
    
    # ìƒ‰ìƒ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ê²€ì •ìƒ‰ ìš°ì„ , ì£¼í™©ìƒ‰ ê°•í™”)
    color_prompts = [
        "a black climbing hold", "a very dark black climbing hold", "a dark black climbing hold",  # ê²€ì •ìƒ‰ ìµœìš°ì„ 
        "a bright orange climbing hold",
        "a dark orange climbing hold",
        "an orange climbing hold",
        "a bright yellow climbing hold",
        "a yellow climbing hold",
        "a light yellow climbing hold",
        "a dark yellow climbing hold",
        "a red climbing hold", 
        "a dark red climbing hold",
        "a blue climbing hold",
        "a light blue climbing hold",
        "a dark blue climbing hold",
        "a green climbing hold",
        "a light green climbing hold",
        "a dark green climbing hold",
        "a purple climbing hold",
        "a pink climbing hold",
        "a white climbing hold",
        "a gray climbing hold",
        "a brown climbing hold"
    ]
    
    # ìƒ‰ìƒ ë§¤í•‘ (ê²€ì •ìƒ‰ ìš°ì„ )
    color_map = {
        "black": ["black", "very dark black", "dark black"],  # ê²€ì •ìƒ‰ ìµœìš°ì„ 
        "orange": ["orange", "bright orange", "dark orange"],
        "yellow": ["yellow", "light yellow", "dark yellow", "bright yellow"],
        "red": ["red", "dark red"],
        "blue": ["blue", "light blue", "dark blue"],
        "green": ["green", "light green", "dark green"],
        "purple": ["purple"],
        "pink": ["pink"],
        "white": ["white"],
        "gray": ["gray"],
        "brown": ["brown"]
    }
    
    # í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ
    text_tokens = clip.tokenize(color_prompts).to(device)
    with torch.no_grad():
        text_features = model.encode_text(text_tokens)
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)
        
        # ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
        image_input = preprocess(hold_pil).unsqueeze(0).to(device)
        image_features = model.encode_image(image_input)
        image_features = image_features / image_features.norm(dim=-1, keepdim=True)
    
    # ğŸ¯ ê²€ì •ìƒ‰ í™€ë“œ ì‚¬ì „ ê°ì§€ (ê°œë³„ í•¨ìˆ˜ìš©) - ë‹¤ë‹¨ê³„ ë¡œì§
    pixels = hold_image[mask_core > 0]
    is_black_candidate = False
    black_confidence_level = "low"
    
    if len(pixels) > 10:
        avg_rgb = np.mean(pixels, axis=0)
        avg_brightness = np.mean(avg_rgb)
        max_rgb = np.max(avg_rgb)
        
        # RGB í‘œì¤€í¸ì°¨ì™€ ì±„ë„ ì°¨ì´ ê³„ì‚°
        rgb_std = np.std(pixels, axis=0)
        avg_std = np.mean(rgb_std)
        channel_diff = np.max(avg_rgb) - np.min(avg_rgb)
        
        # 1ë‹¨ê³„: ì§„ì§œ ê²€ì •ìƒ‰ (ë§¤ìš° ì–´ë‘ì›€)
        if avg_brightness <= 80 and max_rgb <= 100:
            is_black_candidate = True
            black_confidence_level = "very_high"
            print(f"   ğŸ–¤ ê°œë³„ í•¨ìˆ˜: ì§„ì§œ ê²€ì •ìƒ‰ (í‰ê· : {avg_brightness:.1f}, ìµœëŒ€: {max_rgb:.1f})")
        
        # 2ë‹¨ê³„: ëª¨ë“  ë°ê¸°ì—ì„œ ìƒ‰ìƒ íŠ¹ì„± ê¸°ë°˜ íŒë³„ (ê°œë³„ í•¨ìˆ˜)
        else:
            # ğŸš¨ ìƒ‰ìƒ íŠ¹ì„± ì²´í¬: ë¬´ì±„ìƒ‰ì¸ì§€ í™•ì¸
            r, g, b = avg_rgb[0], avg_rgb[1], avg_rgb[2]
            
            # ë³´ë¼ìƒ‰ íŠ¹ì„± ì²´í¬: Redì™€ Blueê°€ ë†’ê³  Greenì´ ë‚®ìŒ (ë” ì™„í™”)
            is_purple = (r > g + 3 and b > g + 3)
            
            # ë…¸ë€ìƒ‰ íŠ¹ì„± ì²´í¬: Redì™€ Greenì´ ë†’ê³  Blueê°€ ë‚®ìŒ (ë” ì™„í™”)
            is_yellow = (r > b + 3 and g > b + 3)
            
            # íŒŒë€ìƒ‰ íŠ¹ì„± ì²´í¬: Blueê°€ ë‹¤ë¥¸ ì±„ë„ë³´ë‹¤ ë†’ìŒ (ì™„í™”)
            is_blue = (b > r + 10 and b > g + 10)
            
            # ë¹¨ê°„ìƒ‰ íŠ¹ì„± ì²´í¬: Redê°€ ë‹¤ë¥¸ ì±„ë„ë³´ë‹¤ ë†’ìŒ (ì™„í™”)
            is_red = (r > g + 10 and r > b + 10)
            
            # ì´ˆë¡ìƒ‰ íŠ¹ì„± ì²´í¬: Greenì´ ë‹¤ë¥¸ ì±„ë„ë³´ë‹¤ ë†’ìŒ (ì™„í™”)
            is_green = (g > r + 10 and g > b + 10)
            
            # ğŸ¯ ë¬´ì±„ìƒ‰(ê²€ì •ìƒ‰/íšŒìƒ‰/í°ìƒ‰) ì¡°ê±´: ìƒ‰ìƒ íŠ¹ì„±ì´ ì—†ê³  ì±„ë„ ì°¨ì´ê°€ ì‘ìŒ
            is_achromatic = not (is_purple or is_yellow or is_blue or is_red or is_green)
            
            # ë¬´ì±„ìƒ‰ì´ë©´ ê²€ì •ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ (ë°ê¸° ë¬´ê´€)
            if is_achromatic and channel_diff < 50:
                is_black_candidate = True
                black_confidence_level = "high"
                print(f"   ğŸ–¤ ê°œë³„ í•¨ìˆ˜: ë¬´ì±„ìƒ‰ ê²€ì •ìƒ‰ (RGB: {avg_rgb}, ì±„ë„ì°¨: {channel_diff:.1f}, ë°ê¸°: {avg_brightness:.1f})")
            elif is_purple:
                print(f"   ğŸ’œ ê°œë³„ í•¨ìˆ˜: ë³´ë¼ìƒ‰ íŠ¹ì„± ê°ì§€ (RGB: {avg_rgb}) - ê²€ì •ìƒ‰ ì œì™¸")
            elif is_yellow:
                print(f"   ğŸ’› ê°œë³„ í•¨ìˆ˜: ë…¸ë€ìƒ‰ íŠ¹ì„± ê°ì§€ (RGB: {avg_rgb}) - ê²€ì •ìƒ‰ ì œì™¸")
            elif is_blue:
                print(f"   ğŸ’™ ê°œë³„ í•¨ìˆ˜: íŒŒë€ìƒ‰ íŠ¹ì„± ê°ì§€ (RGB: {avg_rgb}) - ê²€ì •ìƒ‰ ì œì™¸")
            elif is_red:
                print(f"   â¤ï¸ ê°œë³„ í•¨ìˆ˜: ë¹¨ê°„ìƒ‰ íŠ¹ì„± ê°ì§€ (RGB: {avg_rgb}) - ê²€ì •ìƒ‰ ì œì™¸")
            elif is_green:
                print(f"   ğŸ’š ê°œë³„ í•¨ìˆ˜: ì´ˆë¡ìƒ‰ íŠ¹ì„± ê°ì§€ (RGB: {avg_rgb}) - ê²€ì •ìƒ‰ ì œì™¸")
    
    # ìœ ì‚¬ë„ ê³„ì‚°
    similarities = (image_features @ text_features.T).squeeze().cpu().numpy()
    
    # ğŸ¯ ê²€ì •ìƒ‰ í›„ë³´ ê°•ì œ ë¶„ë¥˜ (ì‹ ë¢°ë„ë³„)
    if is_black_candidate:
        if black_confidence_level == "very_high":
            confidence = 0.98
        elif black_confidence_level == "high":
            confidence = 0.95
        else:  # medium
            confidence = 0.90
            
        color_name = "black"
        print(f"   âœ… ê²€ì •ìƒ‰ìœ¼ë¡œ ê°•ì œ ë¶„ë¥˜ (ê°œë³„ í•¨ìˆ˜, ì‹ ë¢°ë„: {black_confidence_level})")
    else:
        # ê°€ì¥ ìœ ì‚¬í•œ ìƒ‰ìƒ ì„ íƒ
        best_idx = np.argmax(similarities)
        confidence = float(similarities[best_idx])
        best_prompt = color_prompts[best_idx]
        
        # ìƒ‰ìƒ ì´ë¦„ ì¶”ì¶œ
        color_name = "unknown"
        for color, keywords in color_map.items():
            if any(keyword in best_prompt for keyword in keywords):
                color_name = color
                break
    
    # ğŸ¯ ë§ˆìŠ¤í¬ ì¹¨ë²” ë°©ì§€: ì¤‘ì‹¬ë¶€ í”½ì…€ë§Œ ì‚¬ìš© (ê²½ê³„ ì œì™¸)
    mask_area = mask[y_min:y_max+1, x_min:x_max+1]
    
    # ëª¨í´ë¡œì§€ ì¹¨ì‹ìœ¼ë¡œ ê²½ê³„ ì œê±° (ì¹¨ë²” ë°©ì§€)
    kernel_size = max(3, min(mask_area.shape) // 10)  # ë§ˆìŠ¤í¬ í¬ê¸°ì˜ 10%
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    mask_core = cv2.erode((mask_area * 255).astype(np.uint8), kernel, iterations=2)
    mask_core = (mask_core > 127).astype(np.float32)
    
    # ì¤‘ì‹¬ë¶€ í”½ì…€ ì¶”ì¶œ
    pixels = hold_image[mask_core > 0]
    
    if len(pixels) > 10:  # ì¶©ë¶„í•œ í”½ì…€ì´ ìˆì„ ë•Œë§Œ
        # ë°ì€ í”½ì…€ë§Œ ì„ íƒ (ìƒìœ„ 30%)
        pixels_hsv = cv2.cvtColor(hold_image, cv2.COLOR_BGR2HSV)[mask_core > 0]
        brightness = pixels_hsv[:, 2]
        bright_threshold = np.percentile(brightness, 70)
        bright_mask = brightness >= bright_threshold
        
        if np.sum(bright_mask) > 10:
            pixels = pixels[bright_mask]
            pixels_hsv = pixels_hsv[bright_mask]
        
        # RGB/HSV í‰ê· 
        rgb = np.mean(pixels, axis=0).astype(int)[::-1]  # BGR -> RGB
        hsv = np.mean(pixels_hsv, axis=0).astype(int)
    else:
        # ì¤‘ì‹¬ë¶€ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ì›ë³¸ ë§ˆìŠ¤í¬ ì‚¬ìš©
        pixels = hold_image[mask_area > 0]
        if len(pixels) > 0:
            pixels_hsv = cv2.cvtColor(hold_image, cv2.COLOR_BGR2HSV)[mask_area > 0]
            rgb = np.mean(pixels, axis=0).astype(int)[::-1]
            hsv = np.mean(pixels_hsv, axis=0).astype(int)
        else:
            rgb = [128, 128, 128]
            hsv = [0, 0, 128]
    
    # CLIP íŠ¹ì§• ë²¡í„° ë°˜í™˜
    clip_features = image_features.squeeze().cpu().numpy()
    
    print(f"   ğŸ¨ CLIP AI: {color_name} (ì‹ ë¢°ë„: {confidence:.3f})")
    
    return color_name, confidence, rgb.tolist(), hsv.tolist(), clip_features

def extract_colors_with_clip_ai_batch(hold_images, masks):
    """
    ğŸš€ CLIP AI ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ í™€ë“œì˜ ìƒ‰ìƒì„ í•œ ë²ˆì— ì¶”ì¶œ
    
    Args:
        hold_images: í™€ë“œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (BGR)
        masks: í™€ë“œ ë§ˆìŠ¤í¬ ë¦¬ìŠ¤íŠ¸ (0/1)
    
    Returns:
        results: ê° í™€ë“œë³„ (color_name, confidence, rgb, hsv, clip_features) ë¦¬ìŠ¤íŠ¸
    """
    if not hold_images:
        return []
    
    model, preprocess, device = get_clip_model()
    
    # ğŸš€ ì„±ëŠ¥ ìµœì í™”: ê²€ì •ìƒ‰ ì‚¬ì „ ê°ì§€ë¥¼ ìµœëŒ€í•œ ê°„ì†Œí™” (ì†ë„ ìš°ì„ )
    black_candidates = []
    
    for i, (image, mask) in enumerate(zip(hold_images, masks)):
        # ğŸš€ ë¹ ë¥¸ ìƒ˜í”Œë§: ë§ˆìŠ¤í¬ì—ì„œ ì„ì˜ë¡œ 100ê°œ í”½ì…€ë§Œ ì¶”ì¶œ
        y_coords, x_coords = np.where(mask > 0)
        if len(y_coords) == 0:
            continue
        
        # ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ì†ë„ í–¥ìƒ
        sample_count = min(100, len(y_coords))
        sample_indices = np.random.choice(len(y_coords), sample_count, replace=False)
        sampled_y = y_coords[sample_indices]
        sampled_x = x_coords[sample_indices]
        
        pixels = image[sampled_y, sampled_x]
        if len(pixels) > 10:
            # ğŸš€ ê·¹ë‹¨ì  ìµœì í™”: ë§¤ìš° ê°„ë‹¨í•œ ê²€ì •ìƒ‰ ê°ì§€ë§Œ ìˆ˜í–‰
            avg_rgb = np.mean(pixels, axis=0)
            avg_brightness = np.mean(avg_rgb)
            channel_diff = np.max(avg_rgb) - np.min(avg_rgb)
            
            # ê²€ì •ìƒ‰ í›„ë³´: ì–´ë‘¡ê³ (< 80) ë¬´ì±„ìƒ‰(ì±„ë„ì°¨ < 30)
            if avg_brightness < 80 and channel_diff < 30:
                black_candidates.append((i, "high"))
    
    # ìƒ‰ìƒ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ë‹¤ì–‘í•œ í‘œí˜„ ìœ ì§€)
    color_prompts = [
        "a black climbing hold", "a very dark black climbing hold", "a dark black climbing hold",
        "a white climbing hold", "a bright white climbing hold", "a pure white climbing hold",
        "a gray climbing hold", "a light gray climbing hold", "a dark gray climbing hold",
        "an orange climbing hold", "a bright orange climbing hold", "a dark orange climbing hold",
        "a yellow climbing hold", "a bright yellow climbing hold", "a lemon yellow climbing hold", "a golden yellow climbing hold",
        "a red climbing hold", "a bright red climbing hold", "a dark red climbing hold",
        "a pink climbing hold", "a hot pink climbing hold",
        "a blue climbing hold", "a light blue climbing hold", "a sky blue climbing hold",
        "a green climbing hold", "a bright green climbing hold", "a forest green climbing hold",
        "a mint climbing hold", "a mint green climbing hold", "a turquoise mint climbing hold",
        "a lime climbing hold", "a lime green climbing hold", "a neon lime climbing hold",
        "a purple climbing hold", "a bright purple climbing hold", "a violet climbing hold",
        "a brown climbing hold", "a dark brown climbing hold"
    ]
    
    color_map = {
        "black": ["black", "very dark black", "dark black"],
        "white": ["white", "bright white", "pure white"],
        "gray": ["gray", "light gray", "dark gray"],
        "orange": ["orange", "bright orange", "dark orange"],
        "yellow": ["yellow", "bright yellow", "lemon", "golden"],
        "red": ["red", "bright red", "dark red"],
        "pink": ["pink", "hot pink"],
        "blue": ["blue", "light blue", "sky blue"],
        "green": ["green", "bright green", "forest"],
        "mint": ["mint", "mint green", "turquoise mint"],
        "lime": ["lime", "lime green", "neon lime"],
        "purple": ["purple", "bright purple", "violet"],
        "brown": ["brown", "dark brown"]
    }
    
    # í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ (í•œ ë²ˆë§Œ)
    text_tokens = clip.tokenize(color_prompts).to(device)
    with torch.no_grad():
        text_features = model.encode_text(text_tokens)
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)
    
    # ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™”: ë°°ì¹˜ í¬ê¸°ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • (ê¸°ë³¸ê°’: 16)
    batch_size = int(os.getenv("CLIP_BATCH_SIZE", "2"))  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ë” ì‘ê²Œ ì„¤ì •
    print(f"ğŸ“Š CLIP ë°°ì¹˜ í¬ê¸°: {batch_size}")
    
    all_similarities = []
    all_image_features = []
    valid_indices = []
    
    for batch_start in range(0, len(hold_images), batch_size):
        batch_end = min(batch_start + batch_size, len(hold_images))
        batch_images = hold_images[batch_start:batch_end]
        batch_masks = masks[batch_start:batch_end]
        
        processed_images = []
        batch_valid_indices = []
        
        for i, (image, mask) in enumerate(zip(batch_images, batch_masks)):
            actual_idx = batch_start + i
            y_coords, x_coords = np.where(mask > 0)
            if len(y_coords) == 0:
                continue
                
            y_min, y_max = y_coords.min(), y_coords.max()
            x_min, x_max = x_coords.min(), x_coords.max()
            hold_image = image[y_min:y_max+1, x_min:x_max+1]
            hold_pil = Image.fromarray(cv2.cvtColor(hold_image, cv2.COLOR_BGR2RGB))
            processed_images.append(preprocess(hold_pil))
            batch_valid_indices.append(actual_idx)
        
        if not processed_images:
            continue
        
        # ë°°ì¹˜ë¡œ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
        images_tensor = torch.stack(processed_images).to(device)
        
        with torch.no_grad():
            batch_image_features = model.encode_image(images_tensor)
            batch_image_features = batch_image_features / batch_image_features.norm(dim=-1, keepdim=True)
            
            # ìœ ì‚¬ë„ ê³„ì‚° (ë°°ì¹˜)
            batch_similarities = (batch_image_features @ text_features.T).cpu().numpy()
        
        all_similarities.append(batch_similarities)
        all_image_features.append(batch_image_features)
        valid_indices.extend(batch_valid_indices)
        
        # ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™”: ë°°ì¹˜ë§ˆë‹¤ ë©”ëª¨ë¦¬ ì •ë¦¬
        del batch_image_features, batch_similarities, images_tensor
        if 'processed_images' in locals():
            del processed_images
        gc.collect()
    
    if not all_similarities:
        return []
    
    # ëª¨ë“  ë°°ì¹˜ ê²°ê³¼ í•©ì¹˜ê¸°
    similarities = np.vstack(all_similarities)
    image_features = torch.cat(all_image_features, dim=0)
    
    # ê²°ê³¼ ì²˜ë¦¬
    results = []
    for i, orig_idx in enumerate(valid_indices):
        # ì›ë³¸ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ê°€ì ¸ì˜¤ê¸°
        image = hold_images[orig_idx]
        mask = masks[orig_idx]
        
        # ê°€ì¥ ìœ ì‚¬í•œ ìƒ‰ìƒ ì„ íƒ
        best_idx = np.argmax(similarities[i])
        confidence = float(similarities[i][best_idx])
        best_prompt = color_prompts[best_idx]
        
        # ğŸ¯ ê²€ì •ìƒ‰ í›„ë³´ì— ëŒ€í•œ íŠ¹ë³„ ì²˜ë¦¬
        is_black_candidate = False
        black_confidence_level = None
        
        for candidate_idx, conf_level in black_candidates:
            if candidate_idx == orig_idx:
                is_black_candidate = True
                black_confidence_level = conf_level
                break
        
        if is_black_candidate:
            print(f"   ğŸ–¤ í™€ë“œ {orig_idx}: ê²€ì •ìƒ‰ í›„ë³´ ({black_confidence_level}) - ê°•ì œ ê²€ì •ìƒ‰ ë¶„ë¥˜")
            
            # ì‹ ë¢°ë„ì— ë”°ë¥¸ ê°•ì œ ë¶„ë¥˜
            if black_confidence_level == "very_high":
                color_name = "black"
                confidence = 0.98
            elif black_confidence_level == "high":
                color_name = "black"
                confidence = 0.95
            else:  # medium
                color_name = "black"
                confidence = 0.90
            
            print(f"      âœ… ê²€ì •ìƒ‰ìœ¼ë¡œ ê°•ì œ ë¶„ë¥˜ (ì‹ ë¢°ë„: {black_confidence_level}, confidence: {confidence})")
            
            # ì¶”ê°€ ê²€ì¦: ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ ë¶„ë¥˜ë  ê°€ëŠ¥ì„± ì²´í¬
            other_color_similarities = []
            for j, prompt in enumerate(color_prompts):
                if "black" not in prompt.lower():
                    other_color_similarities.append(similarities[i][j])
            
            if other_color_similarities:
                max_other_similarity = max(other_color_similarities)
                if max_other_similarity > 0.3:  # ë‹¤ë¥¸ ìƒ‰ìƒ ìœ ì‚¬ë„ê°€ ë†’ìœ¼ë©´ ê²½ê³ 
                    print(f"      âš ï¸ ë‹¤ë¥¸ ìƒ‰ìƒ ìœ ì‚¬ë„ë„ ë†’ìŒ: {max_other_similarity:.3f}")
        else:
            # ì¼ë°˜ í™€ë“œ ì²˜ë¦¬
            color_name = "unknown"
            for color, keywords in color_map.items():
                if any(keyword in best_prompt for keyword in keywords):
                    color_name = color
                    break
        
        # RGB/HSV ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
        y_coords, x_coords = np.where(mask > 0)
        y_min, y_max = y_coords.min(), y_coords.max()
        x_min, x_max = x_coords.min(), x_coords.max()
        hold_image = image[y_min:y_max+1, x_min:x_max+1]
        
        # ë§ˆìŠ¤í¬ ì¹¨ë²” ë°©ì§€ ë¡œì§
        mask_area = mask[y_min:y_max+1, x_min:x_max+1]
        kernel_size = max(3, min(mask_area.shape) // 10)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
        mask_core = cv2.erode((mask_area * 255).astype(np.uint8), kernel, iterations=2)
        mask_core = (mask_core > 127).astype(np.float32)
        
        pixels = hold_image[mask_core > 0]
        if len(pixels) > 10:
            pixels_hsv = cv2.cvtColor(hold_image, cv2.COLOR_BGR2HSV)[mask_core > 0]
            brightness = pixels_hsv[:, 2]
            bright_threshold = np.percentile(brightness, 70)
            bright_mask = brightness >= bright_threshold
            
            if np.sum(bright_mask) > 10:
                pixels = pixels[bright_mask]
                pixels_hsv = pixels_hsv[bright_mask]
            
            rgb = np.mean(pixels, axis=0).astype(int)[::-1]  # BGR -> RGB
            hsv = np.mean(pixels_hsv, axis=0).astype(int)
        else:
            rgb = [128, 128, 128]
            hsv = [0, 0, 128]
        
        results.append((color_name, confidence, rgb.tolist(), hsv.tolist(), image_features[i].cpu().numpy()))
    
    return results

# -------------------------------
# ğŸ“Œ Resize + Padding
# -------------------------------
def resize_with_padding(image, target_size=(640, 640), pad_color=(255, 255, 255)):
    h, w = image.shape[:2]
    target_w, target_h = target_size
    scale = min(target_w / w, target_h / h)
    new_w, new_h = int(w * scale), int(h * scale)
    resized = cv2.resize(image, (new_w, new_h))
    pad_left = (target_w - new_w) // 2
    pad_top = (target_h - new_h) // 2
    pad_right = target_w - new_w - pad_left
    pad_bottom = target_h - new_h - pad_top
    padded = cv2.copyMakeBorder(resized, pad_top, pad_bottom, pad_left, pad_right,
                                borderType=cv2.BORDER_CONSTANT, value=pad_color)
    return padded, scale, pad_left, pad_top

# -------------------------------
# ğŸ“Œ ì›ë³¸ í¬ê¸° ë³µì›
# -------------------------------
def restore_mask_to_original(mask, original_shape, scale, pad_left, pad_top):
    h_ori, w_ori = original_shape
    unpadded = mask[pad_top:pad_top + int(h_ori * scale), pad_left:pad_left + int(w_ori * scale)]
    restored = cv2.resize(unpadded, (w_ori, h_ori), interpolation=cv2.INTER_NEAREST)
    return restored

# -------------------------------
# ğŸ“Œ ëŒ€í‘œìƒ‰ ì¶”ì¶œ (Dominant Color) - ì•™ìƒë¸” ë°©ì‹
# -------------------------------
def remove_outliers(pixels, percentile=5):
    """ì•„ì›ƒë¼ì´ì–´ ì œê±° (ìƒìœ„/í•˜ìœ„ 5%)"""
    if len(pixels) == 0:
        return pixels
    lower = np.percentile(pixels, percentile, axis=0)
    upper = np.percentile(pixels, 100 - percentile, axis=0)
    mask = np.all((pixels >= lower) & (pixels <= upper), axis=1)
    return pixels[mask]

def refine_mask_boundary(mask, kernel_size=3, iterations=2):
    """ë§ˆìŠ¤í¬ ê²½ê³„ ì •ì œ - ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ"""
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    
    # ë‹«í˜ ì—°ì‚° (êµ¬ë© ë©”ìš°ê¸°)
    closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=iterations)
    
    # ì—´ë¦¼ ì—°ì‚° (ë…¸ì´ì¦ˆ ì œê±°)
    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=1)
    
    return opened

def detect_background_color(image, masks):
    """ë°°ê²½ìƒ‰ ìë™ ê°ì§€ - ë‚˜ë¬´ ë²½ë©´ ìƒ‰ìƒ ì¶”ì¶œ"""
    if len(masks) == 0:
        return None
    
    # ëª¨ë“  í™€ë“œ ë§ˆìŠ¤í¬ë¥¼ í•©ì³ì„œ ë°°ê²½ ì˜ì—­ ì°¾ê¸°
    all_holds_mask = np.zeros(image.shape[:2], dtype=np.uint8)
    for mask in masks:
        all_holds_mask = cv2.bitwise_or(all_holds_mask, (mask * 255).astype(np.uint8))
    
    # ë°°ê²½ ì˜ì—­ (í™€ë“œê°€ ì•„ë‹Œ ë¶€ë¶„)
    background_mask = cv2.bitwise_not(all_holds_mask)
    
    # ë°°ê²½ì—ì„œ ìƒ˜í”Œë§
    background_pixels = image[background_mask > 0]
    
    if len(background_pixels) > 100:
        # ë°°ê²½ìƒ‰ì˜ í‰ê· ê°’ ê³„ì‚°
        background_hsv = cv2.cvtColor(background_pixels.reshape(-1, 1, 3), cv2.COLOR_BGR2HSV)
        avg_background_hsv = np.mean(background_hsv, axis=0)[0]
        
        print(f"ğŸ¨ ë°°ê²½ìƒ‰ ê°ì§€: HSV({avg_background_hsv[0]:.1f}, {avg_background_hsv[1]:.1f}, {avg_background_hsv[2]:.1f})")
        return avg_background_hsv
    
    return None

def filter_background_pixels(pixels_hsv, background_hsv, threshold=30):
    """ë°°ê²½ìƒ‰ê³¼ ìœ ì‚¬í•œ í”½ì…€ ì œê±°"""
    if background_hsv is None or len(pixels_hsv) == 0:
        return pixels_hsv
    
    # HSV ê±°ë¦¬ ê³„ì‚°
    h_diff = np.minimum(np.abs(pixels_hsv[:, 0] - background_hsv[0]), 
                        360 - np.abs(pixels_hsv[:, 0] - background_hsv[0]))
    s_diff = np.abs(pixels_hsv[:, 1] - background_hsv[1])
    v_diff = np.abs(pixels_hsv[:, 2] - background_hsv[2])
    
    # ê°€ì¤‘ì¹˜ ì ìš© (H:2, S:1, V:1)
    distance = np.sqrt(2 * h_diff**2 + s_diff**2 + v_diff**2)
    
    # ë°°ê²½ìƒ‰ê³¼ ìœ ì‚¬í•œ í”½ì…€ ì œê±°
    filtered_mask = distance > threshold
    filtered_pixels = pixels_hsv[filtered_mask]
    
    print(f"ğŸš« ë°°ê²½ìƒ‰ í•„í„°ë§: {len(pixels_hsv)} â†’ {len(filtered_pixels)} í”½ì…€")
    return filtered_pixels

def extract_best_color_multiple_methods(pixels_hsv):
    """ë‹¤ì¤‘ ë°©ë²•ìœ¼ë¡œ ìƒ‰ìƒ ì¶”ì¶œ í›„ ìµœì  ì„ íƒ"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # ë°©ë²• 1: K-means (ê¸°ë³¸)
    try:
        from sklearn.cluster import KMeans
        kmeans = KMeans(n_clusters=min(3, len(pixels_hsv)), random_state=42, n_init=10)
        labels = kmeans.fit_predict(pixels_hsv)
        dominant_color_kmeans = kmeans.cluster_centers_[np.argmax(np.bincount(labels))]
    except:
        dominant_color_kmeans = np.mean(pixels_hsv, axis=0)
    
    # ë°©ë²• 2: ì±„ë„ ê¸°ë°˜ ê°€ì¤‘ í‰ê· 
    saturation_weights = pixels_hsv[:, 1] / 255.0
    saturation_weights = saturation_weights ** 2  # ì±„ë„ ê°€ì¤‘ì¹˜ ê°•í™”
    if np.sum(saturation_weights) > 0:
        dominant_color_weighted = np.average(pixels_hsv, axis=0, weights=saturation_weights)
    else:
        dominant_color_weighted = np.mean(pixels_hsv, axis=0)
    
    # ë°©ë²• 3: ì¤‘ì•™ê°’ (ì´ìƒì¹˜ ì œê±°)
    dominant_color_median = np.median(pixels_hsv, axis=0)
    
    # ë°©ë²• 4: íˆìŠ¤í† ê·¸ë¨ í”¼í¬
    h_hist = np.histogram(pixels_hsv[:, 0], bins=36, range=(0, 360))[0]
    peak_h_idx = np.argmax(h_hist)
    peak_h = peak_h_idx * 10  # 10ë„ ë‹¨ìœ„ë¡œ ì–‘ìí™”
    
    # í•´ë‹¹ Hue ë²”ìœ„ì˜ í”½ì…€ë“¤ë§Œ ì‚¬ìš©
    h_mask = (pixels_hsv[:, 0] >= peak_h - 10) & (pixels_hsv[:, 0] <= peak_h + 10)
    if np.sum(h_mask) > 0:
        peak_pixels = pixels_hsv[h_mask]
        dominant_color_peak = np.mean(peak_pixels, axis=0)
        dominant_color_peak[0] = peak_h  # HueëŠ” í”¼í¬ ê°’ ì‚¬ìš©
    else:
        dominant_color_peak = np.mean(pixels_hsv, axis=0)
    
    # ê° ë°©ë²•ì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    methods = [
        (dominant_color_kmeans, "K-means"),
        (dominant_color_weighted, "ì±„ë„ ê°€ì¤‘"),
        (dominant_color_median, "ì¤‘ì•™ê°’"),
        (dominant_color_peak, "íˆìŠ¤í† ê·¸ë¨ í”¼í¬")
    ]
    
    best_color = dominant_color_kmeans
    best_score = -1
    
    for color, method_name in methods:
        # í’ˆì§ˆ ì ìˆ˜: ì±„ë„ * ëª…ë„ * ì¼ê´€ì„±
        saturation = color[1] / 255.0
        brightness = color[2] / 255.0
        
        # ì¼ê´€ì„± ì ìˆ˜ (ì£¼ë³€ í”½ì…€ê³¼ì˜ ìœ ì‚¬ë„)
        if len(pixels_hsv) > 10:
            distances = np.sqrt(np.sum((pixels_hsv - color)**2, axis=1))
            consistency = 1.0 / (1.0 + np.std(distances))
        else:
            consistency = 1.0
        
        score = saturation * brightness * consistency
        
        if score > best_score:
            best_score = score
            best_color = color
            
        print(f"   {method_name}: HSV({color[0]:.1f}, {color[1]:.1f}, {color[2]:.1f}) - ì ìˆ˜: {score:.3f}")
    
    print(f"ğŸ† ìµœì  ìƒ‰ìƒ ì„ íƒ: HSV({best_color[0]:.1f}, {best_color[1]:.1f}, {best_color[2]:.1f})")
    return best_color

def extract_core_pixels(pixels_hsv, core_ratio=0.7):
    """í™€ë“œ ì¤‘ì‹¬ë¶€ í”½ì…€ë§Œ ì¶”ì¶œ - ê°€ì¥ ìˆœìˆ˜í•œ ìƒ‰ìƒ"""
    if len(pixels_hsv) == 0:
        return pixels_hsv
    
    # ì±„ë„ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ core_ratio%ë§Œ ì„ íƒ
    saturation_scores = pixels_hsv[:, 1]  # S ì±„ë„
    threshold = np.percentile(saturation_scores, (1 - core_ratio) * 100)
    core_mask = saturation_scores >= threshold
    
    return pixels_hsv[core_mask]

def get_kmeans_dominant_color(pixels, k=3):
    """ë°©ë²• 1: K-means í´ëŸ¬ìŠ¤í„°ë§"""
    if len(pixels) == 0:
        return [0, 0, 0]
    kmeans = KMeans(n_clusters=min(k, len(pixels)), n_init=10, random_state=42)
    kmeans.fit(pixels)
    counts = np.bincount(kmeans.labels_)
    dominant = kmeans.cluster_centers_[np.argmax(counts)]
    return dominant.tolist() if hasattr(dominant, 'tolist') else list(dominant)

def get_histogram_peak_color(pixels_hsv):
    """ë°©ë²• 2: Histogram peak (Hue ê¸°ì¤€)"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # Hue íˆìŠ¤í† ê·¸ë¨ (18ê°œ êµ¬ê°„, 10ë„ì”©)
    hist, bins = np.histogram(pixels_hsv[:, 0], bins=18, range=(0, 180))
    peak_bin = np.argmax(hist)
    peak_hue = (bins[peak_bin] + bins[peak_bin + 1]) / 2
    
    # í•´ë‹¹ Hue ê·¼ì²˜ì˜ í”½ì…€ë“¤ë§Œ ì„ íƒ
    hue_range = 10
    mask = np.abs(pixels_hsv[:, 0] - peak_hue) < hue_range
    if np.sum(mask) > 0:
        result = np.mean(pixels_hsv[mask], axis=0)
    else:
        result = np.mean(pixels_hsv, axis=0)
    return result.tolist() if hasattr(result, 'tolist') else list(result)

def get_median_color(pixels):
    """ë°©ë²• 3: Median (ì¤‘ì•™ê°’)"""
    if len(pixels) == 0:
        return [0, 0, 0]
    result = np.median(pixels, axis=0)
    return result.tolist() if hasattr(result, 'tolist') else list(result)

def get_weighted_mean_color(pixels_hsv):
    """ë°©ë²• 4: ê°€ì¤‘ í‰ê·  (ì±„ë„ê°€ ë†’ì€ í”½ì…€ì— ë” í° ê°€ì¤‘ì¹˜)"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # ì±„ë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš© (ì±„ë„ê°€ ë†’ì„ìˆ˜ë¡ ìˆœìˆ˜í•œ ìƒ‰ìƒ)
    weights = pixels_hsv[:, 1] / 255.0 + 0.1  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    weights = weights / np.sum(weights)
    
    # HueëŠ” ì›í˜•ì´ë¯€ë¡œ íŠ¹ë³„ ì²˜ë¦¬
    h_rad = np.deg2rad(pixels_hsv[:, 0] / 180.0 * 360.0)
    cos_h = np.sum(np.cos(h_rad) * weights)
    sin_h = np.sum(np.sin(h_rad) * weights)
    weighted_h = np.rad2deg(np.arctan2(sin_h, cos_h)) / 360.0 * 180.0
    if weighted_h < 0:
        weighted_h += 180
    
    weighted_s = np.sum(pixels_hsv[:, 1] * weights)
    weighted_v = np.sum(pixels_hsv[:, 2] * weights)
    
    return [weighted_h, weighted_s, weighted_v]

def colors_are_similar(color1, color2, h_thresh=15, s_thresh=30, v_thresh=30):
    """ë‘ ìƒ‰ìƒì´ ìœ ì‚¬í•œì§€ íŒë‹¨"""
    h1, s1, v1 = color1
    h2, s2, v2 = color2
    
    # Hue ì›í˜• ê±°ë¦¬
    h_diff = min(abs(h1 - h2), 180 - abs(h1 - h2))
    
    return (h_diff < h_thresh and 
            abs(s1 - s2) < s_thresh and 
            abs(v1 - v2) < v_thresh)

def get_black_dominant_color(pixels_hsv):
    """ğŸš¨ ê²€ì •ìƒ‰ í™€ë“œ ì „ìš© ìƒ‰ìƒ ì¶”ì¶œ"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # ê²€ì •ìƒ‰ í™€ë“œëŠ” Valueê°€ ë‚®ì€ í”½ì…€ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤
    # Value ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì–´ë‘ìš´ í”½ì…€ë“¤ ìš°ì„  ì„ íƒ
    sorted_pixels = sorted(pixels_hsv, key=lambda x: x[2])  # Value ê¸°ì¤€ ì •ë ¬
    
    # í•˜ìœ„ 50% í”½ì…€ë“¤ë§Œ ì‚¬ìš© (ê°€ì¥ ì–´ë‘ìš´ í”½ì…€ë“¤)
    dark_pixels = sorted_pixels[:len(sorted_pixels)//2]
    
    if len(dark_pixels) == 0:
        dark_pixels = sorted_pixels[:max(1, len(sorted_pixels)//4)]
    
    # ê²€ì •ìƒ‰ í™€ë“œì˜ ê²½ìš° Value ì¤‘ì‹¬ìœ¼ë¡œ ìƒ‰ìƒ ì¶”ì¶œ
    # Hueì™€ Saturationì€ ëœ ì¤‘ìš”, Valueê°€ ê°€ì¥ ì¤‘ìš”
    
    # 1. Valueì˜ ì¤‘ê°„ê°’ ì‚¬ìš©
    v_values = [p[2] for p in dark_pixels]
    median_v = np.median(v_values)
    
    # 2. HueëŠ” ì „ì²´ í”½ì…€ì˜ ì¤‘ê°„ê°’ ì‚¬ìš© (ê²€ì •ìƒ‰ì€ Hueê°€ ì¤‘ìš”í•˜ì§€ ì•ŠìŒ)
    h_values = [p[0] for p in dark_pixels]
    median_h = np.median(h_values)
    
    # 3. Saturationì€ ë‚®ê²Œ ì„¤ì • (ê²€ì •ìƒ‰ì€ ì±„ë„ê°€ ë‚®ìŒ)
    s_values = [p[1] for p in dark_pixels]
    median_s = min(np.median(s_values), 30)  # ìµœëŒ€ 30ìœ¼ë¡œ ì œí•œ
    
    return [int(median_h), int(median_s), int(median_v)]

def get_white_dominant_color(pixels_hsv):
    """ğŸš¨ í°ìƒ‰ í™€ë“œ ì „ìš© ìƒ‰ìƒ ì¶”ì¶œ"""
    if len(pixels_hsv) == 0:
        return [0, 0, 255]
    
    # í°ìƒ‰ í™€ë“œëŠ” Valueê°€ ë†’ê³  Saturationì´ ë‚®ì€ í”½ì…€ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤
    # Value ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë°ì€ í”½ì…€ë“¤ ìš°ì„  ì„ íƒ
    sorted_pixels = sorted(pixels_hsv, key=lambda x: x[2], reverse=True)  # Value ê¸°ì¤€ ì—­ìˆœ ì •ë ¬
    
    # ìƒìœ„ 50% í”½ì…€ë“¤ë§Œ ì‚¬ìš© (ê°€ì¥ ë°ì€ í”½ì…€ë“¤)
    bright_pixels = sorted_pixels[:len(sorted_pixels)//2]
    
    if len(bright_pixels) == 0:
        bright_pixels = sorted_pixels[:max(1, len(sorted_pixels)//4)]
    
    # í°ìƒ‰ í™€ë“œì˜ ê²½ìš° Valueì™€ Saturation ì¤‘ì‹¬ìœ¼ë¡œ ìƒ‰ìƒ ì¶”ì¶œ
    # HueëŠ” ëœ ì¤‘ìš”, Valueê°€ ë†’ê³  Saturationì´ ë‚®ì•„ì•¼ í•¨
    
    # 1. Valueì˜ ì¤‘ê°„ê°’ ì‚¬ìš© (ë†’ê²Œ)
    v_values = [p[2] for p in bright_pixels]
    median_v = max(np.median(v_values), 200)  # ìµœì†Œ 200ìœ¼ë¡œ ì„¤ì •
    
    # 2. Saturationì€ ë‚®ê²Œ ì„¤ì • (í°ìƒ‰ì€ ì±„ë„ê°€ ë‚®ìŒ)
    s_values = [p[1] for p in bright_pixels]
    median_s = min(np.median(s_values), 30)  # ìµœëŒ€ 30ìœ¼ë¡œ ì œí•œ
    
    # 3. HueëŠ” ì „ì²´ í”½ì…€ì˜ ì¤‘ê°„ê°’ ì‚¬ìš© (í°ìƒ‰ì€ Hueê°€ ì¤‘ìš”í•˜ì§€ ì•ŠìŒ)
    h_values = [p[0] for p in bright_pixels]
    median_h = np.median(h_values)
    
    return [int(median_h), int(median_s), int(median_v)]

def normalize_brightness_invariant_color(pixels_hsv):
    """ğŸŒ ëª…ë„ ì •ê·œí™”: ì–´ë‘¡ê³  ë°ì€ ê°™ì€ ìƒ‰ì„ ë™ì¼í•˜ê²Œ ì¸ì‹"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # HSVì—ì„œ Hue, Saturationë§Œ ì‚¬ìš©í•˜ê³  ValueëŠ” ì •ê·œí™”
    pixels_array = np.array(pixels_hsv)
    
    # 1ë‹¨ê³„: Valueë¥¼ 128ë¡œ ì •ê·œí™” (ì¤‘ê°„ ëª…ë„ë¡œ í†µì¼)
    normalized_pixels = pixels_array.copy()
    normalized_pixels[:, 2] = 128  # Valueë¥¼ 128ë¡œ ê³ ì •
    
    # 2ë‹¨ê³„: Saturation ë³´ì • (ì–´ë‘ìš´ ìƒ‰ì˜ ì±„ë„ ë³´ì •)
    # Valueê°€ ë‚®ì„ ë•Œ Saturationì´ ê³¼ì†Œí‰ê°€ë˜ëŠ” ê²½ìš° ë³´ì •
    original_s = pixels_array[:, 1]
    original_v = pixels_array[:, 2]
    
    # ì–´ë‘ìš´ í”½ì…€ì˜ ì±„ë„ë¥¼ ë³´ì • (V < 100ì¸ ê²½ìš°)
    dark_mask = original_v < 100
    if np.any(dark_mask):
        # ì–´ë‘ìš´ í”½ì…€ì˜ ì±„ë„ë¥¼ 1.5ë°°ë¡œ ì¦ê°€
        brightness_factor = 1.5
        normalized_pixels[dark_mask, 1] = np.minimum(255, original_s[dark_mask] * brightness_factor)
    
    # 3ë‹¨ê³„: ë°ì€ í”½ì…€ì˜ ì±„ë„ë„ ë³´ì • (V > 200ì¸ ê²½ìš°)
    bright_mask = original_v > 200
    if np.any(bright_mask):
        # ë°ì€ í”½ì…€ì˜ ì±„ë„ë¥¼ ì•½ê°„ ê°ì†Œ
        brightness_factor = 0.8
        normalized_pixels[bright_mask, 1] = original_s[bright_mask] * brightness_factor
    
    return normalized_pixels

def get_hybrid_dominant_color(pixels_hsv):
    """ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ìƒ‰ìƒ ì¶”ì¶œ: ìƒ‰ìƒ ìœ í˜•ë³„ ë‹¤ë¥¸ ì „ì²˜ë¦¬ ì „ëµ"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    pixels_array = np.array(pixels_hsv)
    
    # 1ë‹¨ê³„: ìƒ‰ìƒ ìœ í˜• ë¶„ë¥˜
    avg_h = np.mean(pixels_array[:, 0])
    avg_s = np.mean(pixels_array[:, 1]) 
    avg_v = np.mean(pixels_array[:, 2])
    
    # ìƒ‰ìƒ ìœ í˜• íŒë‹¨
    is_achromatic = avg_s < 30  # ì±„ë„ê°€ ë‚®ìœ¼ë©´ ë¬´ì±„ìƒ‰ (í°ìƒ‰, ê²€ì •ìƒ‰, íšŒìƒ‰)
    is_dark = avg_v < 80        # ì–´ë‘ìš´ ìƒ‰
    is_bright = avg_v > 180     # ë°ì€ ìƒ‰
    
    print(f"ğŸ” ìƒ‰ìƒ ë¶„ì„: H={avg_h:.1f}, S={avg_s:.1f}, V={avg_v:.1f}")
    print(f"   ë¬´ì±„ìƒ‰: {is_achromatic}, ì–´ë‘ì›€: {is_dark}, ë°ìŒ: {is_bright}")
    
    # 2ë‹¨ê³„: ìœ í˜•ë³„ ì „ì²˜ë¦¬ ì „ëµ
    if is_achromatic:
        # ë¬´ì±„ìƒ‰ (í°ìƒ‰, ê²€ì •ìƒ‰, íšŒìƒ‰) â†’ ëª…ë„ ì •ê·œí™” í•˜ì§€ ì•ŠìŒ
        print("   â†’ ë¬´ì±„ìƒ‰: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
        return get_dominant_color(pixels_hsv)
    
    elif is_dark or is_bright:
        # ì–´ë‘ìš´/ë°ì€ ìœ ì±„ìƒ‰ â†’ ëª…ë„ ì •ê·œí™” ì ìš©
        print("   â†’ ì–´ë‘ìš´/ë°ì€ ìœ ì±„ìƒ‰: ëª…ë„ ì •ê·œí™” ì ìš©")
        normalized_pixels = normalize_brightness_invariant_color(pixels_hsv)
        
        # K-meansë¡œ ëŒ€í‘œìƒ‰ ì¶”ì¶œ
        from sklearn.cluster import KMeans
        if len(normalized_pixels) < 3:
            return [int(np.mean(normalized_pixels[:, 0])), 
                    int(np.mean(normalized_pixels[:, 1])), 
                    int(np.mean(normalized_pixels[:, 2]))]
        
        k = min(3, len(normalized_pixels) // 15 + 1)
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        labels = kmeans.fit_predict(normalized_pixels)
        
        cluster_sizes = [np.sum(labels == i) for i in range(k)]
        largest_cluster_idx = np.argmax(cluster_sizes)
        
        dominant_hsv = kmeans.cluster_centers_[largest_cluster_idx]
        return [int(dominant_hsv[0]), int(dominant_hsv[1]), int(dominant_hsv[2])]
    
    else:
        # ì¤‘ê°„ ëª…ë„ì˜ ìœ ì±„ìƒ‰ â†’ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        print("   â†’ ì¤‘ê°„ ëª…ë„ ìœ ì±„ìƒ‰: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
        return get_dominant_color(pixels_hsv)

def get_brightness_invariant_dominant_color(pixels_hsv):
    """ğŸŒ ëª…ë„ ë¬´ê´€ ìƒ‰ìƒ ì¶”ì¶œ: ì–´ë‘¡ê³  ë°ì€ ê°™ì€ ìƒ‰ì„ ë™ì¼í•˜ê²Œ ì¸ì‹ (ê¸°ì¡´ í•¨ìˆ˜)"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # ëª…ë„ ì •ê·œí™” ì ìš©
    normalized_pixels = normalize_brightness_invariant_color(pixels_hsv)
    
    # ì •ê·œí™”ëœ í”½ì…€ë“¤ë¡œ ëŒ€í‘œìƒ‰ ì¶”ì¶œ
    # K-meansë¡œ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ ê°€ì¥ í° í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ ìƒ‰ìƒ ì¶”ì¶œ
    from sklearn.cluster import KMeans
    
    if len(normalized_pixels) < 3:
        # í”½ì…€ì´ ë„ˆë¬´ ì ìœ¼ë©´ í‰ê· ê°’ ì‚¬ìš©
        return [int(np.mean(normalized_pixels[:, 0])), 
                int(np.mean(normalized_pixels[:, 1])), 
                int(np.mean(normalized_pixels[:, 2]))]
    
    # K-means í´ëŸ¬ìŠ¤í„°ë§ (ìµœëŒ€ 5ê°œ í´ëŸ¬ìŠ¤í„°)
    k = min(5, len(normalized_pixels) // 10 + 1)
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = kmeans.fit_predict(normalized_pixels)
    
    # ê°€ì¥ í° í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
    cluster_sizes = [np.sum(labels == i) for i in range(k)]
    largest_cluster_idx = np.argmax(cluster_sizes)
    
    # ê°€ì¥ í° í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ ìƒ‰ìƒ ë°˜í™˜
    dominant_hsv = kmeans.cluster_centers_[largest_cluster_idx]
    
    return [int(dominant_hsv[0]), int(dominant_hsv[1]), int(dominant_hsv[2])]

def get_robust_dominant_color(pixels_hsv):
    """ğŸš€ ê·¹ê°•í™”ëœ ì•™ìƒë¸” ë°©ì‹: ìµœê³  ì •í™•ë„ ìƒ‰ìƒ ì¶”ì¶œ + ëª…ë„ ì •ê·œí™”"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # ğŸš¨ ê²€ì •ìƒ‰/í°ìƒ‰ í™€ë“œ íŠ¹ë³„ ì²˜ë¦¬
    # Valueê°€ ë§¤ìš° ë‚®ì€ í”½ì…€ë“¤ í™•ì¸ (ê²€ì •ìƒ‰ í›„ë³´)
    low_value_pixels = [p for p in pixels_hsv if p[2] < 50]  # Value < 50
    high_value_pixels = [p for p in pixels_hsv if p[2] > 200 and p[1] < 50]  # Value > 200, Saturation < 50
    
    if len(low_value_pixels) > len(pixels_hsv) * 0.3:  # 30% ì´ìƒì´ ì–´ë‘ìš´ ìƒ‰ìƒ
        # ê²€ì •ìƒ‰ í™€ë“œë¡œ íŒë‹¨ - íŠ¹ë³„ ì²˜ë¦¬
        return get_black_dominant_color(pixels_hsv)
    elif len(high_value_pixels) > len(pixels_hsv) * 0.3:  # 30% ì´ìƒì´ ë°ê³  ì±„ë„ê°€ ë‚®ì€ ìƒ‰ìƒ
        # í°ìƒ‰ í™€ë“œë¡œ íŒë‹¨ - íŠ¹ë³„ ì²˜ë¦¬
        return get_white_dominant_color(pixels_hsv)
    
    # 1ë‹¨ê³„: ê·¹ë„ë¡œ ì—„ê²©í•œ ì•„ì›ƒë¼ì´ì–´ ì œê±° (ì¼ë°˜ ìƒ‰ìƒìš©)
    filtered_pixels = remove_outliers(pixels_hsv, percentile=3)  # 3%ë¡œ ê·¹ë„ë¡œ ì—„ê²©
    if len(filtered_pixels) < 25:  # ìµœì†Œ í”½ì…€ ìˆ˜ ë” ì¦ê°€
        filtered_pixels = pixels_hsv
    
    # 2ë‹¨ê³„: ë‹¤ë‹¨ê³„ ìƒ‰ìƒ ìˆœë„ í•„í„°ë§
    core_pixels = extract_ultra_pure_pixels(filtered_pixels, purity_threshold=0.8)
    if len(core_pixels) < 20:
        core_pixels = extract_high_purity_pixels(filtered_pixels, purity_threshold=0.6)
    
    # ğŸš¨ í•„í„°ë§ í›„ì—ë„ í”½ì…€ì´ ë„ˆë¬´ ì ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
    if len(core_pixels) < 10:
        print(f"âš ï¸ í•„í„°ë§ í›„ í”½ì…€ ë¶€ì¡± ({len(core_pixels)}ê°œ) - ì›ë³¸ ì‚¬ìš© (ì´ {len(pixels_hsv)}ê°œ)")
        core_pixels = filtered_pixels
    
    # ìµœì¢… ì•ˆì „ì¥ì¹˜
    if len(core_pixels) == 0:
        print(f"ğŸš¨ ì‹¬ê°! core_pixelsê°€ ë¹„ì–´ìˆìŒ! filtered_pixels: {len(filtered_pixels)}, ì›ë³¸: {len(pixels_hsv)}")
        core_pixels = pixels_hsv
    
    # 3ë‹¨ê³„: 8ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ëŒ€í‘œìƒ‰ ì¶”ì¶œ
    method1 = get_kmeans_dominant_color(core_pixels, k=5)  # í´ëŸ¬ìŠ¤í„° ìˆ˜ ë” ì¦ê°€
    method2 = get_histogram_peak_color(core_pixels)
    method3 = get_median_color(core_pixels)
    method4 = get_weighted_mean_color(core_pixels)
    method5 = get_mode_color(core_pixels)
    method6 = get_percentile_color(core_pixels, percentile=80)  # ë” ë†’ì€ ë°±ë¶„ìœ„ìˆ˜
    method7 = get_robust_mean_color(core_pixels)  # ìƒˆë¡œìš´ ë°©ë²•
    method8 = get_dominant_hue_color(core_pixels)  # ìƒˆë¡œìš´ ë°©ë²•
    
    # ğŸš¨ [0,0,0] ê²°ê³¼ ê²€ì¦
    candidates = [method1, method2, method3, method4, method5, method6, method7, method8]
    zero_count = sum(1 for c in candidates if c == [0, 0, 0])
    if zero_count > 4:  # ì ˆë°˜ ì´ìƒì´ [0,0,0]ì´ë©´ ë¬¸ì œ
        print(f"ğŸš¨ ì•™ìƒë¸” ë©”ì„œë“œ ì¤‘ {zero_count}ê°œê°€ [0,0,0] ë°˜í™˜!")
        print(f"   core_pixels ê¸¸ì´: {len(core_pixels)}, ìƒ˜í”Œ: {core_pixels[:3].tolist() if len(core_pixels) >= 3 else []}")
    
    weights = [0.25, 0.2, 0.15, 0.15, 0.1, 0.05, 0.05, 0.05]  # ê°€ì¤‘ì¹˜ ì¬ì¡°ì •
    
    # 4ë‹¨ê³„: ê·¹ë„ë¡œ ì—„ê²©í•œ ê°€ì¤‘ íˆ¬í‘œ ì‹œìŠ¤í…œ
    best_candidate = None
    best_score = 0
    
    for i, candidate in enumerate(candidates):
        score = 0
        for j, other in enumerate(candidates):
            # ê·¹ë„ë¡œ ê·¹ë„ë¡œ ì—„ê²©í•œ ìœ ì‚¬ë„ ê¸°ì¤€
            if colors_are_similar(candidate, other, h_thresh=3, s_thresh=10, v_thresh=10):
                score += weights[j]
        
        if score > best_score:
            best_score = score
            best_candidate = candidate
    
    # 5ë‹¨ê³„: ìµœì¢… ê²€ì¦ ë° ë³´ì •
    if best_candidate is not None:
        # ìƒ‰ìƒ ë²”ìœ„ ê²€ì¦ ë° ë³´ì •
        final_color = validate_and_correct_color(best_candidate)
        return final_color
    
    # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ K-means ê²°ê³¼ ì‚¬ìš©
    return method1

def extract_ultra_pure_pixels(pixels_hsv, purity_threshold=0.8):
    """ğŸ¯ ê·¹ë„ë¡œ ë†’ì€ ìƒ‰ìƒ ìˆœë„ì˜ í”½ì…€ë§Œ ì¶”ì¶œ"""
    if len(pixels_hsv) == 0:
        return pixels_hsv
    
    # ìƒ‰ìƒ ìˆœë„ ê³„ì‚° (Saturationê³¼ Valueì˜ ê³±)
    saturation = pixels_hsv[:, 1] / 255.0
    value = pixels_hsv[:, 2] / 255.0
    color_purity = saturation * value
    
    # ê·¹ë„ë¡œ ë†’ì€ ìˆœë„ë§Œ ì„ íƒ
    ultra_pure_mask = color_purity >= purity_threshold
    
    if np.sum(ultra_pure_mask) < 15:  # ë„ˆë¬´ ì ìœ¼ë©´ ì„ê³„ê°’ ë‚®ì¶¤
        ultra_pure_mask = color_purity >= (purity_threshold * 0.7)
    
    return pixels_hsv[ultra_pure_mask]

def extract_high_purity_pixels(pixels_hsv, purity_threshold=0.7):
    """ğŸ¯ ë†’ì€ ìƒ‰ìƒ ìˆœë„ì˜ í”½ì…€ë§Œ ì¶”ì¶œ"""
    if len(pixels_hsv) == 0:
        return pixels_hsv
    
    # ìƒ‰ìƒ ìˆœë„ ê³„ì‚° (Saturationê³¼ Valueì˜ ê³±)
    saturation = pixels_hsv[:, 1] / 255.0
    value = pixels_hsv[:, 2] / 255.0
    color_purity = saturation * value
    
    # ì„ê³„ê°’ ì´ìƒì˜ í”½ì…€ë§Œ ì„ íƒ
    high_purity_mask = color_purity >= purity_threshold
    
    if np.sum(high_purity_mask) < 10:  # ë„ˆë¬´ ì ìœ¼ë©´ ì„ê³„ê°’ ë‚®ì¶¤
        high_purity_mask = color_purity >= (purity_threshold * 0.6)
    
    return pixels_hsv[high_purity_mask]

def get_robust_mean_color(pixels_hsv):
    """ğŸ¯ ê°•ê±´í•œ í‰ê·  ìƒ‰ìƒ ì¶”ì¶œ (ì•„ì›ƒë¼ì´ì–´ ì œê±°)"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # ê° ì±„ë„ë³„ë¡œ ì•„ì›ƒë¼ì´ì–´ ì œê±° í›„ í‰ê·  ê³„ì‚°
    robust_hue = np.median(pixels_hsv[:, 0])  # ì¤‘ê°„ê°’ ì‚¬ìš©
    robust_sat = np.mean(pixels_hsv[:, 1])     # í‰ê·  ì‚¬ìš©
    robust_val = np.mean(pixels_hsv[:, 2])    # í‰ê·  ì‚¬ìš©
    
    return [robust_hue, robust_sat, robust_val]

def get_dominant_hue_color(pixels_hsv):
    """ğŸ¯ ì§€ë°°ì ì¸ Hue ê¸°ë°˜ ìƒ‰ìƒ ì¶”ì¶œ"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # Hue íˆìŠ¤í† ê·¸ë¨ì—ì„œ ê°€ì¥ ë¹ˆë²ˆí•œ ê°’ ì°¾ê¸°
    hue_hist, hue_bins = np.histogram(pixels_hsv[:, 0], bins=36, range=(0, 180))
    dominant_hue_bin = np.argmax(hue_hist)
    dominant_hue = hue_bins[dominant_hue_bin] + (hue_bins[1] - hue_bins[0]) / 2
    
    # í•´ë‹¹ Hueë¥¼ ê°€ì§„ í”½ì…€ë“¤ì˜ í‰ê·  Saturationê³¼ Value
    hue_mask = (pixels_hsv[:, 0] >= hue_bins[dominant_hue_bin]) & \
               (pixels_hsv[:, 0] < hue_bins[dominant_hue_bin + 1])
    
    if np.sum(hue_mask) > 0:
        avg_sat = np.mean(pixels_hsv[hue_mask, 1])
        avg_val = np.mean(pixels_hsv[hue_mask, 2])
    else:
        avg_sat = np.mean(pixels_hsv[:, 1])
        avg_val = np.mean(pixels_hsv[:, 2])
    
    return [dominant_hue, avg_sat, avg_val]

def get_mode_color(pixels_hsv):
    """ğŸ¯ ìµœë¹ˆê°’ ê¸°ë°˜ ìƒ‰ìƒ ì¶”ì¶œ"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # Hueë¥¼ 18ê°œ êµ¬ê°„ìœ¼ë¡œ ì–‘ìí™”
    hue_quantized = np.floor(pixels_hsv[:, 0] / 10).astype(int)
    sat_quantized = np.floor(pixels_hsv[:, 1] / 32).astype(int)
    val_quantized = np.floor(pixels_hsv[:, 2] / 32).astype(int)
    
    # ê°€ì¥ ë¹ˆë²ˆí•œ ì¡°í•© ì°¾ê¸°
    mode_hue = np.bincount(hue_quantized).argmax() * 10 + 5
    mode_sat = np.bincount(sat_quantized).argmax() * 32 + 16
    mode_val = np.bincount(val_quantized).argmax() * 32 + 16
    
    return [mode_hue, mode_sat, mode_val]

def get_percentile_color(pixels_hsv, percentile=75):
    """ğŸ¯ ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ìƒ‰ìƒ ì¶”ì¶œ"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    h_percentile = np.percentile(pixels_hsv[:, 0], percentile)
    s_percentile = np.percentile(pixels_hsv[:, 1], percentile)
    v_percentile = np.percentile(pixels_hsv[:, 2], percentile)
    
    return [h_percentile, s_percentile, v_percentile]

def validate_and_correct_color(color_hsv):
    """ğŸ¯ ìƒ‰ìƒ ë²”ìœ„ ê²€ì¦ ë° ë³´ì •"""
    h, s, v = color_hsv
    
    # HSV ë²”ìœ„ ê²€ì¦ ë° ë³´ì •
    h = max(0, min(179, h))
    s = max(0, min(255, s))
    v = max(0, min(255, v))
    
    # ë¹„ì •ìƒì ì¸ ìƒ‰ìƒ ë³´ì •
    if s < 30 and v > 200:  # ê±°ì˜ í°ìƒ‰
        s = 0
        v = 255
    elif v < 30:  # ê±°ì˜ ê²€ì€ìƒ‰
        s = 0
        v = 0
    elif s < 10:  # ê±°ì˜ íšŒìƒ‰
        s = 0
    
    return [h, s, v]

def get_dominant_color(pixels_hsv, k=3):
    """ğŸ¯ ìƒìœ„ ë°ê¸° ë°©ì‹: ê°€ì¥ ë°ì€ í”½ì…€ë“¤ì˜ í‰ê·  ìƒ‰ìƒ ì¶”ì¶œ"""
    if len(pixels_hsv) == 0:
        return [0, 0, 0]
    
    # í”½ì…€ì´ ë„ˆë¬´ ì ìœ¼ë©´ ì¤‘ì•™ê°’ ì‚¬ìš©
    if len(pixels_hsv) < 10:
        return [int(np.median(pixels_hsv[:, 0])), 
                int(np.median(pixels_hsv[:, 1])), 
                int(np.median(pixels_hsv[:, 2]))]
    
    # ğŸš€ ìƒìœ„ 30% ë°ì€ í”½ì…€ë§Œ ì‚¬ìš© (ê·¸ë¦¼ì/ê²½ê³„ ì œì™¸)
    brightness_scores = pixels_hsv[:, 2]  # V ì±„ë„
    bright_threshold = np.percentile(brightness_scores, 70)  # ìƒìœ„ 30%
    
    bright_mask = brightness_scores >= bright_threshold
    
    if np.sum(bright_mask) > 10:  # ì¶©ë¶„í•œ ë°ì€ í”½ì…€ì´ ìˆìœ¼ë©´
        pixels_hsv = pixels_hsv[bright_mask]
        print(f"   ìƒìœ„ ë°ê¸° í”½ì…€ ì„ ë³„: {len(pixels_hsv)}ê°œ (ë°ê¸°â‰¥{bright_threshold:.0f})")
    else:
        print(f"   ë°ì€ í”½ì…€ ë¶€ì¡±, ì „ì²´ ì‚¬ìš©: {len(pixels_hsv)}ê°œ")
    
    # ğŸ¯ ë‹¨ìˆœ í‰ê·  ë°©ì‹: ë°ì€ í”½ì…€ë“¤ì˜ í‰ê·  ìƒ‰ìƒ (ë” ë°ì€ ê²°ê³¼)
    h_avg = np.mean(pixels_hsv[:, 0])
    s_avg = np.mean(pixels_hsv[:, 1])
    v_avg = np.mean(pixels_hsv[:, 2])
    
    print(f"   ë°ì€ í”½ì…€ í‰ê· : HSV({h_avg:.1f}, {s_avg:.1f}, {v_avg:.1f})")
    
    return [int(h_avg), int(s_avg), int(v_avg)]

# -------------------------------
# ğŸ“Œ í”½ì…€ ê¸°ë°˜ í†µê³„ì¹˜ ì¶”ì¶œ
# -------------------------------
def calculate_color_stats(image, mask, brightness_normalization=False, 
                          brightness_filter=False, min_brightness=0, max_brightness=100,
                          saturation_filter=False, min_saturation=0):
    """ğŸš€ í™•ì¥ëœ ìƒ‰ìƒ í†µê³„ ì¶”ì¶œ - ë‹¤ì¤‘ ìƒ‰ìƒ ê³µê°„ + ê³ ê¸‰ íŠ¹ì§• + ëª…ë„ ì •ê·œí™” ì˜µì…˜"""
    # ë‹¤ì¤‘ ìƒ‰ìƒ ê³µê°„ ë³€í™˜
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)
    yuv_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
    xyz_image = cv2.cvtColor(image, cv2.COLOR_BGR2XYZ)

    pixels_hsv = hsv_image[mask > 0.5]
    pixels_rgb = rgb_image[mask > 0.5]
    pixels_lab = lab_image[mask > 0.5]
    pixels_yuv = yuv_image[mask > 0.5]
    pixels_xyz = xyz_image[mask > 0.5]
    
    # ğŸ¨ ìƒ‰ìƒ í’ˆì§ˆ í•„í„°ë§ ì ìš©
    if len(pixels_hsv) > 0:
        # ëª…ë„ í•„í„°ë§ (V ì±„ë„ ê¸°ì¤€)
        if brightness_filter:
            brightness_mask = (pixels_hsv[:, 2] >= min_brightness * 2.55) & (pixels_hsv[:, 2] <= max_brightness * 2.55)
            pixels_hsv = pixels_hsv[brightness_mask]
            pixels_rgb = pixels_rgb[brightness_mask]
            pixels_lab = pixels_lab[brightness_mask]
            pixels_yuv = pixels_yuv[brightness_mask]
            pixels_xyz = pixels_xyz[brightness_mask]
        
        # ì±„ë„ í•„í„°ë§ (S ì±„ë„ ê¸°ì¤€)
        if saturation_filter and len(pixels_hsv) > 0:
            saturation_mask = pixels_hsv[:, 1] >= min_saturation * 2.55
            pixels_hsv = pixels_hsv[saturation_mask]
            pixels_rgb = pixels_rgb[saturation_mask]
            pixels_lab = pixels_lab[saturation_mask]
            pixels_yuv = pixels_yuv[saturation_mask]
            pixels_xyz = pixels_xyz[saturation_mask]
    
    # í•„í„°ë§ í›„ í”½ì…€ì´ ë¶€ì¡±í•œ ê²½ìš° ì›ë³¸ ì‚¬ìš©
    if len(pixels_hsv) < 10:  # ìµœì†Œ 10ê°œ í”½ì…€ í•„ìš”
        pixels_hsv = hsv_image[mask > 0.5]
        pixels_rgb = rgb_image[mask > 0.5]
        pixels_lab = lab_image[mask > 0.5]
        pixels_yuv = yuv_image[mask > 0.5]
        pixels_xyz = xyz_image[mask > 0.5]

    # ëŒ€í‘œìƒ‰ ì¶”ì¶œ (ì „ì²˜ë¦¬ ë°©ë²•ì— ë”°ë¼ ì„ íƒ)
    if brightness_normalization == "í•˜ì´ë¸Œë¦¬ë“œ":
        dominant_hsv = get_hybrid_dominant_color(pixels_hsv)
        print(f"ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ ì ìš©: ì›ë³¸ HSV ìƒ˜í”Œ {len(pixels_hsv)}ê°œ")
    elif brightness_normalization == "ëª…ë„ ì •ê·œí™”":
        dominant_hsv = get_brightness_invariant_dominant_color(pixels_hsv)
        print(f"ğŸŒ ëª…ë„ ì •ê·œí™” ì ìš©: ì›ë³¸ HSV ìƒ˜í”Œ {len(pixels_hsv)}ê°œ")
    else:
        dominant_hsv = get_dominant_color(pixels_hsv)
        print(f"ğŸ“Š ê¸°ì¡´ ë°©ì‹ ì ìš©: ì›ë³¸ HSV ìƒ˜í”Œ {len(pixels_hsv)}ê°œ")
    
    # ğŸš¨ RGBëŠ” dominant_hsvë¥¼ RGBë¡œ ì§ì ‘ ë³€í™˜ (ì¼ê´€ì„± ìœ ì§€)
    # HSV â†’ RGB ë³€í™˜ìœ¼ë¡œ í†µì¼
    if len(pixels_hsv) == 0:
        print(f"âš ï¸ í”½ì…€ ì—†ìŒ! pixels_hsv ê¸¸ì´: 0")
        dominant_rgb = [128, 128, 128]  # íšŒìƒ‰ìœ¼ë¡œ ëŒ€ì²´
    else:
        try:
            hsv_arr = np.uint8([[dominant_hsv]])
            rgb_arr = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
            dominant_rgb = [int(rgb_arr[0]), int(rgb_arr[1]), int(rgb_arr[2])]
            
            # RGB(0,0,0) ê²€ì¦
            if dominant_rgb == [0, 0, 0]:
                print(f"âš ï¸ HSV={dominant_hsv} â†’ RGB(0,0,0) ë³€í™˜ë¨! pixels_hsv ê¸¸ì´: {len(pixels_hsv)}")
                print(f"   ì›ë³¸ HSV ìƒ˜í”Œ: {pixels_hsv[:3].tolist() if len(pixels_hsv) >= 3 else pixels_hsv.tolist()}")
                dominant_rgb = [128, 128, 128]  # íšŒìƒ‰ìœ¼ë¡œ ëŒ€ì²´
        except Exception as e:
            print(f"âš ï¸ HSVâ†’RGB ë³€í™˜ ì˜¤ë¥˜: {e}, HSV={dominant_hsv}")
            dominant_rgb = [128, 128, 128]  # íšŒìƒ‰ìœ¼ë¡œ ëŒ€ì²´
    
    dominant_lab = get_dominant_color(pixels_lab) if len(pixels_lab) > 0 else [0, 0, 0]
    dominant_yuv = get_dominant_color(pixels_yuv) if len(pixels_yuv) > 0 else [0, 0, 0]
    dominant_xyz = get_dominant_color(pixels_xyz) if len(pixels_xyz) > 0 else [0, 0, 0]
    
    # ê¸°ë³¸ í†µê³„ ê³„ì‚° (í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Ÿê°’, ìµœëŒ“ê°’)
    hsv_stats = calculate_basic_stats(pixels_hsv)
    rgb_stats = calculate_basic_stats(pixels_rgb)
    lab_stats = calculate_basic_stats(pixels_lab)
    yuv_stats = calculate_basic_stats(pixels_yuv)
    xyz_stats = calculate_basic_stats(pixels_xyz)
    
    # ê³ ê¸‰ íŠ¹ì§• ê³„ì‚°
    advanced_features = calculate_advanced_features(pixels_hsv, pixels_lab, pixels_rgb)

    stats = {
        # ëŒ€í‘œìƒ‰ (5ê°œ ìƒ‰ìƒ ê³µê°„)
        "dominant_hsv": dominant_hsv,
        "dominant_rgb": dominant_rgb,
        "dominant_lab": dominant_lab,
        "dominant_yuv": dominant_yuv,
        "dominant_xyz": dominant_xyz,
        
        # ê¸°ë³¸ í†µê³„ (5ê°œ ìƒ‰ìƒ ê³µê°„)
        "hsv_stats": hsv_stats,
        "rgb_stats": rgb_stats,
        "lab_stats": lab_stats,
        "yuv_stats": yuv_stats,
        "xyz_stats": xyz_stats,
        
        # ê³ ê¸‰ íŠ¹ì§•
        "advanced": advanced_features,
        
        # í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ êµ¬ì¡° ìœ ì§€
        "illumination_invariant": advanced_features
    }
    return stats

def calculate_basic_stats(pixels):
    """ê¸°ë³¸ í†µê³„ (í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Ÿê°’, ìµœëŒ“ê°’)"""
    if len(pixels) == 0:
        return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  # 4 * 3 channels
    
    return np.hstack([
        np.mean(pixels, axis=0),
        np.std(pixels, axis=0),
        np.min(pixels, axis=0),
        np.max(pixels, axis=0),
    ]).tolist()

def calculate_advanced_features(pixels_hsv, pixels_lab, pixels_rgb):
    """ê³ ê¸‰ ìƒ‰ìƒ íŠ¹ì§• ê³„ì‚°"""
    if len(pixels_hsv) == 0:
        return {
            "lab_ab": [0, 0], "hue_sat": [0, 0], "color_purity": 0.0,
            "hue_variance": 0.0, "saturation_variance": 0.0, "value_variance": 0.0,
            "color_uniformity": 0.0, "contrast": 0.0, "brightness_std": 0.0,
            "hue_dominant_frequency": 0.0, "saturation_consistency": 0.0
        }
    
    # ì¡°ëª… ë¶ˆë³€ íŠ¹ì§•
    lab_a_mean = np.mean(pixels_lab[:, 1])
    lab_b_mean = np.mean(pixels_lab[:, 2])
    hue_mean = np.mean(pixels_hsv[:, 0])
    sat_mean = np.mean(pixels_hsv[:, 1])
    color_purity = sat_mean / 255.0
    
    # ìƒ‰ìƒ ë¶„ì‚° íŠ¹ì§•
    hue_variance = np.var(pixels_hsv[:, 0])
    saturation_variance = np.var(pixels_hsv[:, 1])
    value_variance = np.var(pixels_hsv[:, 2])
    
    # ìƒ‰ìƒ ê· ì¼ì„± (ë‚®ì„ìˆ˜ë¡ ê· ì¼)
    color_uniformity = np.mean([
        hue_variance / 100.0,  # ì •ê·œí™”
        saturation_variance / 100.0,
        value_variance / 100.0
    ])
    
    # ëŒ€ë¹„ (ëª…ë„ ì°¨ì´)
    contrast = np.std(pixels_rgb, axis=0).mean() / 255.0
    
    # ë°ê¸° í‘œì¤€í¸ì°¨
    brightness = np.mean(pixels_rgb, axis=1)
    brightness_std = np.std(brightness) / 255.0
    
    # Hue íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ íŠ¹ì§•
    hue_hist, _ = np.histogram(pixels_hsv[:, 0], bins=18, range=(0, 180))
    hue_dominant_frequency = np.max(hue_hist) / len(pixels_hsv)
    
    # Saturation ì¼ê´€ì„± (ë†’ì„ìˆ˜ë¡ ì¼ê´€ì )
    saturation_consistency = 1.0 - (saturation_variance / 100.0)
    
    return {
        "lab_ab": [float(lab_a_mean), float(lab_b_mean)],
        "hue_sat": [float(hue_mean), float(sat_mean)],
        "color_purity": float(color_purity),
        "hue_variance": float(hue_variance),
        "saturation_variance": float(saturation_variance),
        "value_variance": float(value_variance),
        "color_uniformity": float(color_uniformity),
        "contrast": float(contrast),
        "brightness_std": float(brightness_std),
        "hue_dominant_frequency": float(hue_dominant_frequency),
        "saturation_consistency": float(saturation_consistency)
    }

# -------------------------------
# ğŸ“Œ Preprocess Pipeline
# -------------------------------
def preprocess(image_input, model_path="/app/holdcheck/roboflow_weights/weights.pt", conf=0.4, brightness_normalization=False, 
               brightness_filter=False, min_brightness=0, max_brightness=100, 
               saturation_filter=False, min_saturation=0, mask_refinement=5, use_clip_ai=False):
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ì‹œì‘)
    log_memory_usage("Preprocess ì‹œì‘")
    
    # image_inputì´ ë¬¸ìì—´(íŒŒì¼ ê²½ë¡œ)ì¸ì§€ numpy ë°°ì—´ì¸ì§€ í™•ì¸
    if isinstance(image_input, str):
        # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
        original_image = cv2.imread(image_input)
        if original_image is None:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŒ: {image_input}")
    else:
        # ì´ë¯¸ numpy ë°°ì—´ì¸ ê²½ìš° (ì´ë¯¸ ë¡œë“œëœ ì´ë¯¸ì§€)
        original_image = image_input

    h_img, w_img = original_image.shape[:2]
    padded_image, scale, pad_left, pad_top = resize_with_padding(original_image)
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ì´ë¯¸ì§€ ë¡œë”© í›„)
    log_memory_usage("ì´ë¯¸ì§€ ë¡œë”© í›„")

    # ğŸš€ ìºì‹±ëœ YOLO ëª¨ë¸ ì‚¬ìš© (ì†ë„ ëŒ€í­ í–¥ìƒ)
    model = get_yolo_model(model_path)
    
    # ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™”: YOLO í•´ìƒë„ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • (ê¸°ë³¸ê°’: 384)
    yolo_img_size = int(os.getenv("YOLO_IMG_SIZE", "384"))  # 640 â†’ 384 (ë©”ëª¨ë¦¬ ì ˆì•½)
    print(f"ğŸ“Š YOLO ì´ë¯¸ì§€ í¬ê¸°: {yolo_img_size}")
    
    results = model(padded_image, conf=conf, imgsz=yolo_img_size)[0]
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (YOLO ì¶”ë¡  í›„)
    log_memory_usage("YOLO ì¶”ë¡  í›„")

    masks_raw = results.masks.data.cpu().numpy()
    masks = [restore_mask_to_original(m, (h_img, w_img), scale, pad_left, pad_top) for m in masks_raw]

    hold_data = []
    overlay = original_image.copy()

    # ğŸš€ ìµœì í™”: ë§ˆìŠ¤í¬ ì „ì²˜ë¦¬ë¥¼ í•œ ë²ˆë§Œ ìˆ˜í–‰ (ì¤‘ë³µ ì œê±°)
    if use_clip_ai:
        valid_hold_images = []
        valid_masks = []
        valid_indices = []
        preprocessed_data = {}  # ì „ì²˜ë¦¬ ê²°ê³¼ ìºì‹±
        
        # ğŸš¨ CRITICAL: í™€ë“œ ê°œìˆ˜ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡± ìœ„í—˜!
        max_holds = int(os.getenv("MAX_HOLDS", "50"))  # ê¸°ë³¸ê°’: 50ê°œë¡œ ì œí•œ
        if len(masks) > max_holds:
            print(f"âš ï¸  ê²½ê³ : í™€ë“œê°€ {len(masks)}ê°œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤! (ìµœëŒ€ {max_holds}ê°œ)")
            print(f"âš ï¸  ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ìƒìœ„ {max_holds}ê°œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            print(f"âš ï¸  ë” ë§ì€ í™€ë“œë¥¼ ì²˜ë¦¬í•˜ë ¤ë©´ MAX_HOLDS í™˜ê²½ë³€ìˆ˜ë¥¼ ëŠ˜ë ¤ì£¼ì„¸ìš”.")
            
            # ë©´ì ì´ í° í™€ë“œë¶€í„° ì„ íƒ (confidenceê°€ ë†’ì€ ê²ƒ ìš°ì„ )
            mask_areas = []
            for mask in masks:
                area = np.sum(mask > 0)
                mask_areas.append(area)
            
            # ë©´ì  ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ Nê°œë§Œ ì„ íƒ
            top_indices = np.argsort(mask_areas)[::-1][:max_holds]
            masks = [masks[i] for i in sorted(top_indices)]
            print(f"âœ… ìƒìœ„ {len(masks)}ê°œ í™€ë“œ ì„ íƒ ì™„ë£Œ")
        
        # ë¨¼ì € ëª¨ë“  í™€ë“œë¥¼ ê²€ì¦í•˜ê³  ìˆ˜ì§‘
        print(f"ğŸ” í™€ë“œ ë§ˆìŠ¤í¬ ì „ì²˜ë¦¬ ì¤‘... ({len(masks)}ê°œ)")
        for i, mask in enumerate(masks):
            # ğŸš€ ë§ˆìŠ¤í¬ ì „ì²˜ë¦¬
            mask_uint8 = (mask * 255).astype(np.uint8)
            mask_refined = refine_mask_boundary(mask_uint8, kernel_size=3, iterations=mask_refinement)
            
            contours, _ = cv2.findContours(mask_refined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if len(contours) == 0:
                continue
                
            largest_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)
            
            if area < 200:
                continue
                
            perimeter = cv2.arcLength(largest_contour, True)
            if perimeter == 0:
                continue
                
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            if circularity < 0.1:
                continue
            
            mask_clean = np.zeros_like(mask_refined)
            cv2.fillPoly(mask_clean, [largest_contour], 255)
            
            # ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
            preprocessed_data[i] = {
                'mask_refined': mask_refined,
                'largest_contour': largest_contour,
                'area': area,
                'perimeter': perimeter,
                'circularity': circularity,
                'mask_clean': mask_clean
            }
            
            valid_hold_images.append(original_image)
            valid_masks.append(mask_clean / 255.0)
            valid_indices.append(i)
        
        print(f"âœ… ë§ˆìŠ¤í¬ ì „ì²˜ë¦¬ ì™„ë£Œ ({len(valid_indices)}ê°œ ìœ íš¨)")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ë§ˆìŠ¤í¬ ì „ì²˜ë¦¬ í›„)
        log_memory_usage("ë§ˆìŠ¤í¬ ì „ì²˜ë¦¬ í›„")
        
        # ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ë¡œ CLIP AI ìƒ‰ìƒ ì¶”ì¶œ
        if valid_hold_images:
            print(f"ğŸ¤– CLIP AI ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ ({len(valid_hold_images)}ê°œ í™€ë“œ)")
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (CLIP ì²˜ë¦¬ ì „)
            memory_before_clip = log_memory_usage("CLIP ì²˜ë¦¬ ì „")
            
            batch_results = extract_colors_with_clip_ai_batch(valid_hold_images, valid_masks)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (CLIP ì²˜ë¦¬ í›„)
            memory_after_clip = log_memory_usage("CLIP ì²˜ë¦¬ í›„")
            
            # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ ê³„ì‚°
            clip_memory_increase = memory_after_clip['rss'] - memory_before_clip['rss']
            print(f"ğŸ“Š CLIP ì²˜ë¦¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: +{clip_memory_increase:.1f}MB")
            
            print(f"âœ… CLIP AI ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
        else:
            batch_results = []
        
        # ë°°ì¹˜ ê²°ê³¼ë¥¼ hold_dataì— ì ìš©
        batch_idx = 0
        for i, mask in enumerate(masks):
            if i in valid_indices:
                # ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ì‚¬ìš©
                color_name, confidence, rgb, hsv, clip_features = batch_results[batch_idx]
                batch_idx += 1
                
                # ğŸš€ ì „ì²˜ë¦¬ ê²°ê³¼ ì¬ì‚¬ìš© (ì¤‘ë³µ ì œê±°)
                preproc = preprocessed_data[i]
                mask_refined = preproc['mask_refined']
                largest_contour = preproc['largest_contour']
                area = preproc['area']
                perimeter = preproc['perimeter']
                circularity = preproc['circularity']
                mask_clean = preproc['mask_clean']
                
                M = cv2.moments(largest_contour)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                else:
                    cx, cy = 0, 0
                
                stats = {
                    "dominant_rgb": rgb,
                    "dominant_hsv": hsv,
                    "clip_color_name": color_name,
                    "clip_confidence": confidence,
                    "clip_features": clip_features.tolist()
                }
                
                hold_data.append({
                    "id": i,
                    "center": [int(cx), int(cy)],
                    "area": area,
                    "circularity": circularity,
                    **stats,
                    "size": int(np.sum(mask_clean > 0))
                })

                overlay[mask > 0.5] = (0, 255, 0)
                cv2.putText(overlay, f"ID:{i}", (cx, cy),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
            else:
                # ìœ íš¨í•˜ì§€ ì•Šì€ í™€ë“œëŠ” ê±´ë„ˆëœ€
                continue
    else:
        # ê¸°ì¡´ ë°©ì‹ (CLIP AI ì‚¬ìš© ì•ˆ í•¨)
        for i, mask in enumerate(masks):
            # ğŸš€ ê°•í™”ëœ ë§ˆìŠ¤í¬ ì „ì²˜ë¦¬
            mask_uint8 = (mask * 255).astype(np.uint8)
            
            # 1ë‹¨ê³„: ë§ˆìŠ¤í¬ ê²½ê³„ ì •ì œ
            mask_refined = refine_mask_boundary(mask_uint8, kernel_size=3, iterations=mask_refinement)
            
            # 2ë‹¨ê³„: ì»¨íˆ¬ì–´ ê¸°ë°˜ í’ˆì§ˆ ê²€ì¦
            contours, _ = cv2.findContours(mask_refined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if len(contours) == 0:
                continue
                
            # ê°€ì¥ í° ì»¨íˆ¬ì–´ ì„ íƒ
            largest_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)
            
            # ë” ì—„ê²©í•œ í¬ê¸° í•„í„°ë§
            if area < 200:  # ìµœì†Œ í¬ê¸° ì¦ê°€
                continue
            
            # 3ë‹¨ê³„: ì»¨íˆ¬ì–´ í’ˆì§ˆ ê²€ì¦
            perimeter = cv2.arcLength(largest_contour, True)
            if perimeter == 0:
                continue
            
            # ì›í˜•ë„ ê²€ì¦ (í™€ë“œëŠ” ëŒ€ì²´ë¡œ ì›í˜•ì— ê°€ê¹Œì›€)
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            if circularity < 0.1:  # ë„ˆë¬´ ë¶ˆê·œì¹™í•œ ëª¨ì–‘ ì œì™¸
                continue
            
            # 4ë‹¨ê³„: ìµœì¢… ë§ˆìŠ¤í¬ ìƒì„±
            mask_clean = np.zeros_like(mask_refined)
            cv2.fillPoly(mask_clean, [largest_contour], 255)
            
            # 5ë‹¨ê³„: ì¤‘ì‹¬ì  ê³„ì‚°
            M = cv2.moments(largest_contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
            else:
                cx, cy = 0, 0
            
            # 6ë‹¨ê³„: ê¸°ì¡´ ìƒ‰ìƒ í†µê³„ ì¶”ì¶œ
            stats = calculate_color_stats(
                original_image, 
                mask_clean / 255.0, 
                brightness_normalization=brightness_normalization,
                brightness_filter=brightness_filter,
                min_brightness=min_brightness,
                max_brightness=max_brightness,
                saturation_filter=saturation_filter,
                min_saturation=min_saturation
            )
            
            # ğŸš¨ RGB(0,0,0) ê²€ì¦ ë° ë¡œê·¸
            if stats.get("dominant_rgb") == [0, 0, 0]:
                print(f"ğŸš¨ ê²½ê³ ! í™€ë“œ {i}: RGB(0,0,0) ê°ì§€!")
                print(f"   - ë§ˆìŠ¤í¬ í”½ì…€ ìˆ˜: {np.sum(mask_clean > 0)}")
                print(f"   - dominant_hsv: {stats.get('dominant_hsv')}")
                print(f"   - ê±´ë„ˆëœ€ ë˜ëŠ” ê¸°ë³¸ê°’ ì„¤ì • í•„ìš”")
                stats["dominant_rgb"] = [128, 128, 128]  # íšŒìƒ‰ìœ¼ë¡œ ëŒ€ì²´
                stats["dominant_hsv"] = [0, 0, 128]  # íšŒìƒ‰ HSV

            hold_data.append({
                "id": i,
                "center": [int(cx), int(cy)],
                "area": area,
                "circularity": circularity,
                **stats,
                "size": int(np.sum(mask_clean > 0))
        })

        overlay[mask > 0.5] = (0, 255, 0)
        cv2.putText(overlay, f"ID:{i}", (cx, cy),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)

    blended = cv2.addWeighted(original_image, 0.7, overlay, 0.3, 0)

    os.makedirs("outputs", exist_ok=True)
    
    # ì´ë¯¸ì§€ ì…ë ¥ì´ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°ì—ë§Œ íŒŒì¼ëª… ì¶”ì¶œ
    if isinstance(image_input, str):
        base_name = os.path.splitext(os.path.basename(image_input))[0]
    else:
        # ì´ë¯¸ì§€ ë°°ì—´ì¸ ê²½ìš° íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©
        import time
        base_name = f"image_{int(time.time())}"

    cv2.imwrite(f"outputs/{base_name}_preprocessed.png", blended)
    
    # ğŸš€ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë°ì´í„° ë³€í™˜
    json_safe_data = convert_to_json_safe(hold_data)
    with open(f"outputs/{base_name}_preprocessed.json", "w", encoding="utf-8") as f:
        json.dump(json_safe_data, f, indent=2, ensure_ascii=False)

    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ì™„ë£Œ)
    log_memory_usage("Preprocess ì™„ë£Œ")
    
    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
    gc.collect()
    
    return hold_data, masks