import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import cv2
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import torch
import clip
from PIL import Image
import json
import os
from pathlib import Path

# ğŸš€ ì„±ëŠ¥ ìµœì í™”: ì „ì—­ ìºì‹œ
_clip_model = None
_clip_text_features = None
_clip_device = None

# ğŸ¨ ë£° ê¸°ë°˜ ìƒ‰ìƒ ë¶„ë¥˜ ìºì‹œ
_color_ranges_cache = None
_color_feedback_data = []

def hsv_to_rgb(hsv):
    hsv_arr = np.uint8([[hsv]])
    rgb = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
    return tuple(int(x) for x in rgb)

def transform_rgb_with_axis_weights(rgb):
    """
    ğŸ¯ RGBë¥¼ 1:1:1 ëŒ€ê°ì„  ê¸°ì¤€ 3D ì¢Œí‘œê³„ë¡œ ë³€í™˜
    
    Zì¶•: (0,0,0) â†’ (255,255,255) 1:1:1 ëŒ€ê°ì„  (ì¡°ëª…/ë°ê¸°) - ê´€ëŒ€
    X,Yì¶•: Zì¶•ì„ ìˆ˜ì§ìœ¼ë¡œ 360ë„ ë°˜ê²½ (ìˆœìˆ˜ ìƒ‰ìƒ) - ì—„ê²©
    """
    r, g, b = rgb
    
    # 1. 1:1:1 ëŒ€ê°ì„  ë°©í–¥ ë²¡í„° (ì •ê·œí™”)
    diagonal_vector = np.array([1, 1, 1]) / np.sqrt(3)  # (1/âˆš3, 1/âˆš3, 1/âˆš3)
    
    # 2. RGB ë²¡í„°
    rgb_vector = np.array([r, g, b])
    
    # 3. Zì¶• ì„±ë¶„ (1:1:1 ëŒ€ê°ì„ ì— íˆ¬ì˜) - ê´€ëŒ€í•œ ì¶•
    z_component = np.dot(rgb_vector, diagonal_vector)
    
    # 4. ëŒ€ê°ì„ ì— ìˆ˜ì§ì¸ í‰ë©´ìœ¼ë¡œ íˆ¬ì˜ (X,Yì¶• ì„±ë¶„) - ì—„ê²©í•œ ì¶•
    diagonal_projection = z_component * diagonal_vector
    perpendicular_vector = rgb_vector - diagonal_projection
    
    # 5. ìˆ˜ì§ ë²¡í„°ë¥¼ X,Yì¶•ìœ¼ë¡œ ë¶„í•´ (ì„ì˜ì˜ ì§êµ ì¢Œí‘œê³„)
    # Xì¶•: (1, -1, 0) ë°©í–¥ ì„±ë¶„
    x_axis = np.array([1, -1, 0]) / np.sqrt(2)
    x_component = np.dot(perpendicular_vector, x_axis)
    
    # Yì¶•: (1, 1, -2) ë°©í–¥ ì„±ë¶„ (Xì¶•ê³¼ ì§êµ)
    y_axis = np.array([1, 1, -2]) / np.sqrt(6)
    y_component = np.dot(perpendicular_vector, y_axis)
    
    return np.array([x_component, y_component, z_component])

def clip_ai_color_clustering(hold_data, vectors, original_image, masks, eps=0.3, use_dbscan=False):
    """
    ğŸ¤– CLIP AI ê¸°ë°˜ ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë§ (ê°œì„  ë²„ì „)
    
    Args:
        hold_data: í™€ë“œ ë°ì´í„° (ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì´ë¯¸ CLIP íŠ¹ì§• í¬í•¨ ê°€ëŠ¥)
        vectors: íŠ¹ì§• ë²¡í„° (ì‚¬ìš© ì•ˆ í•¨)
        original_image: ì›ë³¸ ì´ë¯¸ì§€
        masks: í™€ë“œ ë§ˆìŠ¤í¬ë“¤
        eps: DBSCAN epsilon (CLIP íŠ¹ì§• ë²¡í„° ê±°ë¦¬ ê¸°ì¤€)
        use_dbscan: Trueë©´ DBSCANìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§, Falseë©´ ì§ì ‘ ìƒ‰ìƒ ë§¤ì¹­
    
    Returns:
        hold_data: ê·¸ë£¹ ì •ë³´ê°€ ì¶”ê°€ëœ í™€ë“œ ë°ì´í„°
    """
    if len(hold_data) == 0:
        return hold_data
    
    print(f"\nğŸ¤– CLIP AI ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘")
    print(f"   í™€ë“œ ê°œìˆ˜: {len(hold_data)}ê°œ")
    print(f"   ëª¨ë“œ: {'DBSCAN (íŠ¹ì§• ë²¡í„° ê¸°ë°˜)' if use_dbscan else 'ì§ì ‘ ìƒ‰ìƒ ë§¤ì¹­'}")
    
    # CLIP íŠ¹ì§• ë²¡í„°ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
    has_clip_features = all("clip_features" in hold for hold in hold_data)
    
    if not has_clip_features:
        # ğŸš€ ì„±ëŠ¥ ìµœì í™”: ì „ì—­ CLIP ëª¨ë¸ ìºì‹œ ì‚¬ìš©
        global _clip_model, _clip_text_features, _clip_device
        
        if _clip_model is None:
            print("   ğŸ”„ CLIP ëª¨ë¸ ë¡œë”© ì¤‘...")
            _clip_device = "cuda" if torch.cuda.is_available() else "cpu"
            model, preprocess = clip.load("ViT-B/32", device=_clip_device)
            _clip_model = (model, preprocess)
            print(f"   âœ… CLIP ëª¨ë¸ ë¡œë”© ì™„ë£Œ (Device: {_clip_device})")
        else:
            print("   âœ… CLIP ëª¨ë¸ ìºì‹œ ì‚¬ìš© (Device: {})".format(_clip_device))
            model, preprocess = _clip_model
        
        # ê° í™€ë“œì˜ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
        print("   ğŸ” CLIP íŠ¹ì§• ë²¡í„° ì¶”ì¶œ ì¤‘...")
        for i, hold in enumerate(hold_data):
            mask = masks[hold["id"]].astype(np.uint8) * 255
            y_coords, x_coords = np.where(mask > 0)
            if len(y_coords) == 0:
                hold["clip_features"] = np.zeros(512).tolist()
                continue
                
            y_min, y_max = y_coords.min(), y_coords.max()
            x_min, x_max = x_coords.min(), x_coords.max()
            hold_image = original_image[y_min:y_max+1, x_min:x_max+1]
            hold_pil = Image.fromarray(cv2.cvtColor(hold_image, cv2.COLOR_BGR2RGB))
            
            image_input = preprocess(hold_pil).unsqueeze(0).to(_clip_device)
            with torch.no_grad():
                image_feature = model.encode_image(image_input)
                image_feature = image_feature / image_feature.norm(dim=-1, keepdim=True)
            
            hold["clip_features"] = image_feature.squeeze().cpu().numpy().tolist()
    
    # CLIP íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
    clip_features = np.array([hold["clip_features"] for hold in hold_data])
    
    if use_dbscan:
        # ğŸ”· ëª¨ë“œ 1: DBSCANìœ¼ë¡œ ìë™ í´ëŸ¬ìŠ¤í„°ë§
        print(f"   ğŸ¯ DBSCAN í´ëŸ¬ìŠ¤í„°ë§ (eps={eps})")
        from sklearn.metrics.pairwise import cosine_distances
        
        # ì½”ì‚¬ì¸ ê±°ë¦¬ ê³„ì‚°
        distances = cosine_distances(clip_features)
        
        # DBSCAN í´ëŸ¬ìŠ¤í„°ë§
        dbscan = DBSCAN(eps=eps, min_samples=1, metric='precomputed')
        labels = dbscan.fit_predict(distances)
        
        # ê·¸ë£¹ í• ë‹¹
        for i, hold in enumerate(hold_data):
            hold["group"] = f"clip_g{labels[i]}"
        
        # í†µê³„
        unique_labels = set(labels)
        print(f"\nâœ… CLIP DBSCAN í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ")
        print(f"   ê·¸ë£¹ ê°œìˆ˜: {len(unique_labels)}ê°œ")
        for label in sorted(unique_labels):
            count = np.sum(labels == label)
            print(f"   ê·¸ë£¹ {label}: {count}ê°œ í™€ë“œ")
    else:
        # ğŸ”· ëª¨ë“œ 2: ìƒ‰ìƒ í”„ë¡¬í”„íŠ¸ ì§ì ‘ ë§¤ì¹­ + ê²€ì •ìƒ‰ ê°•ì œ ê°ì§€
        print("   ğŸ¨ ìƒ‰ìƒ í”„ë¡¬í”„íŠ¸ ë§¤ì¹­ ì¤‘...")
        
        # ğŸš€ ì„±ëŠ¥ ìµœì í™”: ì „ì—­ ìºì‹œ ì‚¬ìš©
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ğŸš€ ëª¨ë“  í™€ë“œë¥¼ í•œ ë²ˆì— CLIPìœ¼ë¡œ ìƒ‰ìƒ ë¶„ì„
        print("   ğŸ¨ ëª¨ë“  í™€ë“œë¥¼ í•œ ë²ˆì— CLIPìœ¼ë¡œ ìƒ‰ìƒ ë¶„ì„ ì¤‘...")
        
        if _clip_model is None or _clip_device != device:
            print("   ğŸ”„ CLIP ëª¨ë¸ ë¡œë”© ì¤‘...")
            model, preprocess = clip.load("ViT-B/32", device=device)
            _clip_model = (model, preprocess)
            _clip_device = device
            print("   âœ… CLIP ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        else:
            print("   âš¡ CLIP ëª¨ë¸ ìºì‹œ ì‚¬ìš©")
            model, preprocess = _clip_model
        
        # ğŸ¯ ëª¨ë“  ìƒ‰ìƒ í”„ë¡¬í”„íŠ¸ (ê²€ì •ìƒ‰ í¬í•¨)
        color_prompts = [
            "a black climbing hold", "a very dark black climbing hold", "a dark black climbing hold",
            "a white climbing hold", "a bright white climbing hold", "a pure white climbing hold",
            "a gray climbing hold", "a light gray climbing hold", "a dark gray climbing hold",
            "an orange climbing hold", "a bright orange climbing hold", "a vivid orange climbing hold",
            "a yellow climbing hold", "a bright yellow climbing hold", "a pure yellow climbing hold",
            "a red climbing hold", "a bright red climbing hold", "a vivid red climbing hold",
            "a pink climbing hold", "a bright pink climbing hold", "a hot pink climbing hold",
            "a blue climbing hold", "a light blue climbing hold", "a sky blue climbing hold",
            "a green climbing hold", "a bright green climbing hold", "a forest green climbing hold",
            "a purple climbing hold", "a bright purple climbing hold", "a violet climbing hold",
            "a brown climbing hold", "a dark brown climbing hold", "a light brown climbing hold"
        ]
        
        color_map = {
            "black": ["black", "very dark black", "dark black"],
            "white": ["white", "bright white", "pure white"],
            "gray": ["gray", "light gray", "dark gray"],
            "orange": ["orange", "bright orange", "vivid orange"],
            "yellow": ["yellow", "bright yellow", "pure yellow"],
            "red": ["red", "bright red", "vivid red"],
            "pink": ["pink", "bright pink", "hot pink"],
            "blue": ["blue", "light blue", "sky blue"],
            "green": ["green", "bright green", "forest green"],
            "purple": ["purple", "bright purple", "violet"],
            "brown": ["brown", "dark brown", "light brown"]
        }
        
        # í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ
        if _clip_text_features is None:
            print("   ğŸ“ í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
            text_tokens = clip.tokenize(color_prompts).to(device)
            with torch.no_grad():
                text_features = model.encode_text(text_tokens)
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)
            _clip_text_features = text_features
            print("   âœ… í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")
        else:
            print("   âš¡ ìºì‹œëœ í…ìŠ¤íŠ¸ íŠ¹ì§• ì‚¬ìš©")
            text_features = _clip_text_features
        
        # ëª¨ë“  í™€ë“œì˜ CLIP íŠ¹ì§• ì¶”ì¶œ
        print(f"   ğŸ–¼ï¸ {len(hold_data)}ê°œ í™€ë“œì˜ CLIP íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
        batch_size = 32
        all_image_features = []
        valid_indices = []
        
        for batch_start in range(0, len(hold_data), batch_size):
            batch_end = min(batch_start + batch_size, len(hold_data))
            batch_holds = hold_data[batch_start:batch_end]
            
            processed_images = []
            batch_valid_indices = []
            
            for i, hold in enumerate(batch_holds):
                actual_idx = batch_start + i
                mask = masks[hold["id"]].astype(np.uint8) * 255
                y_coords, x_coords = np.where(mask > 0)
                if len(y_coords) == 0:
                    continue
                
                y_min, y_max = y_coords.min(), y_coords.max()
                x_min, x_max = x_coords.min(), x_coords.max()
                hold_image = original_image[y_min:y_max+1, x_min:x_max+1]
                hold_pil = Image.fromarray(cv2.cvtColor(hold_image, cv2.COLOR_BGR2RGB))
                
                processed_images.append(preprocess(hold_pil))
                batch_valid_indices.append(actual_idx)
            
            if processed_images:
                image_tensor = torch.stack(processed_images).to(device)
                with torch.no_grad():
                    image_features = model.encode_image(image_tensor)
                    image_features = image_features / image_features.norm(dim=-1, keepdim=True)
                
                all_image_features.append(image_features.cpu().numpy())
                valid_indices.extend(batch_valid_indices)
        
        if not all_image_features:
            print("   âš ï¸ ì²˜ë¦¬í•  í™€ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return hold_data
        
        # ëª¨ë“  ì´ë¯¸ì§€ íŠ¹ì§• í•©ì¹˜ê¸°
        all_image_features = np.vstack(all_image_features)
        print(f"   âœ… {len(all_image_features)}ê°œ í™€ë“œì˜ CLIP íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")
        
        # ìœ ì‚¬ë„ ê³„ì‚° (ëª¨ë“  í™€ë“œ)
        clip_features_tensor = torch.from_numpy(all_image_features).float().to(device)
        similarities = (clip_features_tensor @ text_features.T).cpu().numpy()
        
        # ìƒ‰ìƒ ê·¸ë£¹ í• ë‹¹ (ëª¨ë“  í™€ë“œ)
        color_groups = {}
        for i, orig_idx in enumerate(valid_indices):
            best_idx = np.argmax(similarities[i])
            best_prompt = color_prompts[best_idx]
            confidence = similarities[i][best_idx]
            
            # ìƒ‰ìƒ ì´ë¦„ ì¶”ì¶œ
            color_name = "unknown"
            for color, keywords in color_map.items():
                for keyword in keywords:
                    if keyword in best_prompt:
                        color_name = color
                        break
                if color_name != "unknown":
                    break
            
            # í™€ë“œì— ìƒ‰ìƒ ì •ë³´ ì €ì¥
            hold_data[orig_idx]["color_name"] = color_name
            hold_data[orig_idx]["color_confidence"] = confidence
            
            # ê·¸ë£¹í•‘
            if color_name not in color_groups:
                color_groups[color_name] = []
            color_groups[color_name].append(orig_idx)
        
        # ìƒ‰ìƒë³„ ê·¸ë£¹ ID í• ë‹¹
        group_id = 0
        for color, indices in color_groups.items():
            for idx in indices:
                hold_data[idx]["group"] = group_id
            group_id += 1
        
        print(f"   âœ… ìƒ‰ìƒë³„ ê·¸ë£¹í•‘ ì™„ë£Œ: {len(color_groups)}ê°œ ê·¸ë£¹")
        for color, indices in color_groups.items():
            print(f"   {color}: {len(indices)}ê°œ")
        
        return hold_data
        
        # ğŸ¤– CLIP AI ê°œì„ : ëª¨ë“  í™€ë“œì— ëŒ€í•´ CLIP AIë¡œ ìƒ‰ìƒ íŒë‹¨
        print("   ğŸ¤– CLIP AI ìƒ‰ìƒ íŒë‹¨ ê°œì„  ì¤‘...")
        
        # ğŸ¯ ëŒ€í­ í™•ì¥ëœ ìƒ‰ìƒ ë¶„ë¥˜ ì²´ê³„ (ìƒ‰ìƒë‹¹ 5ê°œ ì´ìƒ, ì´ˆë¡/ë…¸ë‘ ëª…í™•íˆ êµ¬ë¶„)
        color_prompts = [
            # âš« ê²€ì •ìƒ‰ (8ê°œ)
            "a black climbing hold",
            "a very dark black climbing hold", 
            "a dark black climbing hold",
            "a charcoal black climbing hold",
            "a jet black climbing hold",
            "a pitch black climbing hold",
            "a coal black climbing hold",
            "a midnight black climbing hold",
            
            # âšª í°ìƒ‰ (8ê°œ)
            "a white climbing hold",
            "a bright white climbing hold",
            "a pure white climbing hold",
            "a snow white climbing hold",
            "a pearl white climbing hold",
            "a clean white climbing hold",
            "a chalk white climbing hold",
            "a fresh white climbing hold",
            
            # ğŸ”˜ íšŒìƒ‰ (8ê°œ)
            "a gray climbing hold",
            "a light gray climbing hold",
            "a dark gray climbing hold",
            "a medium gray climbing hold",
            "a silver climbing hold",
            "a neutral gray climbing hold",
            "a slate gray climbing hold",
            "a stone gray climbing hold",
            
            # ğŸŸ  ì£¼í™©ìƒ‰ (8ê°œ)
            "an orange climbing hold",
            "a bright orange climbing hold",
            "a vivid orange climbing hold",
            "a pumpkin orange climbing hold",
            "a tangerine orange climbing hold",
            "a flame orange climbing hold",
            "a traffic orange climbing hold",
            "a sunset orange climbing hold",
            
            # ğŸŸ¡ ë…¸ë€ìƒ‰ (10ê°œ - ì´ˆë¡ê³¼ ëª…í™•íˆ êµ¬ë¶„)
            "a yellow climbing hold",
            "a bright yellow climbing hold",
            "a pure yellow climbing hold",
            "a lemon yellow climbing hold",
            "a golden yellow climbing hold",
            "a sunshine yellow climbing hold",
            "a canary yellow climbing hold",
            "a banana yellow climbing hold",
            "a mustard yellow climbing hold",
            "a highlighter yellow climbing hold",
            
            # ğŸ”´ ë¹¨ê°„ìƒ‰ (8ê°œ)
            "a red climbing hold",
            "a bright red climbing hold",
            "a vivid red climbing hold",
            "a cherry red climbing hold",
            "a crimson red climbing hold",
            "a scarlet red climbing hold",
            "a burgundy red climbing hold",
            "a wine red climbing hold",
            
            # ğŸ©· ë¶„í™ìƒ‰ (7ê°œ)
            "a pink climbing hold",
            "a bright pink climbing hold",
            "a hot pink climbing hold",
            "a rose pink climbing hold",
            "a coral pink climbing hold",
            "a fuchsia pink climbing hold",
            "a bubblegum pink climbing hold",
            
            # ğŸ”µ íŒŒë€ìƒ‰ (10ê°œ)
            "a blue climbing hold",
            "a bright blue climbing hold",
            "a pure blue climbing hold",
            "a light blue climbing hold",
            "a sky blue climbing hold",
            "a baby blue climbing hold",
            "a royal blue climbing hold",
            "a navy blue climbing hold",
            "a dark blue climbing hold",
            "a cobalt blue climbing hold",
            
            # ğŸŸ¢ ì´ˆë¡ìƒ‰ (12ê°œ - ë…¸ë‘ê³¼ ëª…í™•íˆ êµ¬ë¶„, ë‹¤ì–‘í•œ í†¤)
            "a green climbing hold",
            "a pure green climbing hold",
            "a bright green climbing hold",
            "a vivid green climbing hold",
            "a grass green climbing hold",
            "a forest green climbing hold",
            "a dark green climbing hold",
            "an emerald green climbing hold",
            "a kelly green climbing hold",
            "a jade green climbing hold",
            "an olive green climbing hold",
            "a moss green climbing hold",
            
            # ğŸ’š ë¯¼íŠ¸ìƒ‰ (ìƒˆë¡œ ì¶”ê°€ - 6ê°œ)
            "a mint climbing hold",
            "a mint green climbing hold",
            "a light mint climbing hold",
            "a fresh mint climbing hold",
            "a turquoise mint climbing hold",
            "a pastel mint climbing hold",
            
            # ğŸƒ ì—°ë‘ìƒ‰ (ìƒˆë¡œ ì¶”ê°€ - 6ê°œ, ë…¸ë‘/ì´ˆë¡ ì¤‘ê°„)
            "a lime climbing hold",
            "a lime green climbing hold",
            "a bright lime climbing hold",
            "a neon lime climbing hold",
            "a chartreuse climbing hold",
            "a yellow-green climbing hold",
            
            # ğŸŸ£ ë³´ë¼ìƒ‰ (7ê°œ)
            "a purple climbing hold",
            "a bright purple climbing hold",
            "a dark purple climbing hold",
            "a violet climbing hold",
            "a lavender climbing hold",
            "a lilac climbing hold",
            "a magenta climbing hold",
            
            # ğŸŸ¤ ê°ˆìƒ‰ (7ê°œ)
            "a brown climbing hold",
            "a dark brown climbing hold",
            "a light brown climbing hold",
            "a tan climbing hold",
            "a beige climbing hold",
            "a chocolate brown climbing hold",
            "a coffee brown climbing hold"
        ]
        
        # ğŸ¯ í™•ì¥ëœ ìƒ‰ìƒ ë§¤í•‘ (ë¯¼íŠ¸/ì—°ë‘ ì¶”ê°€, ì´ˆë¡/ë…¸ë‘ ëª…í™•íˆ êµ¬ë¶„)
        color_map = {
            "black": ["black", "very dark black", "dark black", "charcoal", "jet black", "pitch black", 
                     "coal black", "midnight black"],
            
            "white": ["white", "bright white", "pure white", "snow white", "pearl white", "clean white",
                     "chalk white", "fresh white"],
            
            "gray": ["gray", "light gray", "dark gray", "medium gray", "silver", "neutral gray",
                    "slate", "stone"],
            
            "orange": ["orange", "bright orange", "vivid orange", "pumpkin", "tangerine", "flame",
                      "traffic", "sunset"],
            
            "yellow": ["yellow", "bright yellow", "pure yellow", "lemon", "golden", "sunshine", 
                      "canary", "banana", "mustard", "highlighter"],
            
            "red": ["red", "bright red", "vivid red", "cherry", "crimson", "scarlet", "burgundy", "wine"],
            
            "pink": ["pink", "bright pink", "hot pink", "rose pink", "coral pink", "fuchsia", "bubblegum"],
            
            "blue": ["blue", "bright blue", "pure blue", "light blue", "sky blue", "baby blue", 
                    "royal blue", "navy", "dark blue", "cobalt"],
            
            "green": ["green", "pure green", "bright green", "vivid green", "grass", "forest", 
                     "dark green", "emerald", "kelly", "jade", "olive", "moss"],
            
            "mint": ["mint", "mint green", "light mint", "fresh mint", "turquoise mint", "pastel mint"],
            
            "lime": ["lime", "lime green", "bright lime", "neon lime", "chartreuse", "yellow-green"],
            
            "purple": ["purple", "bright purple", "dark purple", "violet", "lavender", "lilac", "magenta"],
            
            "brown": ["brown", "dark brown", "light brown", "tan", "beige", "chocolate", "coffee"]
        }
        
        # ğŸ¤– ëª¨ë“  í™€ë“œì— ëŒ€í•´ CLIP AI ë§¤ì¹­ ìˆ˜í–‰ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        # ğŸš€ ì„±ëŠ¥ ìµœì í™”: í…ìŠ¤íŠ¸ íŠ¹ì§• ìºì‹±
        if _clip_text_features is None:
            print("   ğŸ”„ í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
            text_tokens = clip.tokenize(color_prompts).to(device)
            with torch.no_grad():
                text_features = model.encode_text(text_tokens)
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)
            _clip_text_features = text_features
            print("   âœ… í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")
        else:
            print("   âš¡ ìºì‹œëœ í…ìŠ¤íŠ¸ íŠ¹ì§• ì‚¬ìš©")
            text_features = _clip_text_features
        
        # ìœ ì‚¬ë„ ê³„ì‚° (ëª¨ë“  í™€ë“œ)
        clip_features_tensor = torch.from_numpy(clip_features).float().to(device)
        similarities = (clip_features_tensor @ text_features.T).cpu().numpy()
        
        # ìƒ‰ìƒ ê·¸ë£¹ í• ë‹¹ (ëª¨ë“  í™€ë“œ)
        color_groups = {}
        for i, hold in enumerate(hold_data):
            best_idx = np.argmax(similarities[i])
            best_prompt = color_prompts[best_idx]
            confidence = similarities[i][best_idx]
            
            # ìƒ‰ìƒ ì´ë¦„ ì¶”ì¶œ (í”„ë¡¬í”„íŠ¸ì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­)
            color_name = "unknown"
            for color, keywords in color_map.items():
                for keyword in keywords:
                    if keyword in best_prompt:
                        color_name = color
                        break
                if color_name != "unknown":
                    break
            
            # ğŸ¯ CLIP AI ê²°ê³¼ í›„ì²˜ë¦¬ ë³´ì • (ëª…í™•í•œ ì˜¤ë¥˜ ìˆ˜ì • - ê°•í™”)
            rgb = hold.get("dominant_rgb", [128, 128, 128])
            if len(rgb) >= 3:
                r, g, b = rgb[0], rgb[1], rgb[2]
                avg_brightness = (r + g + b) / 3
                max_rgb = max(r, g, b)
                min_rgb = min(r, g, b)
                channel_diff = max_rgb - min_rgb
                
                # ğŸš¨ Unknown ìƒ‰ìƒ ê°•ì œ ë¶„ë¥˜ (RGB ê¸°ë°˜ - ë¯¼íŠ¸/ì—°ë‘ ì¶”ê°€)
                if color_name == "unknown":
                    print(f"   âš ï¸ í™€ë“œ {hold['id']} RGB{tuple(rgb)} - unknown ê°ì§€, RGB ê¸°ë°˜ ì¬ë¶„ë¥˜ ì‹œë„")
                    
                    # ë¯¼íŠ¸ìƒ‰ ì²´í¬ (G > R, B > R, G â‰ˆ B, ë°ìŒ)
                    if g > r + 30 and b > r + 30 and abs(g - b) < 30 and avg_brightness > 150:
                        color_name = "mint"
                        confidence = 0.88
                        print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ mint (ë¯¼íŠ¸ìƒ‰)")
                    # ì—°ë‘ìƒ‰ ì²´í¬ (Gê°€ ê°€ì¥ ë†’ê³ , R > B, R â‰ˆ G)
                    elif g > b + 40 and r > b + 20 and abs(r - g) < 50:
                        color_name = "lime"
                        confidence = 0.88
                        print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ lime (ì—°ë‘ìƒ‰)")
                    # ì´ˆë¡ìƒ‰ ì²´í¬ (Gê°€ í™•ì‹¤íˆ ë†’ìŒ)
                    elif g > r + 30 and g > b + 30:
                        color_name = "green"
                        confidence = 0.90
                        print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ green (ì´ˆë¡ìƒ‰)")
                    # ì£¼í™©ìƒ‰ ì²´í¬ (RGB(195,118,74) ê°™ì€ ì¼€ì´ìŠ¤)
                    elif r > g + 30 and r > b + 50 and g > b:
                        color_name = "orange"
                        confidence = 0.90
                        print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ orange (ì£¼í™©ìƒ‰)")
                    # ë…¸ë€ìƒ‰ ì²´í¬ (R â‰ˆ G, ë‘˜ ë‹¤ Bë³´ë‹¤ ë†’ìŒ)
                    elif r > b + 50 and g > b + 50 and abs(r - g) < 40:
                        color_name = "yellow"
                        confidence = 0.90
                        print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ yellow (ë…¸ë€ìƒ‰)")
                    # íŒŒë€ìƒ‰ ì²´í¬
                    elif b > r + 20 and b > g + 20:
                        color_name = "blue"
                        confidence = 0.90
                        print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ blue (íŒŒë€ìƒ‰)")
                    # ë¹¨ê°„ìƒ‰ ì²´í¬
                    elif r > g + 30 and r > b + 30:
                        color_name = "red"
                        confidence = 0.90
                        print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ red (ë¹¨ê°„ìƒ‰)")
                    # ë¬´ì±„ìƒ‰ ì²´í¬
                    elif channel_diff < 15:
                        if avg_brightness > 200:
                            color_name = "white"
                            confidence = 0.95
                            print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ white (ë°ì€ ë¬´ì±„ìƒ‰)")
                        elif avg_brightness > 100:
                            color_name = "gray"
                            confidence = 0.95
                            print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ gray (ì¤‘ê°„ ë¬´ì±„ìƒ‰)")
                        else:
                            color_name = "black"
                            confidence = 0.95
                            print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ black (ì–´ë‘ìš´ ë¬´ì±„ìƒ‰)")
                    # ê°ˆìƒ‰ ì²´í¬ (ì–´ë‘ìš´ ì£¼í™©ìƒ‰)
                    elif r > g + 10 and r > b + 20 and avg_brightness < 150:
                        color_name = "brown"
                        confidence = 0.85
                        print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜: í™€ë“œ {hold['id']} - unknown â†’ brown (ê°ˆìƒ‰)")
                    else:
                        # ìµœí›„ì˜ ìˆ˜ë‹¨: ê°€ì¥ ë†’ì€ ì±„ë„ ê¸°ì¤€
                        if r > g and r > b:
                            color_name = "red"
                        elif g > r and g > b:
                            color_name = "green"
                        elif b > r and b > g:
                            color_name = "blue"
                        else:
                            color_name = "gray"
                        confidence = 0.70
                        print(f"   ğŸ”§ RGB ì¬ë¶„ë¥˜ (ìµœì¢…): í™€ë“œ {hold['id']} - unknown â†’ {color_name} (ìµœê³  ì±„ë„ ê¸°ì¤€)")
                
                # ğŸ–¤ ê²€ì •ìƒ‰ ë³´ì •: ë§¤ìš° ì–´ë‘ìš´ ìƒ‰ìƒ (RGB(43,54,72) ê°™ì€ ì¼€ì´ìŠ¤)
                elif avg_brightness <= 70 and max_rgb <= 80:
                    if color_name != "black":
                        print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - {color_name} â†’ black (ë§¤ìš° ì–´ë‘ì›€)")
                        color_name = "black"
                        confidence = 0.99
                
                # âšª ë¬´ì±„ìƒ‰ ë³´ì • (RGB(194,199,198) ê°™ì€ ì¼€ì´ìŠ¤ - ì±„ë„ ì°¨ì´ < 15)
                elif channel_diff < 15:
                    # ë°ì€ í°ìƒ‰
                    if avg_brightness > 200:
                        if color_name not in ["white"]:
                            print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - {color_name} â†’ white (ë°ì€ ë¬´ì±„ìƒ‰)")
                            color_name = "white"
                            confidence = 0.99
                    # ì¤‘ê°„ ë°ê¸° íšŒìƒ‰ (RGB(194,199,198) ê°™ì€ ì¼€ì´ìŠ¤)
                    elif avg_brightness > 150:
                        if color_name not in ["white", "gray"]:
                            print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - {color_name} â†’ gray (ì¤‘ê°„ ë¬´ì±„ìƒ‰)")
                            color_name = "gray"
                            confidence = 0.99
                    # ì–´ë‘ìš´ íšŒìƒ‰
                    elif avg_brightness > 80:
                        if color_name not in ["gray", "black"]:
                            print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - {color_name} â†’ gray (ì–´ë‘ìš´ ë¬´ì±„ìƒ‰)")
                            color_name = "gray"
                            confidence = 0.98
                    # ë§¤ìš° ì–´ë‘ìš´ ê²€ì •
                    else:
                        if color_name not in ["black"]:
                            print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - {color_name} â†’ black (ì–´ë‘ìš´ ë¬´ì±„ìƒ‰)")
                            color_name = "black"
                            confidence = 0.98
                
                # âšª í°ìƒ‰ ë³´ì •: ë§¤ìš° ë°ì€ ìƒ‰ìƒ (í‰ê·  ë°ê¸° > 200, ì±„ë„ ì°¨ì´ < 30)
                elif avg_brightness > 200 and channel_diff < 30:
                    if color_name not in ["white", "gray"]:
                        print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - {color_name} â†’ white (ë§¤ìš° ë°ìŒ)")
                        color_name = "white"
                        confidence = 0.98
                
                # ğŸ”µ ë°ì€ íŒŒë€ìƒ‰ ë³´ì •: íŒŒë€ìƒ‰ ì±„ë„ì´ ë†’ê³  ë°ì€ ê²½ìš°
                elif avg_brightness > 180 and b > r + 15 and b > g + 10:
                    if color_name not in ["blue", "white"]:
                        print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - {color_name} â†’ blue (ë°ì€ íŒŒë€ìƒ‰)")
                        color_name = "blue"
                        confidence = 0.95
                
                # âšª ê²€ì •ìƒ‰ìœ¼ë¡œ ì˜ëª» ë¶„ë¥˜ëœ ë°ì€ ìƒ‰ìƒ ë³´ì •
                elif color_name == "black" and avg_brightness > 150:
                    # í•˜ëŠ˜ìƒ‰ ì²´í¬ (RGB(184,223,237) ê°™ì€ ì¼€ì´ìŠ¤)
                    if b > r + 10 and b > g + 5:
                        print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - black â†’ blue (í•˜ëŠ˜ìƒ‰)")
                        color_name = "blue"
                        confidence = 0.95
                    # ë°ì€ íšŒìƒ‰/í°ìƒ‰ ì²´í¬ (RGB(202,199,187) ê°™ì€ ì¼€ì´ìŠ¤)
                    elif channel_diff < 30:
                        if avg_brightness > 190:
                            print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - black â†’ white (ë°ì€ í°ìƒ‰)")
                            color_name = "white"
                            confidence = 0.95
                        else:
                            print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - black â†’ gray (ë°ì€ íšŒìƒ‰)")
                            color_name = "gray"
                            confidence = 0.95
                    # ì¼ë°˜ ë°ì€ ìƒ‰ìƒ
                    else:
                        print(f"   ğŸ”§ í›„ì²˜ë¦¬ ë³´ì •: í™€ë“œ {hold['id']} RGB{tuple(rgb)} - black â†’ white (ë°ì€ ìƒ‰ìƒ)")
                        color_name = "white"
                        confidence = 0.95
            
            hold["group"] = f"ai_{color_name}"
            hold["clip_color_name"] = color_name
            hold["clip_confidence"] = float(confidence)
            
            if color_name not in color_groups:
                color_groups[color_name] = []
            color_groups[color_name].append(hold["id"])
            
            print(f"   í™€ë“œ {hold['id']}: {color_name} (ì‹ ë¢°ë„: {confidence:.3f}) - RGB{tuple(rgb)}")
        
        # ğŸ”· ìµœì¢… ê·¸ë£¹ ì •ë³´ í†µí•©
        final_color_groups = {}
        for hold in hold_data:
            group_name = hold.get("group", "ai_unknown")
            color_name = group_name.replace("ai_", "")
            if color_name not in final_color_groups:
                final_color_groups[color_name] = []
            final_color_groups[color_name].append(hold["id"])
            
            confidence = hold.get("clip_confidence", 0.0)
            print(f"   í™€ë“œ {hold['id']}: {color_name} (ì‹ ë¢°ë„: {confidence:.3f})")
        
        print(f"\nâœ… CLIP AI í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ")
        for color, hold_ids in sorted(final_color_groups.items()):
            print(f"   {color}: {len(hold_ids)}ê°œ í™€ë“œ")
    
    return hold_data

def lighting_invariant_dbscan_clustering(hold_data, vectors, eps=0.3, eps_black_gray=1.0, eps_white=1.0, eps_color=2.0):
    """
    ğŸŒŸ ì¶•ë³„ ê°€ì¤‘ì¹˜ ì¡°ëª… ë¶ˆë³€ í´ëŸ¬ìŠ¤í„°ë§
    
    xyì¶• (ìƒ‰ìƒ): ì—„ê²©í•œ eps ì ìš©
    zì¶• (ëŒ€ê°ì„ /ì¡°ëª…): ê´€ëŒ€í•œ eps ì ìš©
    """
    if len(hold_data) == 0:
        return hold_data
    
    print(f"\nğŸŒŸ ì¶•ë³„ ê°€ì¤‘ì¹˜ ì¡°ëª… ë¶ˆë³€ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘")
    print(f"   ê¸°ë³¸ eps: {eps}")
    print(f"   xyì¶•(ìƒ‰ìƒ): ì—„ê²©í•œ eps, zì¶•(ì¡°ëª…): ê´€ëŒ€í•œ eps")
    
    # HSV â†’ RGB ë³€í™˜
    rgb_values = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        hsv_arr = np.uint8([[[h, s, v]]])
        rgb = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
        rgb_values.append(rgb)
    
    rgb_values = np.array(rgb_values)
    
    # ì¶•ë³„ ê°€ì¤‘ì¹˜ ë³€í™˜ ì ìš©
    transformed_rgb = np.array([transform_rgb_with_axis_weights(rgb) for rgb in rgb_values])
    
    print(f"   ì›ë³¸ RGB ìƒ˜í”Œ: {rgb_values[:3]}")
    print(f"   ë³€í™˜ RGB ìƒ˜í”Œ: {transformed_rgb[:3]}")
    
    # ì¶•ë³„ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
    from sklearn.metrics.pairwise import euclidean_distances
    
    # ê°€ì¤‘ì¹˜ ì„¤ì • (zì¶•ì€ ê´€ëŒ€í•˜ê²Œ)
    weights = np.array([1.0, 1.0, 0.3])  # x, y, z ì¶• ê°€ì¤‘ì¹˜
    
    # ê°€ì¤‘ì¹˜ ì ìš©ëœ ê±°ë¦¬ ê³„ì‚°
    weighted_distances = euclidean_distances(transformed_rgb * weights)
    
    # DBSCAN with precomputed distances
    if len(hold_data) == 1:
        labels = np.array([0])
    else:
        dbscan = DBSCAN(eps=eps, min_samples=1, metric='precomputed')
        labels = dbscan.fit_predict(weighted_distances)
    
    # ê·¸ë£¹ í• ë‹¹ ë° ë³€í™˜ëœ RGB ê°’ ì €ì¥
    group_id = 0
    for i, label in enumerate(labels):
        if label == -1:
            hold_data[i]["group"] = f"g{group_id}"
            group_id += 1
        else:
            hold_data[i]["group"] = f"g{group_id + label}"
        
        # ë³€í™˜ëœ RGB ê°’ì„ ì €ì¥ (2D ì‹œê°í™”ì—ì„œ ì‚¬ìš©)
        hold_data[i]["transformed_rgb"] = rgb_values[i].tolist()
    
    # ê·¸ë£¹ ìˆ˜ ê³„ì‚°
    unique_labels = set(labels)
    if -1 in unique_labels:
        group_count = len(unique_labels) - 1  # -1 ì œì™¸
    else:
        group_count = len(unique_labels)
    
    print(f"   ìƒì„±ëœ ê·¸ë£¹ ìˆ˜: {group_count}ê°œ")
    
    # í†µê³„ ì¶œë ¥
    groups = {}
    for hold in hold_data:
        g = hold["group"]
        if g not in groups:
            groups[g] = []
        groups[g].append(hold["id"])
    
    print(f"\nâœ… ì´ {len(groups)}ê°œ ê·¸ë£¹ ìƒì„±")
    for g in sorted(groups.keys()):
        print(f"   {g}: {len(groups[g])}ê°œ í™€ë“œ")
    
    return hold_data

def create_clip_3d_visualization(hold_data, selected_hold_id=None, eps=None):
    """
    ğŸ¤– CLIP íŠ¹ì§• ë²¡í„° 3D ì‹œê°í™” (PCAë¡œ ì°¨ì› ì¶•ì†Œ)
    """
    if len(hold_data) == 0:
        return None
    
    # CLIP íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
    clip_features = np.array([hold.get("clip_features", np.zeros(512)) for hold in hold_data])
    
    # PCAë¡œ 3Dë¡œ ì¶•ì†Œ
    from sklearn.decomposition import PCA
    pca = PCA(n_components=3)
    clip_3d = pca.fit_transform(clip_features)
    
    # ê·¸ë£¹ë³„ ìƒ‰ìƒ ë§¤í•‘
    groups = {}
    for hold in hold_data:
        g = hold.get("group", "unknown")
        if g not in groups:
            groups[g] = []
        groups[g].append(hold["id"])
    
    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
    group_colors = [
        '#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7',
        '#DDA0DD', '#98D8C8', '#F7DC6F', '#BB8FCE', '#85C1E9'
    ]
    
    # 3D í”Œë¡¯ ìƒì„±
    fig = go.Figure()
    
    # ê·¸ë£¹ë³„ë¡œ ì  ì¶”ê°€
    for i, group_id in enumerate(sorted(groups.keys())):
        group_hold_ids = groups[group_id]
        group_mask = [hold["id"] in group_hold_ids for hold in hold_data]
        group_coords = clip_3d[group_mask]
        group_color = group_colors[i % len(group_colors)]
        
        # í˜¸ë²„ í…ìŠ¤íŠ¸ ìƒì„±
        hover_texts = []
        for hold in [h for h, m in zip(hold_data, group_mask) if m]:
            color_name = hold.get("clip_color_name", "unknown")
            confidence = hold.get("clip_confidence", 0.0)
            hover_texts.append(
                f"í™€ë“œ ID: {hold['id']}<br>"
                f"ê·¸ë£¹: {group_id}<br>"
                f"AI ìƒ‰ìƒ: {color_name}<br>"
                f"ì‹ ë¢°ë„: {confidence:.3f}"
            )
        
        fig.add_trace(go.Scatter3d(
            x=group_coords[:, 0],
            y=group_coords[:, 1],
            z=group_coords[:, 2],
            mode='markers+text',
            marker=dict(
                size=10,
                color=group_color,
                line=dict(width=1, color='black'),
                opacity=0.8
            ),
            text=[str(hold["id"]) for hold in [h for h, m in zip(hold_data, group_mask) if m]],
            textposition="middle center",
            name=f"ê·¸ë£¹ {group_id}",
            hovertext=hover_texts,
            hoverinfo='text'
        ))
    
    # ì„ íƒëœ í™€ë“œ ê°•ì¡°
    if selected_hold_id is not None:
        for i, hold in enumerate(hold_data):
            if hold["id"] == selected_hold_id:
                fig.add_trace(go.Scatter3d(
                    x=[clip_3d[i, 0]],
                    y=[clip_3d[i, 1]],
                    z=[clip_3d[i, 2]],
                    mode='markers',
                    marker=dict(
                        size=15,
                        color='yellow',
                        symbol='diamond',
                        line=dict(width=3, color='red')
                    ),
                    name=f"ì„ íƒëœ í™€ë“œ {selected_hold_id}",
                    showlegend=True
                ))
                break
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title="ğŸ¤– CLIP AI íŠ¹ì§• ë²¡í„° 3D ê³µê°„ (PCA íˆ¬ì˜)",
        scene=dict(
            xaxis_title="PC1 (ì£¼ì„±ë¶„ 1)",
            yaxis_title="PC2 (ì£¼ì„±ë¶„ 2)",
            zaxis_title="PC3 (ì£¼ì„±ë¶„ 3)"
        ),
        width=900,
        height=700,
        showlegend=True,
        hovermode='closest'
    )
    
    return fig

def create_compressed_2d_visualization(hold_data, selected_hold_id=None, eps=None):
    """
    ğŸ¨ ì••ì¶•ëœ 2D ë¶„í¬ë„ ì‹œê°í™” (ì‹¤ì œ í´ëŸ¬ìŠ¤í„°ë§ê³¼ ì—°ê²°)
    ê° ì ì— ì‹¤ì œ ìƒ‰ìƒê³¼ ê·¸ë£¹ ì •ë³´ í‘œì‹œ
    """
    if len(hold_data) == 0:
        return None
    
    # í´ëŸ¬ìŠ¤í„°ë§ì—ì„œ ì €ì¥ëœ ë³€í™˜ëœ RGB ê°’ ì‚¬ìš©
    rgb_values = []
    for hold in hold_data:
        if "transformed_rgb" in hold:
            # í´ëŸ¬ìŠ¤í„°ë§ì—ì„œ ì €ì¥ëœ ë³€í™˜ëœ RGB ê°’ ì‚¬ìš©
            rgb_values.append(hold["transformed_rgb"])
        else:
            # ë°±ì—…: HSV â†’ RGB ë³€í™˜
            h, s, v = hold["dominant_hsv"]
            hsv_arr = np.uint8([[[h, s, v]]])
            rgb = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
            rgb_values.append(rgb)
    
    rgb_values = np.array(rgb_values)
    
    # ì‹¤ì œ í´ëŸ¬ìŠ¤í„°ë§ì—ì„œ ì‚¬ìš©ëœ ë³€í™˜ ì¢Œí‘œ ê³„ì‚°
    transformed_coords = np.array([transform_rgb_with_axis_weights(rgb) for rgb in rgb_values])
    # 2D ì‹œê°í™”ë¥¼ ìœ„í•´ xyì¶•ë§Œ ì‚¬ìš©
    compressed_coords = transformed_coords[:, :2]  # x, y ì¶•ë§Œ
    
    # ê·¸ë£¹ë³„ ìƒ‰ìƒ ë§¤í•‘
    groups = {}
    for hold in hold_data:
        g = hold["group"]
        if g not in groups:
            groups[g] = []
        groups[g].append(hold["id"])
    
    # ê·¸ë£¹ë³„ ìƒ‰ìƒ ìƒì„± (ë” ë§ì€ ìƒ‰ìƒ)
    group_colors = [
        '#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7',
        '#DDA0DD', '#98D8C8', '#F7DC6F', '#BB8FCE', '#85C1E9',
        '#F8C471', '#82E0AA', '#F1948A', '#85C1E9', '#D7BDE2',
        '#A9DFBF', '#F9E79F', '#D5A6BD', '#AED6F1', '#A3E4D7'
    ]
    
    # ì‹œê°í™” ìƒì„±
    fig = go.Figure()
    
    # ê·¸ë£¹ë³„ë¡œ ì  ì¶”ê°€
    for i, group_id in enumerate(sorted(groups.keys())):
        group_hold_ids = groups[group_id]
        group_mask = [hold["id"] in group_hold_ids for hold in hold_data]
        group_coords = compressed_coords[group_mask]
        group_rgb = rgb_values[group_mask]
        
        # ê·¸ë£¹ ìƒ‰ìƒ ì„ íƒ (ìˆœí™˜)
        group_color = group_colors[i % len(group_colors)]
        
        # ê° í™€ë“œë³„ë¡œ ì‹¤ì œ RGB ìƒ‰ìƒìœ¼ë¡œ ì  ì¶”ê°€
        for j, (coord, rgb, hold) in enumerate(zip(group_coords, group_rgb, 
                                                   [h for h, m in zip(hold_data, group_mask) if m])):
            fig.add_trace(go.Scatter(
                x=[coord[0]],
                y=[coord[1]],
                mode='markers+text',
                marker=dict(
                    size=15,
                    color=f'rgb({rgb[0]},{rgb[1]},{rgb[2]})',  # ì‹¤ì œ RGB ìƒ‰ìƒ
                    line=dict(width=2, color='black'),
                    opacity=0.8
                ),
                text=[str(hold["id"])],
                textposition="middle center",
                name=f"ê·¸ë£¹ {group_id}",
                showlegend=(j == 0),  # ê·¸ë£¹ë‹¹ í•˜ë‚˜ë§Œ ë²”ë¡€ì— í‘œì‹œ
                hovertemplate=f"í™€ë“œ ID: {hold['id']}<br>ê·¸ë£¹: {group_id}<br>ì‹¤ì œ RGB: ({rgb[0]},{rgb[1]},{rgb[2]})<br>ë³€í™˜ ì¢Œí‘œ: ({coord[0]:.1f}, {coord[1]:.1f})<br>xyì¶•(ìƒ‰ìƒ): ì—„ê²©, zì¶•(ì¡°ëª…): ê´€ëŒ€<extra></extra>"
            ))
    
    # ì„ íƒëœ í™€ë“œ ê°•ì¡°
    if selected_hold_id is not None:
        for i, hold in enumerate(hold_data):
            if hold["id"] == selected_hold_id:
                fig.add_trace(go.Scatter(
                    x=[compressed_coords[i, 0]],
                    y=[compressed_coords[i, 1]],
                    mode='markers',
                    marker=dict(
                        size=25,
                        color='yellow',
                        symbol='star',
                        line=dict(width=4, color='red')
                    ),
                    name=f"ì„ íƒëœ í™€ë“œ {selected_hold_id}",
                    showlegend=True
                ))
                break
    
    # eps êµ¬ í‘œì‹œ (ì„ íƒëœ í™€ë“œê°€ ìˆì„ ë•Œ)
    if selected_hold_id is not None and eps is not None:
        for i, hold in enumerate(hold_data):
            if hold["id"] == selected_hold_id:
                center_x, center_y = compressed_coords[i, 0], compressed_coords[i, 1]
                
                # eps êµ¬ë¥¼ ì›ìœ¼ë¡œ í‘œì‹œ
                theta = np.linspace(0, 2*np.pi, 100)
                circle_x = center_x + eps * np.cos(theta)
                circle_y = center_y + eps * np.sin(theta)
                
                fig.add_trace(go.Scatter(
                    x=circle_x,
                    y=circle_y,
                    mode='lines',
                    line=dict(color='red', width=2, dash='dash'),
                    name=f'eps={eps} êµ¬',
                    showlegend=True
                ))
                break
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title=f"ğŸ¨ 1:1:1 ëŒ€ê°ì„  ê¸°ì¤€ 2D ë¶„í¬ë„ (X,Yì¶•: ì—„ê²©, Zì¶•: ê´€ëŒ€, eps={eps})",
        xaxis_title="Xì¶•: 1:1:1 ëŒ€ê°ì„ ì— ìˆ˜ì§ ì„±ë¶„ (ì—„ê²©í•œ eps)",
        yaxis_title="Yì¶•: 1:1:1 ëŒ€ê°ì„ ì— ìˆ˜ì§ ì„±ë¶„ (ì—„ê²©í•œ eps)",
        width=900,
        height=700,
        showlegend=True,
        hovermode='closest'
    )
    
    # ê²©ì ì¶”ê°€
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
    
    return fig

def create_gradient_background_heatmap(fig):
    """ğŸ¨ ê°„ë‹¨í•œ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒì„± (ì‚¬ê°í˜• ë°©ì‹)"""
    # ë” í° ê°„ê²©ìœ¼ë¡œ ê·¸ë¼ë°ì´ì…˜ ì‚¬ê°í˜• ìƒì„±
    for v in range(0, 256, 16):  # Value: 16ì”© ê°„ê²©
        for h in range(0, 180, 9):  # Hue: 9ë„ì”© ê°„ê²©
            # HSVë¥¼ RGBë¡œ ë³€í™˜ (Saturation=255ë¡œ ê³ ì •í•˜ì—¬ ìˆœìˆ˜í•œ ìƒ‰ìƒ)
            hsv_color = np.array([[[h, 255, v]]], dtype=np.uint8)
            rgb_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2RGB)[0][0]
            color_rgb = f"rgb({rgb_color[0]}, {rgb_color[1]}, {rgb_color[2]})"
            
            # ë°°ê²½ ì‚¬ê°í˜• ì¶”ê°€
            fig.add_shape(
                type="rect",
                x0=v, y0=h, x1=v+16, y1=h+9,  # Value(ê°€ë¡œ) Ã— Hue(ì„¸ë¡œ)
                fillcolor=color_rgb,
                line=dict(width=0),
                layer="below"
            )

def recommend_holds(hold_data, vectors, clicked_id, top_n=5, alpha=0.7, beta=0.3, gamma=0.5):
    """í™€ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ"""
    # í´ë¦­í•œ í™€ë“œ ì°¾ê¸°
    clicked_hold = None
    clicked_vector = None
    for i, hold in enumerate(hold_data):
        if hold["id"] == clicked_id:
            clicked_hold = hold
            clicked_vector = vectors[i]
            break
    
    if clicked_hold is None or clicked_vector is None:
        return []
    
    recommendations = []
    
    for i, (hold, vector) in enumerate(zip(hold_data, vectors)):
        if hold["id"] == clicked_id:
            continue  # ìê¸° ìì‹  ì œì™¸
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        cos_sim = cosine_similarity([clicked_vector], [vector])[0][0]
        
        # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
        euclid_dist = np.linalg.norm(clicked_vector - vector)
        
        # ê·¸ë£¹ ê²Œì´íŒ…: ê°™ì€ ê·¸ë£¹ì´ë©´ ë³´ë„ˆìŠ¤
        group_bonus = 1.0
        if clicked_hold["group"] is not None and hold["group"] is not None:
            if clicked_hold["group"] == hold["group"]:
                group_bonus = 1.0  # ê°™ì€ ê·¸ë£¹
            else:
                group_bonus = gamma  # ë‹¤ë¥¸ ê·¸ë£¹ íŒ¨ë„í‹°
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        score = (alpha * cos_sim + beta * (1 - euclid_dist)) * group_bonus
        
        recommendations.append((hold["id"], score))
    
    # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ Nê°œ ë°˜í™˜
    recommendations.sort(key=lambda x: x[1], reverse=True)
    return recommendations[:top_n]

def build_feature_vectors(hold_data, scaler_option="none", use_illumination_invariant=True):
    """ğŸš€ ê°•í™”ëœ íŠ¹ì§• ë²¡í„° ìƒì„± - ìƒ‰ìƒ + ê³µê°„ + í’ˆì§ˆ íŠ¹ì§•"""
    vectors = []
    ids = []
    
    # ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚° (ì •ê·œí™”ìš©)
    centers = [hold["center"] for hold in hold_data]
    areas = [hold.get("area", hold.get("size", 1)) for hold in hold_data]
    
    if centers:
        max_x = max(c[0] for c in centers)
        max_y = max(c[1] for c in centers)
        max_area = max(areas) if areas else 1
    else:
        max_x = max_y = max_area = 1
    
    for hold in hold_data:
        vec_components = []
        
        if use_illumination_invariant and "advanced" in hold:
            # ì¡°ëª… ë¶ˆë³€ íŠ¹ì§• (í•µì‹¬)
            advanced = hold["advanced"]
            
            # 1. Lab a*, b* (ì¡°ëª…ì— ê°€ì¥ ëœ ë¯¼ê°)
            if "lab_ab" in advanced:
                lab_a, lab_b = advanced["lab_ab"]
                vec_components.extend([
                    (lab_a - 128) / 128.0,  # ì •ê·œí™”
                    (lab_b - 128) / 128.0
                ])
            
            # 2. Hue, Saturation (Value ì œì™¸)
            if "hue_sat" in advanced:
                h, s = advanced["hue_sat"]
                h_rad = np.deg2rad(h / 180.0 * 360.0)
                vec_components.extend([
                    np.cos(h_rad),
                    np.sin(h_rad),
                    s / 255.0
                ])
            
            # 3. ìƒ‰ìƒ ìˆœë„
            if "color_purity" in advanced:
                vec_components.append(advanced["color_purity"])
            
            # 4. ìƒ‰ìƒ ê· ì¼ì„± (ë‚®ì„ìˆ˜ë¡ ê· ì¼í•œ ìƒ‰ìƒ)
            if "color_uniformity" in advanced:
                vec_components.append(advanced["color_uniformity"])
            
        else:
            # ê¸°ë³¸ HSV íŠ¹ì§• (í•˜ìœ„ í˜¸í™˜ì„±)
            h, s, v = hold["dominant_hsv"]
            h_rad = np.deg2rad(h / 180.0 * 360.0)
            vec_components = [np.cos(h_rad), np.sin(h_rad), s / 255.0, v / 255.0]
        
        # ğŸš€ ê³µê°„ì  íŠ¹ì§• ì¶”ê°€
        cx, cy = hold["center"]
        area = hold.get("area", hold.get("size", 1))
        
        spatial_features = [
            cx / max_x,  # ì •ê·œí™”ëœ X ìœ„ì¹˜
            cy / max_y,  # ì •ê·œí™”ëœ Y ìœ„ì¹˜
            area / max_area,  # ì •ê·œí™”ëœ í¬ê¸°
            hold.get("circularity", 0.5)  # ì›í˜•ë„ (0~1)
        ]
        vec_components.extend(spatial_features)
        
        vectors.append(np.array(vec_components))
        ids.append(hold["id"])
    
    vectors = np.array(vectors)

    if scaler_option == "standard":
        vectors = (vectors - np.mean(vectors, axis=0)) / (np.std(vectors, axis=0) + 1e-8)
    elif scaler_option == "minmax":
        vectors = (vectors - np.min(vectors, axis=0)) / (np.ptp(vectors, axis=0) + 1e-8)
    
    return vectors, ids

def color_specific_classification(hold_data):
    """ğŸš¨ ìƒ‰ìƒë³„ íŠ¹í™” ë¶„ë¥˜ ì‹œìŠ¤í…œ"""
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        
        # ê²€ì •ìƒ‰/í°ìƒ‰ íŠ¹ë³„ ì²˜ë¦¬ ì œê±° - RGB íë¸Œì—ì„œ ìˆœìˆ˜ ê±°ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
        
        # íšŒìƒ‰ í™€ë“œ (Saturation ë‚®ìŒ, Value ì¤‘ê°„)
        if s < 40 and 30 <= v <= 200:
            hold["color_category"] = "gray"
            hold["group"] = None  # ë‚˜ì¤‘ì— íšŒìƒ‰ ì „ìš© êµ°ì§‘í™”
        # 4. ë¹¨ê°„ìƒ‰ ê³„ì—´ (Hue 0-30ë„, 330-360ë„)
        elif (0 <= h <= 30) or (330 <= h <= 360):
            if s > 100 and v > 100:  # ì§„í•œ ë¹¨ê°„ìƒ‰
                hold["color_category"] = "red"
            elif s > 80 and v > 150:  # í•‘í¬ìƒ‰
                hold["color_category"] = "pink"
            else:
                hold["color_category"] = "red_light"
            hold["group"] = None
        # 5. ì£¼í™©ìƒ‰ ê³„ì—´ (Hue 15-45ë„)
        elif 15 <= h <= 45:
            hold["color_category"] = "orange"
            hold["group"] = None
        # 6. ë…¸ë€ìƒ‰ ê³„ì—´ (Hue 45-75ë„)
        elif 45 <= h <= 75:
            hold["color_category"] = "yellow"
            hold["group"] = None
        # 7. ì—°ë‘ìƒ‰ ê³„ì—´ (Hue 60-90ë„)
        elif 60 <= h <= 90:
            hold["color_category"] = "lime_green"
            hold["group"] = None
        # 8. ì´ˆë¡ìƒ‰ ê³„ì—´ (Hue 75-165ë„)
        elif 75 <= h <= 165:
            hold["color_category"] = "green"
            hold["group"] = None
        # 9. ì²­ë¡ìƒ‰ ê³„ì—´ (Hue 150-180ë„)
        elif 150 <= h <= 180:
            hold["color_category"] = "cyan"
            hold["group"] = None
        # 10. íŒŒë€ìƒ‰ ê³„ì—´ (Hue 180-240ë„)
        elif 180 <= h <= 240:
            if h <= 210:  # í•˜ëŠ˜ìƒ‰
                hold["color_category"] = "sky_blue"
            else:  # ì§„í•œ íŒŒë€ìƒ‰
                hold["color_category"] = "blue"
            hold["group"] = None
        # 11. ë‚¨ìƒ‰ ê³„ì—´ (Hue 240-270ë„)
        elif 240 <= h <= 270:
            hold["color_category"] = "navy_blue"
            hold["group"] = None
        # 12. ë³´ë¼ìƒ‰ ê³„ì—´ (Hue 270-330ë„)
        elif 270 <= h <= 330:
            hold["color_category"] = "purple"
            hold["group"] = None
        # 13. ê¸°íƒ€
        else:
            hold["color_category"] = "other"
            hold["group"] = None
    
    return hold_data

def cluster_by_color_category(hold_data, vectors, eps, min_samples, method):
    """ğŸš¨ ìƒ‰ìƒ ì¹´í…Œê³ ë¦¬ë³„ êµ°ì§‘í™”"""
    categories = set(h["color_category"] for h in hold_data)
    current_group_id = 0
    
    for category in categories:
        category_holds = [h for h in hold_data if h["color_category"] == category]
        
        if len(category_holds) <= 1:
            # í™€ë“œê°€ 1ê°œë¿ì´ë©´ ê·¸ë£¹ IDë§Œ í• ë‹¹
            category_holds[0]["group"] = current_group_id
            current_group_id += 1
            continue
        
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ í™€ë“œ ì¸ë±ìŠ¤ ì°¾ê¸°
        category_indices = [i for i, h in enumerate(hold_data) if h["color_category"] == category]
        category_vectors = vectors[category_indices]
        
        # ğŸš¨ ìƒ˜í”Œ ìˆ˜ì— ë”°ë¥¸ ì•ˆì „í•œ êµ°ì§‘í™”
        if len(category_holds) < 2:
            # í™€ë“œê°€ 1ê°œë¿ì´ë©´ ê·¸ë£¹ IDë§Œ í• ë‹¹
            category_holds[0]["group"] = current_group_id
            current_group_id += 1
            continue
        elif len(category_holds) < 4:
            # í™€ë“œê°€ 2-3ê°œë¿ì´ë©´ ê°ê° ë³„ë„ ê·¸ë£¹ìœ¼ë¡œ ì²˜ë¦¬ (êµ°ì§‘í™” ë¶ˆí•„ìš”)
            for i, hold in enumerate(category_holds):
                hold["group"] = current_group_id + i
            current_group_id += len(category_holds)
            continue
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” eps ì‚¬ìš©
        category_eps = get_category_specific_eps(category, eps)
        
        if method == "ensemble":
            labels = safe_ensemble_clustering(category_holds, category_vectors, base_eps=category_eps)
        else:
            labels = cosine_dbscan(category_vectors, eps=category_eps, min_samples=min_samples)
        
        # ê·¸ë£¹ ID í• ë‹¹ (ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë…ë¦½ì ì¸ ê·¸ë£¹ ID)
        for i, hold in enumerate(category_holds):
            if labels[i] != -1:
                hold["group"] = current_group_id + labels[i]
            else:
                hold["group"] = current_group_id + i  # ë…¸ì´ì¦ˆë„ ë³„ë„ ê·¸ë£¹
        
        current_group_id += max(labels) + 1 if len(labels) > 0 else 1
    
    return hold_data

def get_category_specific_eps(category, base_eps):
    """ğŸš¨ ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” eps ì„¤ì •"""
    eps_multipliers = {
        "black": 0.1,      # ê²€ì •ìƒ‰ì€ ë§¤ìš° ì—„ê²©
        "white": 0.1,      # í°ìƒ‰ë„ ë§¤ìš° ì—„ê²©
        "gray": 0.2,       # íšŒìƒ‰ì€ ì—„ê²©
        "red": 0.3,        # ë¹¨ê°„ìƒ‰ì€ ì¤‘ê°„
        "pink": 0.5,       # í•‘í¬ëŠ” ì¢€ ë” ëŠìŠ¨ (ë¹¨ê°•ê³¼ êµ¬ë¶„)
        "orange": 0.4,     # ì£¼í™©ìƒ‰
        "yellow": 0.6,     # ë…¸ë€ìƒ‰ì€ ë” ëŠìŠ¨ (ì—°ë‘ì™€ êµ¬ë¶„)
        "lime_green": 0.7, # ì—°ë‘ìƒ‰ (ë…¸ë‘ê³¼ êµ¬ë¶„)
        "green": 0.4,      # ì´ˆë¡ìƒ‰
        "cyan": 0.5,       # ì²­ë¡ìƒ‰
        "blue": 0.4,       # íŒŒë€ìƒ‰
        "sky_blue": 0.6,   # í•˜ëŠ˜ìƒ‰ (íŒŒë‘ê³¼ êµ¬ë¶„)
        "navy_blue": 0.5,  # ë‚¨ìƒ‰ (íŒŒë‘ê³¼ êµ¬ë¶„)
        "purple": 0.4,     # ë³´ë¼ìƒ‰
        "other": 0.5       # ê¸°íƒ€
    }
    
    return base_eps * eps_multipliers.get(category, 0.5)

def simple_rgb_clustering(hold_data, vectors, eps, min_samples):
    """ğŸš¨ 3D RGB ê³µê°„ì—ì„œ ë‹¨ìˆœí•œ ê±°ë¦¬ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§"""
    from sklearn.cluster import DBSCAN
    
    # RGB íŠ¹ì§• ë²¡í„° ì¶”ì¶œ (vectorsì˜ ì²« 3ê°œ ì°¨ì›ì´ RGB)
    rgb_vectors = vectors[:, :3]  # R, G, B ê°’ë§Œ ì‚¬ìš©
    
    # ğŸš¨ ì—¬ëŸ¬ eps ê°’ìœ¼ë¡œ ì‹œë„í•˜ì—¬ ìµœì ì˜ í´ëŸ¬ìŠ¤í„°ë§ ì°¾ê¸°
    best_labels = None
    best_score = -1
    best_eps = eps
    
    # eps ê°’ì„ 5~50 ì‚¬ì´ì—ì„œ í…ŒìŠ¤íŠ¸ (ë” ë„“ì€ ë²”ìœ„)
    for test_eps in range(5, min(60, eps * 2), 1):
        clustering = DBSCAN(eps=test_eps, min_samples=min_samples, metric='euclidean')
        labels = clustering.fit_predict(rgb_vectors)
        
        # í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ì™€ ë…¸ì´ì¦ˆ ë¹„ìœ¨ë¡œ ì ìˆ˜ ê³„ì‚°
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        n_noise = list(labels).count(-1)
        
        # ì´ìƒì ì¸ í´ëŸ¬ìŠ¤í„° ìˆ˜: 6-10ê°œ, ë…¸ì´ì¦ˆ ìµœì†Œí™” (3D ê·¸ë˜í”„ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ì— ë§ì¶¤)
        if 6 <= n_clusters <= 10 and n_noise < len(hold_data) * 0.3:
            score = n_clusters - (n_noise / len(hold_data))  # í´ëŸ¬ìŠ¤í„° ë§ì„ìˆ˜ë¡, ë…¸ì´ì¦ˆ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
            if score > best_score:
                best_score = score
                best_labels = labels
                best_eps = test_eps
    
    # ìµœì  ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê°•ì œë¡œ 7-8ê°œ í´ëŸ¬ìŠ¤í„° ìƒì„±
    if best_labels is None:
        # ğŸš¨ ê°•ì œ í´ëŸ¬ìŠ¤í„°ë§: ë§¤ìš° ì‘ì€ epsë¡œ ì‹œì‘í•´ì„œ í´ëŸ¬ìŠ¤í„° ìˆ˜ ë§ì¶œ ë•Œê¹Œì§€ ì¦ê°€
        target_clusters = 7  # 3D ê·¸ë˜í”„ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜
        best_labels = None
        
        for force_eps in range(5, 30, 1):
            clustering = DBSCAN(eps=force_eps, min_samples=min_samples, metric='euclidean')
            labels = clustering.fit_predict(rgb_vectors)
            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            
            # 6-8ê°œ í´ëŸ¬ìŠ¤í„°ê°€ ë‚˜ì˜¤ë©´ ì‚¬ìš©
            if 6 <= n_clusters <= 8:
                best_labels = labels
                break
        
        # ê·¸ë˜ë„ ì•ˆë˜ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if best_labels is None:
            clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean')
            best_labels = clustering.fit_predict(rgb_vectors)
    
    # ê·¸ë£¹ ID í• ë‹¹
    for i, hold in enumerate(hold_data):
        hold["group"] = int(best_labels[i]) if best_labels[i] != -1 else -1
    
    return hold_data

def ultra_simple_rgb_clustering(hold_data, vectors, eps=1.0, min_samples=1, n_clusters=7, method="ensemble"):
    """ğŸ¯ ì‚¬ìš©ì ì •ì˜ íŒŒë¼ë¯¸í„° ê¸°ë°˜ 3D XYZ ì§ì„  ê±°ë¦¬ í´ëŸ¬ìŠ¤í„°ë§"""
    from sklearn.cluster import DBSCAN, KMeans
    import streamlit as st
    import numpy as np
    
    # RGB íŠ¹ì§• ë²¡í„° ì¶”ì¶œ (R, G, B ê°’ë§Œ)
    rgb_vectors = vectors[:, :3]
    
    # ğŸš¨ ë””ë²„ê¹…: RGB ë²¡í„° ì •ë³´ ì¶œë ¥
    st.write(f"ğŸ” **ì‚¬ìš©ì ì •ì˜ í´ëŸ¬ìŠ¤í„°ë§ ë””ë²„ê¹…:**")
    st.write(f"- í™€ë“œ ìˆ˜: {len(hold_data)}")
    st.write(f"- RGB ë²¡í„° í˜•íƒœ: {rgb_vectors.shape}")
    st.write(f"- RGB ê°’ ë²”ìœ„: R({rgb_vectors[:, 0].min():.1f}-{rgb_vectors[:, 0].max():.1f}), G({rgb_vectors[:, 1].min():.1f}-{rgb_vectors[:, 1].max():.1f}), B({rgb_vectors[:, 2].min():.1f}-{rgb_vectors[:, 2].max():.1f})")
    
    # ğŸš¨ ì‹¤ì œ ê±°ë¦¬ ê³„ì‚°í•´ì„œ ë¬¸ì œì  ë¶„ì„
    if len(rgb_vectors) > 1:
        st.write(f"ğŸ” **ì‹¤ì œ ê±°ë¦¬ ë¶„ì„:**")
        distances = []
        for i in range(len(rgb_vectors)):
            for j in range(i+1, len(rgb_vectors)):
                dist = np.sqrt(np.sum((rgb_vectors[i] - rgb_vectors[j])**2))
                distances.append(dist)
        
        if distances:
            min_dist = min(distances)
            max_dist = max(distances)
            avg_dist = np.mean(distances)
            st.write(f"- ìµœì†Œ ê±°ë¦¬: {min_dist:.1f}")
            st.write(f"- ìµœëŒ€ ê±°ë¦¬: {max_dist:.1f}")
            st.write(f"- í‰ê·  ê±°ë¦¬: {avg_dist:.1f}")
            
            # epsì™€ ë¹„êµ
            if 'eps' in locals():
                st.write(f"- ì„¤ì •ëœ eps: {eps}")
                close_pairs = [d for d in distances if d <= eps]
                far_pairs = [d for d in distances if d > eps]
                st.write(f"- eps ì´í•˜ ê±°ë¦¬ ìŒ: {len(close_pairs)}ê°œ")
                st.write(f"- eps ì´ˆê³¼ ê±°ë¦¬ ìŒ: {len(far_pairs)}ê°œ")
    
    best_labels = None
    
    # ğŸš¨ ì „ë‹¬ëœ íŒŒë¼ë¯¸í„° í™•ì¸
    st.write(f"ğŸ” **ì „ë‹¬ëœ íŒŒë¼ë¯¸í„° í™•ì¸:**")
    st.write(f"- method: '{method}'")
    st.write(f"- eps: {eps} (ì‹¤ì œ ì‚¬ìš©ê°’)")
    st.write(f"- min_samples: {min_samples}")
    st.write(f"- n_clusters: {n_clusters}")
    
    # ì‚¬ìš©ìê°€ ì„ íƒí•œ ë°©ë²•ì— ë”°ë¼ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
    if method == "DBSCAN (eps ì¡°ì ˆ)":
        st.write(f"- **DBSCAN í´ëŸ¬ìŠ¤í„°ë§**")
        st.write(f"- eps: {eps}")
        st.write(f"- min_samples: {min_samples}")
        
        if len(rgb_vectors) < min_samples:
            st.warning(f"âš ï¸ í™€ë“œ ìˆ˜ê°€ min_samples({min_samples})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤. ëª¨ë“  í™€ë“œë¥¼ ë…¸ì´ì¦ˆë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            best_labels = np.full(len(rgb_vectors), -1)
        else:
            clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean')
            best_labels = clustering.fit_predict(rgb_vectors)
            
            # ğŸš¨ DBSCAN ìƒì„¸ ë¶„ì„
            core_samples = clustering.core_sample_indices_
            n_core = len(core_samples)
            n_clusters = len(set(best_labels)) - (1 if -1 in best_labels else 0)
            n_noise = list(best_labels).count(-1)
            
            st.write(f"ğŸ” **DBSCAN ìƒì„¸ ë¶„ì„:**")
            st.write(f"- í•µì‹¬ì (Core Points): {n_core}ê°œ")
            st.write(f"- í´ëŸ¬ìŠ¤í„°: {n_clusters}ê°œ")
            st.write(f"- ë…¸ì´ì¦ˆ: {n_noise}ê°œ")
            
            # ê° í´ëŸ¬ìŠ¤í„°ë³„ ì ì˜ ê°œìˆ˜
            cluster_counts = {}
            for label in best_labels:
                if label != -1:
                    cluster_counts[label] = cluster_counts.get(label, 0) + 1
            
            st.write(f"- í´ëŸ¬ìŠ¤í„°ë³„ ì  ê°œìˆ˜: {cluster_counts}")
            
            # ë¬¸ì œì  ë¶„ì„
            if n_noise > len(rgb_vectors) * 0.5:
                st.warning(f"âš ï¸ ë…¸ì´ì¦ˆê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤ ({n_noise}/{len(rgb_vectors)}) - epsë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”")
            elif n_clusters == 1 and len(rgb_vectors) > 5:
                st.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„°ê°€ 1ê°œë¿ì…ë‹ˆë‹¤ - epsë¥¼ ì¤„ì—¬ë³´ì„¸ìš”")
            elif n_clusters > len(rgb_vectors) * 0.5:
                st.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„°ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤ ({n_clusters}ê°œ) - epsë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”")
            
    elif method == "K-Means (kê°’ ì¡°ì ˆ)":
        st.write(f"- **K-Means í´ëŸ¬ìŠ¤í„°ë§**")
        st.write(f"- k (í´ëŸ¬ìŠ¤í„° ìˆ˜): {n_clusters}")
        
        if len(rgb_vectors) < n_clusters:
            st.warning(f"âš ï¸ í™€ë“œ ìˆ˜ê°€ kê°’({n_clusters})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤. ëª¨ë“  í™€ë“œë¥¼ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            best_labels = np.zeros(len(rgb_vectors), dtype=int)
        elif len(rgb_vectors) == 0:
            best_labels = np.array([])
        else:
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')
            best_labels = kmeans.fit_predict(rgb_vectors)
            
    else:  # ê¸°ì¡´ ë°©ë²•ë“¤ (ìë™ eps ì°¾ê¸°)
        st.write(f"- **ìë™ eps ì°¾ê¸° í´ëŸ¬ìŠ¤í„°ë§**")
        
        # RGB ê°’ë“¤ì˜ ì‹¤ì œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì„œ ì ì ˆí•œ eps ì°¾ê¸°
        distances = []
        for i in range(len(rgb_vectors)):
            for j in range(i+1, len(rgb_vectors)):
                dist = np.sqrt(np.sum((rgb_vectors[i] - rgb_vectors[j])**2))
                distances.append(dist)
        
        if distances:
            min_dist = min(distances)
            max_dist = max(distances)
            avg_dist = np.mean(distances)
            st.write(f"- ìµœì†Œ ê±°ë¦¬: {min_dist:.1f}")
            st.write(f"- ìµœëŒ€ ê±°ë¦¬: {max_dist:.1f}")
            st.write(f"- í‰ê·  ê±°ë¦¬: {avg_dist:.1f}")
            
            eps_candidates = np.linspace(min_dist, avg_dist/2, 20)
            best_score = -1
            
            for test_eps in eps_candidates:
                clustering = DBSCAN(eps=test_eps, min_samples=min_samples, metric='euclidean')
                labels = clustering.fit_predict(rgb_vectors)
                
                n_clusters_found = len(set(labels)) - (1 if -1 in labels else 0)
                n_noise = list(labels).count(-1)
                
                if n_clusters_found >= 2 and n_clusters_found <= 15:
                    noise_ratio = n_noise / len(hold_data)
                    score = (15 - n_clusters_found) * 0.7 + (1 - noise_ratio) * 0.3
                    
                    if score > best_score:
                        best_score = score
                        best_labels = labels
                        eps = test_eps
                        
            if best_labels is None:
                st.write("âš ï¸ **ê¸°ë³¸ eps=10.0 ì‚¬ìš©**")
                clustering = DBSCAN(eps=10.0, min_samples=min_samples, metric='euclidean')
                best_labels = clustering.fit_predict(rgb_vectors)
                eps = 10.0
    
    # ğŸš¨ ìµœì¢… ê²°ê³¼ ì¶œë ¥
    if best_labels is not None and len(best_labels) > 0:
        final_clusters = len(set(best_labels)) - (1 if -1 in best_labels else 0)
        final_noise = list(best_labels).count(-1)
        st.write(f"ğŸ¯ **ìµœì¢… í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼:**")
        st.write(f"- ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°: eps={eps:.1f}" if method == "DBSCAN (eps ì¡°ì ˆ)" else f"- ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°: k={n_clusters}")
        st.write(f"- ìƒì„±ëœ í´ëŸ¬ìŠ¤í„°: {final_clusters}ê°œ")
        st.write(f"- ë…¸ì´ì¦ˆ: {final_noise}ê°œ")
        st.write(f"- ê·¸ë£¹ IDë“¤: {sorted(set(best_labels))}")
        
        # ê·¸ë£¹ ID í• ë‹¹ (ë…¸ì´ì¦ˆë„ ë³„ë„ ê·¸ë£¹ìœ¼ë¡œ ì²˜ë¦¬)
        for i, hold in enumerate(hold_data):
            if best_labels[i] != -1:
                hold["group"] = int(best_labels[i])
            else:
                hold["group"] = int(len(set(best_labels)) + i)  # ë…¸ì´ì¦ˆë„ ë³„ë„ ê·¸ë£¹
    else:
        st.write("âš ï¸ í´ëŸ¬ìŠ¤í„°ë§í•  í™€ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    return hold_data

def pre_classify_bw(hold_data, v_thresh=40, s_thresh=30, v_high=180):
    """ğŸš€ ê°•í™”ëœ ê²€ì •/í°ìƒ‰ ì „ì²˜ë¦¬ - ë” ì—„ê²©í•œ ê¸°ì¤€"""
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        
        # ê²€ì •ìƒ‰: Valueê°€ ë§¤ìš° ë‚®ê³  Saturationë„ ë‚®ìŒ
        if v < v_thresh and s < s_thresh:
            hold["group"] = -2  # ê²€ì •ìƒ‰ ê·¸ë£¹
        # í°ìƒ‰: Valueê°€ ë§¤ìš° ë†’ê³  Saturationì´ ë§¤ìš° ë‚®ìŒ  
        elif s < s_thresh and v > v_high:
            hold["group"] = -3  # í°ìƒ‰ ê·¸ë£¹
        # íšŒìƒ‰: Value ì¤‘ê°„, Saturation ë‚®ìŒ
        elif s < s_thresh and v_thresh <= v <= v_high:
            hold["group"] = -4  # íšŒìƒ‰ ê·¸ë£¹
        else:
            hold["group"] = None  # ì¼ë°˜ ìƒ‰ìƒ ê·¸ë£¹
    return hold_data

def enhanced_color_preprocessing(hold_data):
    """ğŸš€ ê°•í™”ëœ ìƒ‰ìƒ ì „ì²˜ë¦¬ - ë” ì„¸ë°€í•œ ìƒ‰ìƒ ë¶„ë¥˜"""
    # 1. ê¸°ë³¸ ê²€ì •/í°ìƒ‰/íšŒìƒ‰ ë¶„ë¥˜
    hold_data = pre_classify_bw(hold_data)
    
    # 2. ìƒ‰ìƒ ìˆœë„ ê¸°ë°˜ ì¶”ê°€ ë¶„ë¥˜
    for hold in hold_data:
        if hold["group"] is None:  # ì•„ì§ ë¶„ë¥˜ë˜ì§€ ì•Šì€ í™€ë“œë§Œ
            h, s, v = hold["dominant_hsv"]
            
            # ğŸš€ ìƒ‰ìƒ ìˆœë„ ê³„ì‚° (HSVì—ì„œ)
            # Saturationê³¼ Valueê°€ ëª¨ë‘ ë†’ìœ¼ë©´ ìˆœìˆ˜í•œ ìƒ‰ìƒ
            color_purity = (s / 255.0) * (v / 255.0)
            
            # ğŸš€ ì €ì±„ë„ ìƒ‰ìƒ ë¶„ë¥˜ (íšŒìƒ‰ ê³„ì—´)
            if s < 50:  # ë§¤ìš° ë‚®ì€ ì±„ë„
                if v < 80:
                    hold["group"] = -5  # ì–´ë‘ìš´ íšŒìƒ‰
                elif v > 180:
                    hold["group"] = -6  # ë°ì€ íšŒìƒ‰
                else:
                    hold["group"] = -7  # ì¤‘ê°„ íšŒìƒ‰
            
            # ğŸš€ ìƒ‰ìƒ ìˆœë„ê°€ ë‚®ì€ ê²½ìš° (í˜¼í•©ìƒ‰)
            elif color_purity < 0.3:  # ì±„ë„ë‚˜ ëª…ë„ê°€ ë‚®ì€ ê²½ìš°
                hold["group"] = -8  # ì €ìˆœë„ ìƒ‰ìƒ ê·¸ë£¹
    
    return hold_data

def ultra_strict_color_separation(hold_data, hue_thresh=8, sat_thresh=20, val_thresh=40):
    """ğŸš€ ì´ˆì—„ê²© ìƒ‰ìƒ ë¶„ë¦¬ - ë§¤ìš° ì„¸ë°€í•œ ê¸°ì¤€"""
    # ë¨¼ì € ê°•í™”ëœ ì „ì²˜ë¦¬ ì ìš©
    hold_data = enhanced_color_preprocessing(hold_data)
    
    # ì¼ë°˜ ìƒ‰ìƒ ê·¸ë£¹ì— ëŒ€í•´ ë” ì—„ê²©í•œ ë¶„ë¦¬
    for group in set(h["group"] for h in hold_data if h["group"] is not None and h["group"] >= 0):
        group_holds = [h for h in hold_data if h["group"] == group]
        if len(group_holds) <= 1:
            continue
            
        hsv_values = [h["dominant_hsv"] for h in group_holds]
        hue_values = [hsv[0] for hsv in hsv_values]
        sat_values = [hsv[1] for hsv in hsv_values]
        val_values = [hsv[2] for hsv in hsv_values]
        
        # ğŸš€ ì´ˆì—„ê²© ë¶„ë¦¬ ê¸°ì¤€
        max_hue_diff = max(hue_values) - min(hue_values)
        max_sat_diff = max(sat_values) - min(sat_values)
        max_val_diff = max(val_values) - min(val_values)
        
        should_separate = False
        separation_reason = ""
        
        # Hue ì°¨ì´ê°€ 8ë„ ì´ìƒì´ë©´ ë¶„ë¦¬ (ë§¤ìš° ì—„ê²©)
        if max_hue_diff > hue_thresh:
            should_separate = True
            separation_reason = f"Hue ì°¨ì´ {max_hue_diff:.1f}ë„ (ì„ê³„ê°’: {hue_thresh})"
        # Saturation ì°¨ì´ê°€ 20 ì´ìƒì´ë©´ ë¶„ë¦¬ (ë§¤ìš° ì—„ê²©)
        elif max_sat_diff > sat_thresh:
            should_separate = True
            separation_reason = f"Saturation ì°¨ì´ {max_sat_diff:.1f} (ì„ê³„ê°’: {sat_thresh})"
        # Value ì°¨ì´ê°€ 40 ì´ìƒì´ë©´ ë¶„ë¦¬ (ë§¤ìš° ì—„ê²©)
        elif max_val_diff > val_thresh:
            should_separate = True
            separation_reason = f"Value ì°¨ì´ {max_val_diff:.1f} (ì„ê³„ê°’: {val_thresh})"
        
        # í™€ë“œê°€ 2ê°œ ì´ìƒì´ë©´ ë¶„ë¦¬ (ë” ê´€ëŒ€í•œ ì¡°ê±´)
        if should_separate and len(group_holds) >= 2:
            # K-meansë¡œ 2ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¦¬
            from sklearn.cluster import KMeans
            features = [[hsv[0], hsv[1], hsv[2]] for hsv in hsv_values]
            kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
            sub_labels = kmeans.fit_predict(features)
            
            new_group = max(h["group"] for h in hold_data if h["group"] is not None) + 1
            for i, hold in enumerate(group_holds):
                if sub_labels[i] == 1:
                    hold["group"] = new_group
            
            print(f"ì´ˆì—„ê²© ë¶„ë¦¬: ê·¸ë£¹ {group} ë¶„ë¦¬ë¨ - {separation_reason}")
    
    return hold_data

def advanced_distance_matrix(vectors, hold_data):
    """ğŸš€ ì´ˆê°•í™”ëœ ê±°ë¦¬ í•¨ìˆ˜ - HSV ê¸°ë°˜ ì •êµí•œ ìƒ‰ìƒ ê±°ë¦¬ + ê³µê°„ + í’ˆì§ˆ"""
    n = len(vectors)
    dist_matrix = np.zeros((n, n))
    
    for i in range(n):
        for j in range(i+1, n):
            # 1. HSV ê¸°ë°˜ ì •êµí•œ ìƒ‰ìƒ ê±°ë¦¬ (ê°€ì¤‘ì¹˜ 0.7ë¡œ ì¦ê°€)
            color_dist = calculate_hsv_distance(hold_data[i]["dominant_hsv"], hold_data[j]["dominant_hsv"])
            
            # 2. ê³µê°„ì  ê±°ë¦¬ (ê°€ì¤‘ì¹˜ 0.15ë¡œ ê°ì†Œ)
            center_i = hold_data[i]["center"]
            center_j = hold_data[j]["center"]
            spatial_dist = np.sqrt((center_i[0] - center_j[0])**2 + (center_i[1] - center_j[1])**2)
            spatial_dist = min(spatial_dist / 300.0, 1.0)  # ì •ê·œí™” ë²”ìœ„ ì¦ê°€
            
            # 3. í¬ê¸° ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 0.1)
            area_i = hold_data[i].get("area", hold_data[i].get("size", 1))
            area_j = hold_data[j].get("area", hold_data[j].get("size", 1))
            size_sim = min(area_i, area_j) / max(area_i, area_j) if max(area_i, area_j) > 0 else 1
            size_dist = 1 - size_sim
            
            # 4. ì›í˜•ë„ ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 0.05ë¡œ ê°ì†Œ)
            circ_i = hold_data[i].get("circularity", 0.5)
            circ_j = hold_data[j].get("circularity", 0.5)
            circ_dist = abs(circ_i - circ_j)
            
            # ğŸš€ ê°€ì¤‘ í‰ê·  ê±°ë¦¬ (ìƒ‰ìƒì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            total_dist = (0.7 * color_dist + 0.15 * spatial_dist + 
                         0.1 * size_dist + 0.05 * circ_dist)
            
            dist_matrix[i][j] = dist_matrix[j][i] = total_dist
    
    return dist_matrix

def calculate_hsv_distance(hsv1, hsv2):
    """ğŸ¯ HSV ê¸°ë°˜ ì •êµí•œ ìƒ‰ìƒ ê±°ë¦¬ ê³„ì‚°"""
    h1, s1, v1 = hsv1
    h2, s2, v2 = hsv2
    
    # 1. Hue ê±°ë¦¬ (ì›í˜• ê±°ë¦¬ ê³ ë ¤)
    hue_diff = min(abs(h1 - h2), 179 - abs(h1 - h2))  # OpenCV HSVëŠ” 0-179
    hue_distance = hue_diff / 179.0  # ì •ê·œí™” (0-1)
    
    # 2. Saturation ê±°ë¦¬
    sat_distance = abs(s1 - s2) / 255.0  # ì •ê·œí™” (0-1)
    
    # 3. Value ê±°ë¦¬
    val_distance = abs(v1 - v2) / 255.0  # ì •ê·œí™” (0-1)
    
    # ğŸš€ ê°€ì¤‘ í‰ê·  ê±°ë¦¬ (Hueì— ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜)
    # Hueê°€ ê°€ì¥ ì¤‘ìš”í•œ ìƒ‰ìƒ íŠ¹ì„±ì´ë¯€ë¡œ
    total_distance = (0.6 * hue_distance + 0.25 * sat_distance + 0.15 * val_distance)
    
    return total_distance

def cosine_dbscan(vectors, eps=0.01, min_samples=1):
    """ì›ë˜ ì˜ ì‘ë™í•˜ë˜ ì½”ì‚¬ì¸ DBSCAN"""
    sim_matrix = cosine_similarity(vectors)
    dist_matrix = 1 - sim_matrix
    dist_matrix = np.clip(dist_matrix, 0, 1)
    clustering = DBSCAN(metric="precomputed", eps=eps, min_samples=min_samples)
    labels = clustering.fit_predict(dist_matrix)
    return labels

def advanced_dbscan(vectors, hold_data, eps=0.01, min_samples=1):
    """ğŸš€ ê°œì„ ëœ DBSCAN - ì¢…í•© ê±°ë¦¬ í•¨ìˆ˜ ì‚¬ìš©"""
    dist_matrix = advanced_distance_matrix(vectors, hold_data)
    clustering = DBSCAN(metric="precomputed", eps=eps, min_samples=min_samples)
    labels = clustering.fit_predict(dist_matrix)
    return labels

def hierarchical_clustering(hold_data, vectors, base_eps=0.01):
    """ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§: Hue ëŒ€ë¶„ë¥˜ â†’ ì„¸ë¶€ ë¶„ë¥˜"""
    from sklearn.cluster import KMeans
    
    # ğŸš¨ ìƒ˜í”Œ ìˆ˜ ì²´í¬
    if len(hold_data) < 2:
        return [0] * len(hold_data)
    
    # 1ë‹¨ê³„: Hueë¡œ ëŒ€ë¶„ë¥˜ (ë¹¨ê°•/ë…¸ë‘/ì´ˆë¡/íŒŒë‘ ë“±)
    hue_values = np.array([hold["dominant_hsv"][0] for hold in hold_data])
    
    # Hueë¥¼ ì›í˜• ì¢Œí‘œë¡œ ë³€í™˜
    hue_rad = np.deg2rad(hue_values / 180.0 * 360.0)
    hue_coords = np.column_stack([np.cos(hue_rad), np.sin(hue_rad)])
    
    # ğŸš¨ ì•ˆì „í•œ K-means í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •
    max_clusters = min(8, len(hold_data), len(hold_data) - 1)  # ìƒ˜í”Œ ìˆ˜ë³´ë‹¤ ì‘ê²Œ
    best_n_clusters = min(3, len(hold_data))  # ìµœì†Œ 3ê°œ ë˜ëŠ” ìƒ˜í”Œ ìˆ˜
    
    if len(hold_data) >= 3:
        try:
            from sklearn.metrics import silhouette_score
            best_score = -1
            for n in range(2, max_clusters + 1):  # ìµœì†Œ 2ê°œ í´ëŸ¬ìŠ¤í„°
                if n < len(hold_data):  # í´ëŸ¬ìŠ¤í„° ìˆ˜ê°€ ìƒ˜í”Œ ìˆ˜ë³´ë‹¤ ì‘ì•„ì•¼ í•¨
                    kmeans = KMeans(n_clusters=n, random_state=42, n_init=10)
                    hue_labels = kmeans.fit_predict(hue_coords)
                    if len(set(hue_labels)) > 1:
                        score = silhouette_score(hue_coords, hue_labels)
                        if score > best_score:
                            best_score = score
                            best_n_clusters = n
        except:
            best_n_clusters = min(2, len(hold_data))
    else:
        best_n_clusters = len(hold_data)  # ìƒ˜í”Œ ìˆ˜ì™€ ê°™ê²Œ
    
    # ğŸš¨ ì•ˆì „í•œ K-means ì‹¤í–‰
    if best_n_clusters >= len(hold_data):
        # í´ëŸ¬ìŠ¤í„° ìˆ˜ê°€ ìƒ˜í”Œ ìˆ˜ì™€ ê°™ê±°ë‚˜ í¬ë©´ ê°ê° ë³„ë„ ê·¸ë£¹
        return list(range(len(hold_data)))
    
    kmeans = KMeans(n_clusters=best_n_clusters, random_state=42, n_init=10)
    hue_groups = kmeans.fit_predict(hue_coords)
    
    # 2ë‹¨ê³„: ê° Hue ê·¸ë£¹ ë‚´ì—ì„œ DBSCANìœ¼ë¡œ ì„¸ë¶€ ë¶„ë¥˜
    final_labels = np.full(len(hold_data), -1)
    label_counter = 0
    
    for hue_group_id in range(best_n_clusters):
        group_indices = np.where(hue_groups == hue_group_id)[0]
        if len(group_indices) == 0:
            continue
        
        group_vectors = vectors[group_indices]
        
        # Hue ê·¸ë£¹ì˜ ë¶„ì‚°ì— ë”°ë¼ eps ì¡°ì •
        hue_variance = np.var([hold_data[i]["dominant_hsv"][0] for i in group_indices])
        adaptive_eps = base_eps * (1 + hue_variance / 100.0)  # ë¶„ì‚°ì´ í¬ë©´ eps ì¦ê°€
        adaptive_eps = np.clip(adaptive_eps, 0.005, 0.05)
        
        # DBSCAN ì ìš©
        group_labels = cosine_dbscan(group_vectors, eps=adaptive_eps, min_samples=1)
        
        # ë¼ë²¨ ì¬í• ë‹¹
        for i, orig_idx in enumerate(group_indices):
            if group_labels[i] != -1:
                final_labels[orig_idx] = label_counter + group_labels[i]
            else:
                final_labels[orig_idx] = -1
        
        if len(group_labels) > 0:
            label_counter += max(group_labels) + 1
    
    return final_labels

def safe_ensemble_clustering(hold_data, vectors, base_eps=0.01):
    """ğŸš¨ ì•ˆì „í•œ ì•™ìƒë¸” í´ëŸ¬ìŠ¤í„°ë§ (ìƒ˜í”Œ ìˆ˜ ì²´í¬)"""
    if len(hold_data) < 4:
        # ìƒ˜í”Œì´ 4ê°œ ë¯¸ë§Œì´ë©´ ê°ê° ë³„ë„ ê·¸ë£¹ìœ¼ë¡œ ì²˜ë¦¬
        return list(range(len(hold_data)))
    
    return ensemble_clustering(hold_data, vectors, base_eps)

def ensemble_clustering(hold_data, vectors, base_eps=0.01):
    """ğŸš€ ê°•í™”ëœ ì•™ìƒë¸” í´ëŸ¬ìŠ¤í„°ë§: 4ê°€ì§€ ë°©ë²•ì˜ ê°€ì¤‘ íˆ¬í‘œ"""
    # ğŸš¨ ìƒ˜í”Œ ìˆ˜ ì²´í¬
    if len(hold_data) < 2:
        return [0] * len(hold_data)
    
    # ë°©ë²• 1: ê¸°ë³¸ DBSCAN (ê°€ì¤‘ì¹˜ 0.3)
    labels_1 = cosine_dbscan(vectors, eps=base_eps, min_samples=1)
    
    # ë°©ë²• 2: ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§ (ê°€ì¤‘ì¹˜ 0.3)
    labels_2 = hierarchical_clustering(hold_data, vectors, base_eps=base_eps)
    
    # ë°©ë²• 3: ë” ì—„ê²©í•œ DBSCAN (ê°€ì¤‘ì¹˜ 0.2)
    labels_3 = cosine_dbscan(vectors, eps=base_eps * 0.6, min_samples=1)
    
    # ë°©ë²• 4: ê°œì„ ëœ DBSCAN (ê°€ì¤‘ì¹˜ 0.2)
    labels_4 = advanced_dbscan(vectors, hold_data, eps=base_eps * 0.8, min_samples=1)
    
    # ê°€ì¤‘ íˆ¬í‘œ: ì ìˆ˜ ê¸°ë°˜
    final_labels = np.full(len(hold_data), -1)
    
    for i in range(len(hold_data)):
        votes = {}
        
        # ê° ë°©ë²•ì˜ ê·¸ë£¹ ìŒ ìˆ˜ì§‘ (ê°€ì¤‘ì¹˜ ì ìš©)
        for j in range(len(hold_data)):
            if i == j:
                continue
            
            score = 0
            # ë°©ë²• 1 (ê°€ì¤‘ì¹˜ 0.3)
            if labels_1[i] != -1 and labels_1[i] == labels_1[j]:
                score += 0.3
            
            # ë°©ë²• 2 (ê°€ì¤‘ì¹˜ 0.3)
            if labels_2[i] != -1 and labels_2[i] == labels_2[j]:
                score += 0.3
            
            # ë°©ë²• 3 (ê°€ì¤‘ì¹˜ 0.2)
            if labels_3[i] != -1 and labels_3[i] == labels_3[j]:
                score += 0.2
            
            # ë°©ë²• 4 (ê°€ì¤‘ì¹˜ 0.2)
            if labels_4[i] != -1 and labels_4[i] == labels_4[j]:
                score += 0.2
            
            if score > 0:
                votes[j] = score
        
        # ğŸš€ 0.7ì  ì´ìƒ ë°›ì€ í™€ë“œë“¤ê³¼ ê°™ì€ ê·¸ë£¹ (ì ì ˆí•œ ì—„ê²©ë„)
        same_group = [j for j, v in votes.items() if v >= 0.7]
        
        if same_group:
            # ê·¸ë£¹ ID í• ë‹¹ (ê°€ì¥ ì‘ì€ ì¸ë±ìŠ¤ ì‚¬ìš©)
            final_labels[i] = min(same_group + [i])
    
    # ë¼ë²¨ ì •ê·œí™” (0, 1, 2, ...)
    unique_labels = sorted(set(final_labels))
    label_map = {old: new for new, old in enumerate(unique_labels)}
    final_labels = np.array([label_map[l] for l in final_labels])
    
    return final_labels

def post_process_groups(hold_data, vectors):
    """ğŸš€ ê°•í™”ëœ í›„ì²˜ë¦¬ ê·œì¹™ - ë‹¤ì¤‘ ê¸°ì¤€ ì ìš©"""
    # 1. ë¶„ë¦¬ ê·œì¹™ ê°•í™”
    separate_groups_by_multiple_criteria(hold_data)
    
    # 2. ë³‘í•© ê·œì¹™ ê°•í™”  
    merge_similar_groups_by_multiple_criteria(hold_data)
    
    # 3. ë…¸ì´ì¦ˆ ì œê±° ë° ì •ë¦¬
    cleanup_noise_groups(hold_data)
    
    # 4. ê·¸ë£¹ ë²ˆí˜¸ ì¬ì •ë ¬
    renumber_groups(hold_data)
    
    return hold_data

def post_process_groups_custom(hold_data, vectors, hue_sep_thresh=25, sat_sep_thresh=50, 
                             val_sep_thresh=80, hue_merge_thresh=10):
    """ğŸš€ ì‚¬ìš©ì ì •ì˜ íŒŒë¼ë¯¸í„°ë¡œ í›„ì²˜ë¦¬"""
    # 1. ì‚¬ìš©ì ì •ì˜ ë¶„ë¦¬ ê·œì¹™
    separate_groups_custom(hold_data, hue_sep_thresh, sat_sep_thresh, val_sep_thresh)
    
    # 2. ì‚¬ìš©ì ì •ì˜ ë³‘í•© ê·œì¹™
    merge_similar_groups_custom(hold_data, hue_merge_thresh)
    
    # 3. ë…¸ì´ì¦ˆ ì œê±° ë° ì •ë¦¬
    cleanup_noise_groups(hold_data)
    
    # 4. ê·¸ë£¹ ë²ˆí˜¸ ì¬ì •ë ¬
    renumber_groups(hold_data)
    
    return hold_data

def separate_groups_custom(hold_data, hue_sep_thresh=25, sat_sep_thresh=50, val_sep_thresh=80):
    """ğŸš€ ì´ˆê°•í™”ëœ ì‚¬ìš©ì ì •ì˜ ê·¸ë£¹ ë¶„ë¦¬ - ë” ì •êµí•œ ê¸°ì¤€"""
    for group in set(h["group"] for h in hold_data if h["group"] is not None and h["group"] >= 0):
        group_holds = [h for h in hold_data if h["group"] == group]
        if len(group_holds) <= 1:  # í™€ë“œê°€ 1ê°œë¿ì´ë©´ ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ
            continue
            
        hsv_values = [h["dominant_hsv"] for h in group_holds]
        hue_values = [hsv[0] for hsv in hsv_values]
        sat_values = [hsv[1] for hsv in hsv_values]
        val_values = [hsv[2] for hsv in hsv_values]
        
        # ğŸš€ ë‹¤ì¤‘ ë¶„ë¦¬ ê¸°ì¤€ ì ìš©
        should_separate = False
        separation_reason = ""
        
        # 1. ê¸°ë³¸ ì„ê³„ê°’ ê¸°ì¤€
        max_hue_diff = max(hue_values) - min(hue_values)
        max_sat_diff = max(sat_values) - min(sat_values)
        max_val_diff = max(val_values) - min(val_values)
        
        if max_hue_diff > hue_sep_thresh:
            should_separate = True
            separation_reason = f"Hue ì°¨ì´ {max_hue_diff:.1f}ë„ (ì„ê³„ê°’: {hue_sep_thresh})"
        elif max_sat_diff > sat_sep_thresh:
            should_separate = True
            separation_reason = f"Saturation ì°¨ì´ {max_sat_diff:.1f} (ì„ê³„ê°’: {sat_sep_thresh})"
        elif max_val_diff > val_sep_thresh:
            should_separate = True
            separation_reason = f"Value ì°¨ì´ {max_val_diff:.1f} (ì„ê³„ê°’: {val_sep_thresh})"
        
        # 2. ğŸš€ ìƒˆë¡œìš´ ë¶„ë¦¬ ê¸°ì¤€: ìƒ‰ìƒ ë¶„ì‚°ì´ ë„ˆë¬´ í´ ë•Œ (ë” ì—„ê²©)
        hue_variance = np.var(hue_values)
        sat_variance = np.var(sat_values)
        val_variance = np.var(val_values)
        
        if hue_variance > 200:  # Hue ë¶„ì‚°ì´ ë„ˆë¬´ í´ ë•Œ (ê·¹ë„ë¡œ ì—„ê²©)
            should_separate = True
            separation_reason = f"Hue ë¶„ì‚° {hue_variance:.1f} (ì„ê³„ê°’: 200)"
        elif sat_variance > 800:  # Saturation ë¶„ì‚°ì´ ë„ˆë¬´ í´ ë•Œ (ê·¹ë„ë¡œ ì—„ê²©)
            should_separate = True
            separation_reason = f"Saturation ë¶„ì‚° {sat_variance:.1f} (ì„ê³„ê°’: 800)"
        elif val_variance > 1500:  # Value ë¶„ì‚°ì´ ë„ˆë¬´ í´ ë•Œ (ê·¹ë„ë¡œ ì—„ê²©)
            should_separate = True
            separation_reason = f"Value ë¶„ì‚° {val_variance:.1f} (ì„ê³„ê°’: 1500)"
        
        # 3. ğŸš€ ìƒˆë¡œìš´ ë¶„ë¦¬ ê¸°ì¤€: ê·¹ë‹¨ì ì¸ ìƒ‰ìƒ ì¡°í•©
        bright_dark_mix = False
        color_type_mix = False
        
        # ë°ì€ìƒ‰ê³¼ ì–´ë‘ìš´ìƒ‰ í˜¼í•© ê²€ì‚¬
        bright_count = 0
        dark_count = 0
        colorful_count = 0
        
        for hsv in hsv_values:
            h, s, v = hsv
            # ë°ì€ ìƒ‰ìƒ (Value > 180)
            if v > 180:
                bright_count += 1
            # ì–´ë‘ìš´ ìƒ‰ìƒ (Value < 80)
            elif v < 80:
                dark_count += 1
            # ì±„ë„ê°€ ë†’ì€ ìƒ‰ìƒ (Saturation > 100)
            if s > 100:
                colorful_count += 1
        
        # ì„œë¡œ ë‹¤ë¥¸ ìƒ‰ìƒ íƒ€ì…ì´ ì„ì—¬ìˆëŠ” ê²½ìš°
        if (bright_count > 0 and dark_count > 0) or (colorful_count > 0 and (bright_count > 0 or dark_count > 0)):
            should_separate = True
            separation_reason = f"ë‹¤ë¥¸ ìƒ‰ìƒ íƒ€ì… í˜¼í•© (ë°ìŒ:{bright_count}, ì–´ë‘ :{dark_count}, ì±„ë„:{colorful_count})"
        
        # 4. ğŸš€ ìƒˆë¡œìš´ ë¶„ë¦¬ ê¸°ì¤€: íŠ¹ì • ìƒ‰ìƒ ì¡°í•© ë¶„ë¦¬
        black_count = sum(1 for hsv in hsv_values if hsv[2] < 50)  # ê²€ì •ìƒ‰
        white_count = sum(1 for hsv in hsv_values if hsv[1] < 30 and hsv[2] > 200)  # í°ìƒ‰
        colorful_count = sum(1 for hsv in hsv_values if hsv[1] > 100 and hsv[2] > 100)  # ì±„ë„ ë†’ì€ ìƒ‰ìƒ
        
        if (black_count > 0 and (white_count > 0 or colorful_count > 0)) or (white_count > 0 and colorful_count > 0):
            should_separate = True
            separation_reason = f"íŠ¹ì • ìƒ‰ìƒ ì¡°í•© ë¶„ë¦¬ (ê²€ì •:{black_count}, í°ìƒ‰:{white_count}, ì±„ë„:{colorful_count})"
        
        # ğŸš€ í™€ë“œê°€ 2ê°œ ì´ìƒì´ë©´ ë¶„ë¦¬
        if should_separate and len(group_holds) >= 2:
            # ğŸš€ ê°œì„ ëœ K-means ë¶„ë¦¬ (HSV ê±°ë¦¬ ê¸°ë°˜)
            from sklearn.cluster import KMeans
            
            # HSV íŠ¹ì„±ì„ ê³ ë ¤í•œ íŠ¹ì§• ë²¡í„° ìƒì„±
            features = []
            for hsv in hsv_values:
                h, s, v = hsv
                # Hueë¥¼ ì›í˜• ì¢Œí‘œë¡œ ë³€í™˜
                h_rad = np.deg2rad(h * 2)  # OpenCV HSVëŠ” 0-179
                h_cos = np.cos(h_rad)
                h_sin = np.sin(h_rad)
                features.append([h_cos, h_sin, s/255.0, v/255.0])
            
            kmeans = KMeans(n_clusters=2, random_state=42, n_init=20, max_iter=300)
            sub_labels = kmeans.fit_predict(features)
            
            new_group = max(h["group"] for h in hold_data if h["group"] is not None) + 1
            for i, hold in enumerate(group_holds):
                if sub_labels[i] == 1:
                    hold["group"] = new_group
            
            print(f"ê·¸ë£¹ {group} ë¶„ë¦¬ë¨: {separation_reason}")

def merge_similar_groups_custom(hold_data, hue_merge_thresh=10):
    """ğŸ¯ ì‚¬ìš©ì ì •ì˜ ê·¸ë£¹ ë³‘í•©"""
    groups = [h["group"] for h in hold_data if h["group"] is not None and h["group"] >= 0]
    unique_groups = list(set(groups))
    
    for i, g1 in enumerate(unique_groups):
        for g2 in unique_groups[i+1:]:
            g1_holds = [h for h in hold_data if h["group"] == g1]
            g2_holds = [h for h in hold_data if h["group"] == g2]
            
            if not g1_holds or not g2_holds:
                continue
                
            g1_hsv = [h["dominant_hsv"] for h in g1_holds]
            g2_hsv = [h["dominant_hsv"] for h in g2_holds]
            
            g1_hue_avg = np.mean([hsv[0] for hsv in g1_hsv])
            g2_hue_avg = np.mean([hsv[0] for hsv in g2_hsv])
            
            hue_diff = abs(g1_hue_avg - g2_hue_avg)
            
            # ì‚¬ìš©ì ì •ì˜ Hue ì°¨ì´ ì„ê³„ê°’ìœ¼ë¡œ ë³‘í•©
            if hue_diff <= hue_merge_thresh:
                # g2ë¥¼ g1ìœ¼ë¡œ ë³‘í•©
                for hold in hold_data:
                    if hold["group"] == g2:
                        hold["group"] = g1
                print(f"ê·¸ë£¹ {g2}ë¥¼ ê·¸ë£¹ {g1}ìœ¼ë¡œ ë³‘í•© (Hue ì°¨ì´: {hue_diff:.1f}ë„, ì„ê³„ê°’: {hue_merge_thresh})")

def separate_groups_by_multiple_criteria(hold_data):
    """ğŸš€ ê°•í™”ëœ ê·¸ë£¹ ë¶„ë¦¬ - ë‹¤ì¤‘ ê¸°ì¤€ ì ìš©"""
    for group in set(h["group"] for h in hold_data if h["group"] is not None and h["group"] >= 0):
        group_holds = [h for h in hold_data if h["group"] == group]
        if len(group_holds) <= 2:
            continue
            
        hsv_values = [h["dominant_hsv"] for h in group_holds]
        hue_values = [hsv[0] for hsv in hsv_values]
        sat_values = [hsv[1] for hsv in hsv_values]
        val_values = [hsv[2] for hsv in hsv_values]
        
        # 1. Hue ì°¨ì´ê°€ 25ë„ ì´ìƒì´ë©´ ë¶„ë¦¬ (ë” ì—„ê²©)
        max_hue_diff = max(hue_values) - min(hue_values)
        
        # 2. Saturation ì°¨ì´ê°€ 50 ì´ìƒì´ë©´ ë¶„ë¦¬ (ìƒˆë¡œìš´ ê¸°ì¤€)
        max_sat_diff = max(sat_values) - min(sat_values)
        
        # 3. Value ì°¨ì´ê°€ 80 ì´ìƒì´ë©´ ë¶„ë¦¬ (ìƒˆë¡œìš´ ê¸°ì¤€)
        max_val_diff = max(val_values) - min(val_values)
        
        should_separate = False
        separation_reason = ""
        
        if max_hue_diff > 25:
            should_separate = True
            separation_reason = f"Hue ì°¨ì´ {max_hue_diff:.1f}ë„"
        elif max_sat_diff > 50:
            should_separate = True
            separation_reason = f"Saturation ì°¨ì´ {max_sat_diff:.1f}"
        elif max_val_diff > 80:
            should_separate = True
            separation_reason = f"Value ì°¨ì´ {max_val_diff:.1f}"
        
        if should_separate and len(group_holds) >= 3:  # ìµœì†Œ í™€ë“œ ìˆ˜ ê°ì†Œ
            # K-meansë¡œ 2ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¦¬
            from sklearn.cluster import KMeans
            features = [[hsv[0], hsv[1], hsv[2]] for hsv in hsv_values]
            kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
            sub_labels = kmeans.fit_predict(features)
            
            new_group = max(h["group"] for h in hold_data if h["group"] is not None) + 1
            for i, hold in enumerate(group_holds):
                if sub_labels[i] == 1:
                    hold["group"] = new_group
            
            print(f"ê·¸ë£¹ {group} ë¶„ë¦¬ë¨: {separation_reason}")

def merge_similar_groups_by_multiple_criteria(hold_data):
    """ğŸ¯ ë‹¨ìˆœí™”ëœ ê·¸ë£¹ ë³‘í•©"""
    groups = [h["group"] for h in hold_data if h["group"] is not None and h["group"] >= 0]
    unique_groups = list(set(groups))
    
    for i, g1 in enumerate(unique_groups):
        for g2 in unique_groups[i+1:]:
            g1_holds = [h for h in hold_data if h["group"] == g1]
            g2_holds = [h for h in hold_data if h["group"] == g2]
            
            if not g1_holds or not g2_holds:
                continue
                
            g1_hsv = [h["dominant_hsv"] for h in g1_holds]
            g2_hsv = [h["dominant_hsv"] for h in g2_holds]
            
            g1_hue_avg = np.mean([hsv[0] for hsv in g1_hsv])
            g2_hue_avg = np.mean([hsv[0] for hsv in g2_hsv])
            
            hue_diff = abs(g1_hue_avg - g2_hue_avg)
            
            # Hue ì°¨ì´ê°€ 10ë„ ì´í•˜ë©´ ë³‘í•© (ë‹¨ìˆœí™”)
            if hue_diff <= 10:
                # g2ë¥¼ g1ë¡œ ë³‘í•©
                for hold in hold_data:
                    if hold["group"] == g2:
                        hold["group"] = g1

def cleanup_noise_groups(hold_data):
    """ë…¸ì´ì¦ˆ ê·¸ë£¹ ì •ë¦¬"""
    group_counts = {}
    for hold in hold_data:
        if hold["group"] is not None and hold["group"] >= 0:
            group_counts[hold["group"]] = group_counts.get(hold["group"], 0) + 1
    
    # í™€ë“œê°€ 1ê°œë¿ì¸ ê·¸ë£¹ë“¤ì„ ê°€ì¥ ìœ ì‚¬í•œ ê·¸ë£¹ìœ¼ë¡œ ë³‘í•©
    for group, count in group_counts.items():
        if count == 1:
            single_hold = [h for h in hold_data if h["group"] == group][0]
            
            # ê°€ì¥ ìœ ì‚¬í•œ ê·¸ë£¹ ì°¾ê¸°
            best_group = None
            best_similarity = float('inf')
            
            for other_group in group_counts:
                if other_group != group and group_counts[other_group] > 1:
                    other_holds = [h for h in hold_data if h["group"] == other_group]
                    other_hsv = [h["dominant_hsv"] for h in other_holds]
                    other_hue_avg = np.mean([hsv[0] for hsv in other_hsv])
                    
                    hue_diff = abs(single_hold["dominant_hsv"][0] - other_hue_avg)
                    if hue_diff < best_similarity:
                        best_similarity = hue_diff
                        best_group = other_group
            
            if best_group is not None and best_similarity < 20:  # 20ë„ ì´ë‚´ë©´ ë³‘í•©
                single_hold["group"] = best_group

def renumber_groups(hold_data):
    """ê·¸ë£¹ ë²ˆí˜¸ ì¬ì •ë ¬"""
    groups = [h["group"] for h in hold_data if h["group"] is not None and h["group"] >= 0]
    unique_groups = sorted(list(set(groups)))
    
    group_mapping = {old_group: new_group for new_group, old_group in enumerate(unique_groups)}
    
    for hold in hold_data:
        if hold["group"] is not None and hold["group"] >= 0:
            hold["group"] = group_mapping[hold["group"]]

def adaptive_eps_selection(hold_data, vectors):
    """ğŸ¯ ë‹¨ìˆœí™”ëœ ì ì‘ì  eps ì„ íƒ"""
    # 1. í™€ë“œ ê°œìˆ˜ ê¸°ë°˜ ë‹¨ìˆœ ì¡°ì •
    hold_count = len(hold_data)
    
    # 2. ê¸°ë³¸ eps ì„¤ì •
    if hold_count <= 20:
        base_eps = 0.008  # ì ì€ í™€ë“œ: ë” ì—„ê²©
    elif hold_count <= 50:
        base_eps = 0.012  # ì¤‘ê°„ í™€ë“œ: ë³´í†µ
    else:
        base_eps = 0.015  # ë§ì€ í™€ë“œ: ì¡°ê¸ˆ ê´€ëŒ€
    
    # 3. Hue ë¶„ì‚° ê¸°ë°˜ ì¡°ì • (ë‹¨ìˆœí™”)
    hue_values = [hsv[0] for hsv in [hold["dominant_hsv"] for hold in hold_data]]
    hue_variance = np.var(hue_values)
    
    if hue_variance > 2000:  # ë§¤ìš° ë‹¤ì–‘í•œ ìƒ‰ìƒ
        base_eps *= 1.5
    elif hue_variance > 1000:  # ë‹¤ì–‘í•œ ìƒ‰ìƒ
        base_eps *= 1.2
    
    return min(base_eps, 0.03)  # ìµœëŒ€ 0.03ìœ¼ë¡œ ì œí•œ

def assign_groups(hold_data, vectors, eps=0.01, min_samples=1, method="ensemble"):
    """ğŸš€ ê°œì„ ëœ ê·¸ë£¹ í• ë‹¹ ë¡œì§ - ì ì‘ì  eps + ì•™ìƒë¸” ë°©ì‹"""
    # ì ì‘ì  eps ê³„ì‚°
    adaptive_eps = adaptive_eps_selection(hold_data, vectors)
    final_eps = min(eps, adaptive_eps)  # ë” ì—„ê²©í•œ ê¸°ì¤€ ì‚¬ìš©
    
    # ê²€ì •/í°ìƒ‰ ì „ì²˜ë¦¬
    hold_data = pre_classify_bw(hold_data)
    mask = [h["group"] is None for h in hold_data]
    sub_vectors = vectors[mask]
    
    if len(sub_vectors) > 0:
        sub_hold_data = [h for h in hold_data if h["group"] is None]
        
        if method == "ensemble":
            # ì•™ìƒë¸” í´ëŸ¬ìŠ¤í„°ë§
            labels = ensemble_clustering(sub_hold_data, sub_vectors, base_eps=final_eps)
        elif method == "hierarchical":
            # ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§
            labels = hierarchical_clustering(sub_hold_data, sub_vectors, base_eps=final_eps)
        elif method == "advanced":
            # ê°œì„ ëœ DBSCAN
            labels = advanced_dbscan(sub_vectors, sub_hold_data, eps=final_eps, min_samples=min_samples)
        else:
            # ê¸°ë³¸ DBSCAN
            labels = cosine_dbscan(sub_vectors, eps=final_eps, min_samples=min_samples)
        
        # ë¼ë²¨ í• ë‹¹
        j = 0
        for i, hold in enumerate(hold_data):
            if mask[i]:
                hold["group"] = int(labels[j])
                j += 1
        
        # í›„ì²˜ë¦¬
        hold_data = post_process_groups(hold_data, vectors)
    
    return hold_data

def simple_dbscan_clustering(hold_data, vectors, eps=1.0):
    """ğŸ¯ ìˆœìˆ˜ RGB ê±°ë¦¬ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ - ë…¼ë¦¬ì  ê·¸ë£¹í•‘"""
    import streamlit as st
    import numpy as np
    
    st.write(f"ğŸ” **ìˆœìˆ˜ RGB ê±°ë¦¬ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§:**")
    st.write(f"- í™€ë“œ ìˆ˜: {len(hold_data)}")
    st.write(f"- eps: {eps}")
    st.write(f"ğŸ’¡ **ì°¸ê³ **: RGB(156,39,62)ì™€ RGB(155,43,66)ì˜ ê±°ë¦¬ëŠ” 5.74ì…ë‹ˆë‹¤. eps=10ì´ë©´ ê°™ì€ ê·¸ë£¹ì´ ë©ë‹ˆë‹¤.")
    
    # RGB íŠ¹ì§• ë²¡í„° ì¶”ì¶œ (R, G, B ê°’ë§Œ)
    rgb_vectors = vectors[:, :3]
    st.write(f"- RGB ë²¡í„° í˜•íƒœ: {rgb_vectors.shape}")
    
    # ğŸš¨ ìˆœìˆ˜ ê±°ë¦¬ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ êµ¬í˜„
    n_holds = len(hold_data)
    groups = [-1] * n_holds  # -1ì€ ë¯¸ë¶„ë¥˜
    current_group = 0
    
    # ê° í™€ë“œì— ëŒ€í•´ ì²˜ë¦¬
    for i in range(n_holds):
        if groups[i] != -1:  # ì´ë¯¸ ê·¸ë£¹ì— í• ë‹¹ë¨
            continue
            
        # í˜„ì¬ í™€ë“œì™€ ê±°ë¦¬ê°€ eps ì´í•˜ì¸ ëª¨ë“  í™€ë“œ ì°¾ê¸°
        current_group_holds = [i]
        
        # ë‹¤ë¥¸ ëª¨ë“  í™€ë“œì™€ì˜ ê±°ë¦¬ í™•ì¸
        for j in range(n_holds):
            if i == j or groups[j] != -1:  # ìê¸° ìì‹ ì´ê±°ë‚˜ ì´ë¯¸ ê·¸ë£¹ì— í• ë‹¹ë¨
                continue
                
            # RGB ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
            dist = np.sqrt(np.sum((rgb_vectors[i] - rgb_vectors[j])**2))
            
            if dist <= eps:
                current_group_holds.append(j)
        
        # í˜„ì¬ í™€ë“œì™€ ì—°ê²°ëœ ëª¨ë“  í™€ë“œì— ê°™ì€ ê·¸ë£¹ í• ë‹¹
        for hold_idx in current_group_holds:
            groups[hold_idx] = current_group
            
        # ğŸš¨ ë””ë²„ê¹…: ê·¸ë£¹ ì •ë³´ ì¶œë ¥
        if len(current_group_holds) > 1:
            st.write(f"- **ê·¸ë£¹ {current_group}**: {len(current_group_holds)}ê°œ í™€ë“œ")
            for hold_idx in current_group_holds:
                rgb = rgb_vectors[hold_idx]
                st.write(f"  â€¢ í™€ë“œ {hold_data[hold_idx]['id']}: RGB({rgb[0]:.0f}, {rgb[1]:.0f}, {rgb[2]:.0f})")
            
            # ğŸš¨ ê±°ë¦¬ ê²€ì¦: ê·¸ë£¹ ë‚´ ëª¨ë“  í™€ë“œ ìŒì˜ ê±°ë¦¬ í™•ì¸
            st.write(f"  ğŸ” **ê±°ë¦¬ ê²€ì¦ (eps={eps}):**")
            for i in range(len(current_group_holds)):
                for j in range(i+1, len(current_group_holds)):
                    idx1, idx2 = current_group_holds[i], current_group_holds[j]
                    dist = np.sqrt(np.sum((rgb_vectors[idx1] - rgb_vectors[idx2])**2))
                    rgb1 = rgb_vectors[idx1]
                    rgb2 = rgb_vectors[idx2]
                    status = "âœ…" if dist <= eps else "âŒ"
                    st.write(f"    {status} í™€ë“œ {hold_data[idx1]['id']} â†” í™€ë“œ {hold_data[idx2]['id']}: ê±°ë¦¬ {dist:.1f} (RGB({rgb1[0]:.0f},{rgb1[1]:.0f},{rgb1[2]:.0f}) â†” RGB({rgb2[0]:.0f},{rgb2[1]:.0f},{rgb2[2]:.0f}))")
        
        current_group += 1
    
    # ê²°ê³¼ ë¶„ì„
    unique_groups = set(groups)
    n_clusters = len(unique_groups)
    
    st.write(f"ğŸ¯ **í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼:**")
    st.write(f"- í´ëŸ¬ìŠ¤í„°: {n_clusters}ê°œ")
    st.write(f"- ê·¸ë£¹ IDë“¤: {sorted(unique_groups)}")
    
    # ê·¸ë£¹ë³„ í™€ë“œ ìˆ˜ ì¶œë ¥
    for group_id in sorted(unique_groups):
        group_holds = [i for i, g in enumerate(groups) if g == group_id]
        st.write(f"- ê·¸ë£¹ {group_id}: {len(group_holds)}ê°œ í™€ë“œ")
    
    # ğŸš¨ íŠ¹ë³„ ê²€ì¦: ê²€ì •ìƒ‰ê³¼ í°ìƒ‰ í™•ì¸
    st.write(f"ğŸš¨ **ê²€ì •ìƒ‰/í°ìƒ‰ íŠ¹ë³„ ê²€ì¦:**")
    black_holds = []
    white_holds = []
    
    for i, hold in enumerate(hold_data):
        rgb = rgb_vectors[i]
        if rgb[0] < 10 and rgb[1] < 10 and rgb[2] < 10:  # ê²€ì •ìƒ‰
            black_holds.append((i, hold["id"], groups[i]))
        elif rgb[0] > 245 and rgb[1] > 245 and rgb[2] > 245:  # í°ìƒ‰
            white_holds.append((i, hold["id"], groups[i]))
    
    if black_holds:
        st.write(f"- ê²€ì •ìƒ‰ í™€ë“œ: {len(black_holds)}ê°œ")
        for idx, hold_id, group_id in black_holds:
            rgb = rgb_vectors[idx]
            st.write(f"  â€¢ í™€ë“œ {hold_id}: RGB({rgb[0]:.0f}, {rgb[1]:.0f}, {rgb[2]:.0f}) â†’ ê·¸ë£¹ {group_id}")
    
    if white_holds:
        st.write(f"- í°ìƒ‰ í™€ë“œ: {len(white_holds)}ê°œ")
        for idx, hold_id, group_id in white_holds:
            rgb = rgb_vectors[idx]
            st.write(f"  â€¢ í™€ë“œ {hold_id}: RGB({rgb[0]:.0f}, {rgb[1]:.0f}, {rgb[2]:.0f}) â†’ ê·¸ë£¹ {group_id}")
    
    # ê²€ì •ìƒ‰ê³¼ í°ìƒ‰ì´ ê°™ì€ ê·¸ë£¹ì— ìˆëŠ”ì§€ í™•ì¸
    black_groups = set(groups[idx] for idx, _, _ in black_holds)
    white_groups = set(groups[idx] for idx, _, _ in white_holds)
    
    if black_groups and white_groups:
        intersection = black_groups & white_groups
        if intersection:
            st.error(f"âŒ **ë¬¸ì œ ë°œê²¬!** ê²€ì •ìƒ‰ê³¼ í°ìƒ‰ì´ ê°™ì€ ê·¸ë£¹ì— ìˆìŠµë‹ˆë‹¤: {intersection}")
        else:
            st.success(f"âœ… ê²€ì •ìƒ‰ê³¼ í°ìƒ‰ì´ ë‹¤ë¥¸ ê·¸ë£¹ì— ìˆìŠµë‹ˆë‹¤ (ê²€ì •: {black_groups}, í°ìƒ‰: {white_groups})")
    
    # ê·¸ë£¹ ID í• ë‹¹
    for i, hold in enumerate(hold_data):
        hold["group"] = int(groups[i])
    
    return hold_data

def custom_color_space_transform(rgb_vector):
    """ğŸ¨ ì»¤ìŠ¤í…€ ìƒ‰ìƒ ê³µê°„ ë³€í™˜: ì£¼ìš” ìƒ‰ìƒë“¤ì„ ì™„ì „íˆ ë‹¤ë¥¸ ì˜ì—­ìœ¼ë¡œ ì´ë™"""
    r, g, b = rgb_vector[0], rgb_vector[1], rgb_vector[2]
    
    # ì£¼ìš” ìƒ‰ìƒ ì •ì˜ (RGB ì¢Œí‘œ) - ë” ë§ì€ ìƒ‰ìƒ ì¶”ê°€
    major_colors = {
        'black': [0, 0, 0],
        'white': [255, 255, 255],
        'red': [255, 0, 0],
        'green': [0, 255, 0], 
        'blue': [0, 0, 255],
        'yellow': [255, 255, 0],
        'magenta': [255, 0, 255],
        'cyan': [0, 255, 255],
        'orange': [255, 165, 0],
        'purple': [128, 0, 128],
        'pink': [255, 192, 203],
        'lime': [0, 255, 0],
        'navy': [0, 0, 128],
        'gray': [128, 128, 128],
        'brown': [139, 69, 19],
        'olive': [128, 128, 0],
        'teal': [0, 128, 128],
        'maroon': [128, 0, 0],
        'gold': [255, 215, 0],
        'silver': [192, 192, 192]
    }
    
    # ğŸš€ ìƒˆë¡œìš´ ì ‘ê·¼: ìƒ‰ìƒì„ ì™„ì „íˆ ë‹¤ë¥¸ ì¢Œí‘œê³„ë¡œ ë§¤í•‘
    # ê° ì£¼ìš” ìƒ‰ìƒì„ 3D ê³µê°„ì˜ ì„œë¡œ ë‹¤ë¥¸ êµ¬ì—­ì— ë°°ì¹˜
    color_zones = {
        'black': [0, 0, 0],           # ì›ì 
        'white': [1000, 1000, 1000],  # ìµœëŒ€ê°’
        'red': [1000, 0, 0],          # Xì¶• ìµœëŒ€
        'green': [0, 1000, 0],        # Yì¶• ìµœëŒ€
        'blue': [0, 0, 1000],         # Zì¶• ìµœëŒ€
        'yellow': [1000, 1000, 0],    # X+Y ìµœëŒ€
        'magenta': [1000, 0, 1000],   # X+Z ìµœëŒ€
        'cyan': [0, 1000, 1000],      # Y+Z ìµœëŒ€
        'orange': [1000, 500, 0],     # ì¤‘ê°„ê°’
        'purple': [500, 0, 1000],     # ì¤‘ê°„ê°’
        'pink': [1000, 250, 250],     # ì¤‘ê°„ê°’
        'lime': [250, 1000, 0],       # ì¤‘ê°„ê°’
        'navy': [0, 0, 500],          # ì¤‘ê°„ê°’
        'gray': [500, 500, 500],      # ì¤‘ê°„ê°’
        'brown': [500, 250, 0],       # ì¤‘ê°„ê°’
        'olive': [500, 500, 0],       # ì¤‘ê°„ê°’
        'teal': [0, 500, 500],        # ì¤‘ê°„ê°’
        'maroon': [500, 0, 0],        # ì¤‘ê°„ê°’
        'gold': [1000, 750, 0],       # ì¤‘ê°„ê°’
        'silver': [750, 750, 750]     # ì¤‘ê°„ê°’
    }
    
    # ê° ì£¼ìš” ìƒ‰ìƒê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
    distances = {}
    for color_name, color_rgb in major_colors.items():
        dist = np.sqrt((r - color_rgb[0])**2 + (g - color_rgb[1])**2 + (b - color_rgb[2])**2)
        distances[color_name] = dist
    
    # ê°€ì¥ ê°€ê¹Œìš´ ì£¼ìš” ìƒ‰ìƒ ì°¾ê¸°
    closest_color = min(distances, key=distances.get)
    min_distance = distances[closest_color]
    
    # ğŸš€ ìƒˆë¡œìš´ ì¢Œí‘œê³„ë¡œ ì§ì ‘ ë§¤í•‘
    target_zone = color_zones[closest_color]
    
    # ê±°ë¦¬ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ (ê°€ê¹Œìš¸ìˆ˜ë¡ ë” í™•ì‹¤í•˜ê²Œ ë§¤í•‘)
    if min_distance < 30:  # ë§¤ìš° ê°€ê¹Œìš´ ê²½ìš°
        weight = 1.0  # ì™„ì „íˆ í•´ë‹¹ êµ¬ì—­ìœ¼ë¡œ ì´ë™
    elif min_distance < 60:  # ê°€ê¹Œìš´ ê²½ìš°
        weight = 0.8
    elif min_distance < 100:  # ì¤‘ê°„ ê±°ë¦¬
        weight = 0.6
    elif min_distance < 150:  # ì¤‘ê°„-ë¨¼ ê±°ë¦¬
        weight = 0.4
    else:  # ë¨¼ ê²½ìš°
        weight = 0.2
    
    # ì›ë³¸ RGBì™€ ëª©í‘œ êµ¬ì—­ì„ ê°€ì¤‘ í‰ê· 
    new_r = (1 - weight) * r + weight * target_zone[0]
    new_g = (1 - weight) * g + weight * target_zone[1]
    new_b = (1 - weight) * b + weight * target_zone[2]
    
    # ë²”ìœ„ ì œí•œ (0-1000)
    new_r = np.clip(new_r, 0, 1000)
    new_g = np.clip(new_g, 0, 1000)
    new_b = np.clip(new_b, 0, 1000)
    
    return [new_r, new_g, new_b]

def perceptual_color_dbscan_clustering(hold_data, vectors, eps=30.0):
    """ğŸ¨ ì§€ê°ì  ìƒ‰ìƒ ê³µê°„ DBSCAN: Lab/LCh + CIEDE2000 ê±°ë¦¬"""
    import streamlit as st
    import numpy as np
    from sklearn.cluster import DBSCAN
    import cv2
    
    st.write(f"ğŸ¨ **ì§€ê°ì  ìƒ‰ìƒ ê³µê°„ DBSCAN í´ëŸ¬ìŠ¤í„°ë§:**")
    st.write(f"- í™€ë“œ ìˆ˜: {len(hold_data)}")
    st.write(f"- eps: {eps}")
    st.write(f"- min_samples: 1")
    st.write(f"- **Lab/LCh ê³µê°„ + CIEDE2000 ê±°ë¦¬ ì‚¬ìš©**")
    
    # RGB â†’ Lab ë³€í™˜
    lab_vectors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        # HSV â†’ RGB â†’ Lab ë³€í™˜ (ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ ìˆ˜ì •)
        hsv_arr = np.uint8([[[h, s, v]]])  # 3ì°¨ì› ë°°ì—´ë¡œ ìˆ˜ì •
        rgb_arr = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
        rgb_image = np.uint8([[[rgb_arr[0], rgb_arr[1], rgb_arr[2]]]])
        lab_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2Lab)[0][0]
        lab_vectors.append([lab_image[0], lab_image[1], lab_image[2]])
    
    lab_vectors = np.array(lab_vectors)
    st.write(f"- Lab ë²¡í„° í˜•íƒœ: {lab_vectors.shape}")
    st.write(f"- L ë²”ìœ„: {lab_vectors[:, 0].min():.0f}-{lab_vectors[:, 0].max():.0f}")
    st.write(f"- a ë²”ìœ„: {lab_vectors[:, 1].min():.0f}-{lab_vectors[:, 1].max():.0f}")
    st.write(f"- b ë²”ìœ„: {lab_vectors[:, 2].min():.0f}-{lab_vectors[:, 2].max():.0f}")
    
    # CIEDE2000 ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
    def ciede2000_distance(lab1, lab2):
        """CIEDE2000 ìƒ‰ìƒ ì°¨ì´ ê³„ì‚° (ê°„ì†Œí™” ë²„ì „)"""
        L1, a1, b1 = lab1
        L2, a2, b2 = lab2
        
        # ëª…ë„ ì°¨ì´ì— ë‚®ì€ ê°€ì¤‘ì¹˜, ìƒ‰ì¡° ì°¨ì´ì— ë†’ì€ ê°€ì¤‘ì¹˜
        delta_L = abs(L1 - L2) * 0.3  # ëª…ë„ ì°¨ì´ ê°€ì¤‘ì¹˜ ê°ì†Œ
        delta_a = abs(a1 - a2) * 1.5  # ìƒ‰ì¡° ì°¨ì´ ê°€ì¤‘ì¹˜ ì¦ê°€
        delta_b = abs(b1 - b2) * 1.5  # ìƒ‰ì¡° ì°¨ì´ ê°€ì¤‘ì¹˜ ì¦ê°€
        
        # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
        distance = np.sqrt(delta_L**2 + delta_a**2 + delta_b**2)
        return distance
    
    # ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
    n_samples = len(lab_vectors)
    distance_matrix = np.zeros((n_samples, n_samples))
    
    for i in range(n_samples):
        for j in range(n_samples):
            if i != j:
                distance_matrix[i, j] = ciede2000_distance(lab_vectors[i], lab_vectors[j])
    
    st.write(f"- ê±°ë¦¬ í–‰ë ¬ ê³„ì‚° ì™„ë£Œ: {distance_matrix.shape}")
    st.write(f"- ê±°ë¦¬ ë²”ìœ„: {distance_matrix.min():.2f}-{distance_matrix.max():.2f}")
    
    # precomputed ê±°ë¦¬ í–‰ë ¬ë¡œ DBSCAN ìˆ˜í–‰
    dbscan = DBSCAN(eps=eps, min_samples=1, metric='precomputed')
    labels = dbscan.fit_predict(distance_matrix)
    
    # ê²°ê³¼ ë¶„ì„
    unique_labels = set(labels)
    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)
    n_noise = list(labels).count(-1)
    
    st.write(f"- í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
    st.write(f"- ë…¸ì´ì¦ˆ ì : {n_noise}ê°œ")
    
    # í™€ë“œì— ê·¸ë£¹ í• ë‹¹
    for i, hold in enumerate(hold_data):
        hold["group"] = int(labels[i])
    
    return hold_data

def cylindrical_hsv_dbscan_clustering(hold_data, vectors, eps=30.0):
    """ğŸ¨ ì›í†µ ì¢Œí‘œê³„ HSV DBSCAN: ìƒ‰ì¡° ì¤‘ì‹¬ êµ°ì§‘í™”"""
    import streamlit as st
    import numpy as np
    from sklearn.cluster import DBSCAN
    
    st.write(f"ğŸ¨ **ì›í†µ ì¢Œí‘œê³„ HSV DBSCAN í´ëŸ¬ìŠ¤í„°ë§:**")
    st.write(f"- í™€ë“œ ìˆ˜: {len(hold_data)}")
    st.write(f"- eps: {eps}")
    st.write(f"- min_samples: 1")
    st.write(f"- **Hue ì¤‘ì‹¬ ì›í†µ ì¢Œí‘œê³„ ì‚¬ìš©**")
    
    # HSV â†’ ì›í†µ ì¢Œí‘œê³„ ë³€í™˜
    cylindrical_vectors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        
        # ì›í†µ ì¢Œí‘œê³„ ë³€í™˜
        # Hueë¥¼ ê°ë„ë¡œ, Saturationì„ ë°˜ì§€ë¦„ìœ¼ë¡œ, Valueë¥¼ ë†’ì´ë¡œ
        theta = np.radians(h)  # ê°ë„ (ë¼ë””ì•ˆ)
        r = s  # ë°˜ì§€ë¦„ (Saturation)
        z = v  # ë†’ì´ (Value)
        
        # ëª…ë„ ê°€ì¤‘ì¹˜ ì¡°ì ˆ (Value ì˜í–¥ ìµœì†Œí™”)
        z_weighted = z * 0.2  # Value ê°€ì¤‘ì¹˜ë¥¼ 0.2ë¡œ ê°ì†Œ
        
        # ì§êµ ì¢Œí‘œë¡œ ë³€í™˜
        x = r * np.cos(theta)
        y = r * np.sin(theta)
        
        cylindrical_vectors.append([x, y, z_weighted])
    
    cylindrical_vectors = np.array(cylindrical_vectors)
    st.write(f"- ì›í†µ ì¢Œí‘œ ë²¡í„° í˜•íƒœ: {cylindrical_vectors.shape}")
    st.write(f"- X ë²”ìœ„: {cylindrical_vectors[:, 0].min():.2f}-{cylindrical_vectors[:, 0].max():.2f}")
    st.write(f"- Y ë²”ìœ„: {cylindrical_vectors[:, 1].min():.2f}-{cylindrical_vectors[:, 1].max():.2f}")
    st.write(f"- Z ë²”ìœ„: {cylindrical_vectors[:, 2].min():.2f}-{cylindrical_vectors[:, 2].max():.2f}")
    
    # ì›í†µ ì¢Œí‘œê³„ì—ì„œ DBSCAN ìˆ˜í–‰
    dbscan = DBSCAN(eps=eps, min_samples=1, metric='euclidean')
    labels = dbscan.fit_predict(cylindrical_vectors)
    
    # ê²°ê³¼ ë¶„ì„
    unique_labels = set(labels)
    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)
    n_noise = list(labels).count(-1)
    
    st.write(f"- í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
    st.write(f"- ë…¸ì´ì¦ˆ ì : {n_noise}ê°œ")
    
    # í™€ë“œì— ê·¸ë£¹ í• ë‹¹
    for i, hold in enumerate(hold_data):
        hold["group"] = int(labels[i])
    
    return hold_data

def custom_color_cube_dbscan_clustering(hold_data, vectors, eps=30.0):
    """ğŸ¨ ì»¤ìŠ¤í…€ ìƒ‰ìƒ íë¸Œ DBSCAN: ì£¼ìš” ìƒ‰ìƒ ê°„ ê±°ë¦¬ í™•ì¥"""
    import streamlit as st
    import numpy as np
    from sklearn.cluster import DBSCAN
    
    st.write(f"ğŸ¨ **ì»¤ìŠ¤í…€ ìƒ‰ìƒ íë¸Œ DBSCAN í´ëŸ¬ìŠ¤í„°ë§ (ê°•í™” ë²„ì „):**")
    st.write(f"- í™€ë“œ ìˆ˜: {len(hold_data)}")
    st.write(f"- ì›ë³¸ eps: {eps}")
    
    # ìƒˆë¡œìš´ ì¢Œí‘œê³„ì— ë§ê²Œ eps ì¡°ì • (0-1000 ë²”ìœ„)
    adjusted_eps = eps * 4  # 0-255 â†’ 0-1000 ë²”ìœ„ë¡œ í™•ì¥
    st.write(f"- ì¡°ì •ëœ eps: {adjusted_eps} (ìƒˆë¡œìš´ ì¢Œí‘œê³„ìš©)")
    st.write(f"- min_samples: 1")
    st.write(f"- **ì£¼ìš” ìƒ‰ìƒë“¤ì„ ì™„ì „íˆ ë‹¤ë¥¸ êµ¬ì—­ìœ¼ë¡œ ë¶„ë¦¬**")
    
    # HSVâ†’RGB ë³€í™˜ëœ ê°’ ì‚¬ìš©
    rgb_vectors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        rgb = hsv_to_rgb([h, s, v])
        rgb_vectors.append([rgb[0], rgb[1], rgb[2]])
    rgb_vectors = np.array(rgb_vectors)
    
    st.write(f"- ì›ë³¸ RGB ë²¡í„° í˜•íƒœ: {rgb_vectors.shape}")
    st.write(f"- RGB ê°’ ë²”ìœ„: R({rgb_vectors[:, 0].min():.0f}-{rgb_vectors[:, 0].max():.0f}), G({rgb_vectors[:, 1].min():.0f}-{rgb_vectors[:, 1].max():.0f}), B({rgb_vectors[:, 2].min():.0f}-{rgb_vectors[:, 2].max():.0f})")
    
    # ì»¤ìŠ¤í…€ ìƒ‰ìƒ ê³µê°„ ë³€í™˜ ì ìš©
    custom_vectors = []
    for rgb_vec in rgb_vectors:
        custom_rgb = custom_color_space_transform(rgb_vec)
        custom_vectors.append(custom_rgb)
    custom_vectors = np.array(custom_vectors)
    
    st.write(f"- ë³€í™˜ í›„ RGB ë²¡í„° í˜•íƒœ: {custom_vectors.shape}")
    st.write(f"- ë³€í™˜ í›„ RGB ê°’ ë²”ìœ„: R({custom_vectors[:, 0].min():.0f}-{custom_vectors[:, 0].max():.0f}), G({custom_vectors[:, 1].min():.0f}-{custom_vectors[:, 1].max():.0f}), B({custom_vectors[:, 2].min():.0f}-{custom_vectors[:, 2].max():.0f})")
    
    # ë³€í™˜ëœ ê³µê°„ì—ì„œ DBSCAN ìˆ˜í–‰ (ì¡°ì •ëœ eps ì‚¬ìš©)
    dbscan = DBSCAN(eps=adjusted_eps, min_samples=1, metric='euclidean')
    labels = dbscan.fit_predict(custom_vectors)
    
    # ê²°ê³¼ ë¶„ì„
    unique_labels = set(labels)
    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)
    n_noise = list(labels).count(-1)
    
    st.write(f"- í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
    st.write(f"- ë…¸ì´ì¦ˆ ì : {n_noise}ê°œ")
    
    # í™€ë“œì— ê·¸ë£¹ í• ë‹¹
    for i, hold in enumerate(hold_data):
        hold["group"] = int(labels[i])
    
    return hold_data

def hsv_cube_dbscan_clustering(hold_data, vectors, eps=30.0):
    """ğŸ¯ HSV ìƒ‰ìƒ ê³µê°„ ê¸°ë°˜ DBSCAN í´ëŸ¬ìŠ¤í„°ë§ - ëŒ€ê°ì„  êµì°¨ ë¬¸ì œ í•´ê²°"""
    import streamlit as st
    import numpy as np
    from sklearn.cluster import DBSCAN
    
    st.write(f"ğŸŒˆ **HSV ìƒ‰ìƒ ê³µê°„ ê¸°ë°˜ DBSCAN í´ëŸ¬ìŠ¤í„°ë§:**")
    st.write(f"- í™€ë“œ ìˆ˜: {len(hold_data)}")
    st.write(f"- eps: {eps}")
    st.write(f"- min_samples: 1")
    
    # HSV ê°’ ì§ì ‘ ì‚¬ìš© (ëŒ€ê°ì„  êµì°¨ ë¬¸ì œ í•´ê²°)
    hsv_vectors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        hsv_vectors.append([h, s, v])
    hsv_vectors = np.array(hsv_vectors)
    
    st.write(f"- HSV ë²¡í„° í˜•íƒœ: {hsv_vectors.shape}")
    st.write(f"- H ë²”ìœ„: {hsv_vectors[:, 0].min():.0f}-{hsv_vectors[:, 0].max():.0f}Â°")
    st.write(f"- S ë²”ìœ„: {hsv_vectors[:, 1].min():.0f}-{hsv_vectors[:, 1].max():.0f}")
    st.write(f"- V ë²”ìœ„: {hsv_vectors[:, 2].min():.0f}-{hsv_vectors[:, 2].max():.0f}")
    
    # HSV ê³µê°„ì—ì„œ DBSCAN ìˆ˜í–‰
    dbscan = DBSCAN(eps=eps, min_samples=1, metric='euclidean')
    labels = dbscan.fit_predict(hsv_vectors)
    
    # ê²°ê³¼ ë¶„ì„
    unique_labels = set(labels)
    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)
    n_noise = list(labels).count(-1)
    
    st.write(f"- í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
    st.write(f"- ë…¸ì´ì¦ˆ ì : {n_noise}ê°œ")
    
    # í™€ë“œì— ê·¸ë£¹ í• ë‹¹
    for i, hold in enumerate(hold_data):
        hold["group"] = int(labels[i])
    
    return hold_data

def rgb_weighted_dbscan_clustering(hold_data, vectors, eps=0.01, weights=[0.5, 0.5, 1.2]):
    """ğŸ¯ RGB ì¶•ë³„ ê°€ì¤‘ì¹˜ DBSCAN í´ëŸ¬ìŠ¤í„°ë§ - ì‚¬ìš©ì ì •ì˜ ê°€ì¤‘ì¹˜"""
    import streamlit as st
    import numpy as np
    from sklearn.cluster import DBSCAN
    
    st.write(f"ğŸ¯ **RGB ì¶•ë³„ ê°€ì¤‘ì¹˜ DBSCAN í´ëŸ¬ìŠ¤í„°ë§:**")
    st.write(f"- í™€ë“œ ìˆ˜: {len(hold_data)}")
    st.write(f"- eps: {eps}")
    st.write(f"- min_samples: 1")
    st.write(f"- **ì¶•ë³„ ê°€ì¤‘ì¹˜: R={weights[0]}, G={weights[1]}, B={weights[2]}**")
    
    # HSVâ†’RGB ë³€í™˜ëœ ê°’ ì‚¬ìš©
    rgb_vectors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        rgb = hsv_to_rgb([h, s, v])
        rgb_vectors.append([rgb[0], rgb[1], rgb[2]])
    rgb_vectors = np.array(rgb_vectors)
    
    st.write(f"- RGB ë²¡í„° í˜•íƒœ: {rgb_vectors.shape}")
    st.write(f"- RGB ê°’ ë²”ìœ„: R({rgb_vectors[:, 0].min():.0f}-{rgb_vectors[:, 0].max():.0f}), G({rgb_vectors[:, 1].min():.0f}-{rgb_vectors[:, 1].max():.0f}), B({rgb_vectors[:, 2].min():.0f}-{rgb_vectors[:, 2].max():.0f})")
    
    # ì‚¬ìš©ì ì •ì˜ ê°€ì¤‘ì¹˜ ì ìš©
    weights_array = np.array(weights)
    
    # ê°€ì¤‘ì¹˜ ì ìš©ëœ ê±°ë¦¬ ê³„ì‚°ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­
    def weighted_euclidean_distance(x, y):
        diff = x - y
        weighted_diff = diff * weights_array
        return np.sqrt(np.sum(weighted_diff ** 2))
    
    # ğŸ¯ ê°€ì¤‘ì¹˜ ì ìš©ëœ DBSCAN í´ëŸ¬ìŠ¤í„°ë§
    dbscan = DBSCAN(eps=eps, min_samples=1, metric=weighted_euclidean_distance)
    labels = dbscan.fit_predict(rgb_vectors)
    
    # ê²°ê³¼ ë¶„ì„
    unique_labels = set(labels)
    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)
    n_noise = list(labels).count(-1)
    
    st.write(f"- í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
    st.write(f"- ë…¸ì´ì¦ˆ ì : {n_noise}ê°œ")
    
    # í™€ë“œì— ê·¸ë£¹ í• ë‹¹
    for i, hold in enumerate(hold_data):
        hold["group"] = int(labels[i])
    
    return hold_data

def rgb_cube_dbscan_clustering(hold_data, vectors, eps=0.01):
    """ğŸ¯ 3D RGB íë¸Œ ê¸°ë°˜ DBSCAN í´ëŸ¬ìŠ¤í„°ë§ - ì¶•ë³„ ê°€ì¤‘ì¹˜ ì ìš©"""
    import streamlit as st
    import numpy as np
    from sklearn.cluster import DBSCAN
    
    st.write(f"ğŸ” **3D RGB íë¸Œ ê¸°ë°˜ DBSCAN í´ëŸ¬ìŠ¤í„°ë§ (ì¶•ë³„ ê°€ì¤‘ì¹˜):**")
    st.write(f"- í™€ë“œ ìˆ˜: {len(hold_data)}")
    st.write(f"- eps: {eps}")
    st.write(f"- min_samples: 1")
    
    # ğŸš¨ HSVâ†’RGB ë³€í™˜ëœ ê°’ ì‚¬ìš© (3D íë¸Œì™€ ë™ì¼)
    rgb_vectors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        rgb = hsv_to_rgb([h, s, v])  # HSVì—ì„œ RGBë¡œ ë³€í™˜
        rgb_vectors.append([rgb[0], rgb[1], rgb[2]])
    rgb_vectors = np.array(rgb_vectors)
    
    st.write(f"- RGB ë²¡í„° í˜•íƒœ: {rgb_vectors.shape}")
    st.write(f"- RGB ê°’ ë²”ìœ„: R({rgb_vectors[:, 0].min():.0f}-{rgb_vectors[:, 0].max():.0f}), G({rgb_vectors[:, 1].min():.0f}-{rgb_vectors[:, 1].max():.0f}), B({rgb_vectors[:, 2].min():.0f}-{rgb_vectors[:, 2].max():.0f})")
    
    # ğŸ¯ ì¶•ë³„ ê°€ì¤‘ì¹˜ ì ìš©
    # Blue ë¼ì¸: ìƒí•˜ ë³€í™”ê°€ ì ìŒ â†’ ì—„ê²©í•œ eps (ê°€ì¤‘ì¹˜ ë†’ìŒ)
    # Green/Red ë¼ì¸: 0,0â†’255,255 1:1 ë³€í™” â†’ ê´€ëŒ€í•œ eps (ê°€ì¤‘ì¹˜ ë‚®ìŒ)
    weights = np.array([0.5, 0.5, 1.2])  # [R, G, B] ê°€ì¤‘ì¹˜
    st.write(f"- **ì¶•ë³„ ê°€ì¤‘ì¹˜: R={weights[0]}, G={weights[1]}, B={weights[2]}**")
    st.write(f"- Blue ì¶•(B)ì— ë” ì—„ê²©í•œ ê°€ì¤‘ì¹˜ ì ìš©")
    
    # ê°€ì¤‘ì¹˜ ì ìš©ëœ ê±°ë¦¬ ê³„ì‚°ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­
    def weighted_euclidean_distance(x, y):
        diff = x - y
        weighted_diff = diff * weights
        return np.sqrt(np.sum(weighted_diff ** 2))
    
    # ğŸš¨ RGB ê°’ ê²€ì¦ (ì½˜ì†” ì¶œë ¥)
    print(f"\n=== RGB ê°’ ê²€ì¦ (ì´ {len(rgb_vectors)}ê°œ í™€ë“œ) ===")
    zero_count = 0
    for i, rgb in enumerate(rgb_vectors):
        if rgb[0] == 0 and rgb[1] == 0 and rgb[2] == 0:
            zero_count += 1
            print(f"âš ï¸ í™€ë“œ {hold_data[i]['id']}: RGB({rgb[0]:.0f}, {rgb[1]:.0f}, {rgb[2]:.0f})")
    
    print(f"RGB(0,0,0) í™€ë“œ ì´ ê°œìˆ˜: {zero_count}ê°œ")
    if zero_count > 5:
        print("ğŸš¨ ìƒ‰ìƒ ì¶”ì¶œì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    
    # Streamlitì—ë„ ê°„ë‹¨íˆ í‘œì‹œ
    if zero_count > 5:
        st.warning(f"âš ï¸ RGB(0,0,0) í™€ë“œê°€ ì´ {zero_count}ê°œ ìˆìŠµë‹ˆë‹¤! (ì½˜ì†” ë¡œê·¸ í™•ì¸)")
    else:
        st.success(f"âœ… RGB(0,0,0) í™€ë“œ: {zero_count}ê°œ")
    
    # ğŸ¯ ê°€ì¤‘ì¹˜ ì ìš©ëœ DBSCAN í´ëŸ¬ìŠ¤í„°ë§
    dbscan = DBSCAN(eps=eps, min_samples=1, metric=weighted_euclidean_distance)
    labels = dbscan.fit_predict(rgb_vectors)
    
    # ê²°ê³¼ ë¶„ì„
    unique_labels = set(labels)
    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)
    n_noise = list(labels).count(-1)
    
    st.write(f"ğŸ¯ **DBSCAN í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼:**")
    st.write(f"- í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
    st.write(f"- ë…¸ì´ì¦ˆ ì : {n_noise}ê°œ")
    st.write(f"- ë¼ë²¨ë“¤: {sorted(unique_labels)}")
    
    # ê·¸ë£¹ë³„ í™€ë“œ ìˆ˜ ë° RGB ê°’ ì¶œë ¥ (ì½˜ì†” ì¶œë ¥)
    print(f"\n=== DBSCAN í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ (eps={eps}) ===")
    print(f"í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
    print(f"ë…¸ì´ì¦ˆ ì : {n_noise}ê°œ")
    print(f"ë¼ë²¨ë“¤: {sorted(unique_labels)}")
    
    total_errors = 0
    for label in sorted(unique_labels):
        if label == -1:
            continue
        group_indices = [i for i, l in enumerate(labels) if l == label]
        
        print(f"\n--- ê·¸ë£¹ {label} ({len(group_indices)}ê°œ í™€ë“œ) ---")
        
        # ê·¸ë£¹ ë‚´ RGB ê°’ë“¤ ì¶œë ¥ (ëª¨ë“  í™€ë“œ í‘œì‹œ)
        for i, idx in enumerate(group_indices):
            rgb = rgb_vectors[idx]
            print(f"  í™€ë“œ {hold_data[idx]['id']}: RGB({rgb[0]:.0f}, {rgb[1]:.0f}, {rgb[2]:.0f})")
            
        # ğŸš¨ ê·¸ë£¹ ë‚´ ê±°ë¦¬ ê²€ì¦
        if len(group_indices) > 1:
            print(f"  ğŸ” ê·¸ë£¹ {label} ë‚´ ê±°ë¦¬ ê²€ì¦ (eps={eps}):")
            error_count = 0
            for i in range(len(group_indices)):
                for j in range(i+1, len(group_indices)):
                    idx1, idx2 = group_indices[i], group_indices[j]
                    dist = np.sqrt(np.sum((rgb_vectors[idx1] - rgb_vectors[idx2])**2))
                    status = "âœ…" if dist <= eps else "âŒ"
                    print(f"    {status} í™€ë“œ {hold_data[idx1]['id']} â†” í™€ë“œ {hold_data[idx2]['id']}: ê±°ë¦¬ {dist:.3f}")
                    if dist > eps:
                        print(f"      âš ï¸ ê±°ë¦¬ {dist:.3f} > eps {eps} - ê°™ì€ ê·¸ë£¹ì´ë©´ ì•ˆ ë¨!")
                        error_count += 1
            
            total_errors += error_count
            if error_count > 0:
                print(f"  ğŸš¨ ê·¸ë£¹ {label}ì— {error_count}ê°œì˜ ê±°ë¦¬ ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤!")
            else:
                print(f"  âœ… ê·¸ë£¹ {label}ì˜ ëª¨ë“  í™€ë“œ ê±°ë¦¬ê°€ eps ì´í•˜ì…ë‹ˆë‹¤!")
    
    print(f"\n=== ì´ ê±°ë¦¬ ì˜¤ë¥˜: {total_errors}ê°œ ===")
    
    # Streamlitì—ë„ ê°„ë‹¨íˆ í‘œì‹œ
    if total_errors > 0:
        st.error(f"ğŸš¨ ì´ {total_errors}ê°œì˜ ê±°ë¦¬ ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤! (ì½˜ì†” ë¡œê·¸ í™•ì¸)")
    else:
        st.success(f"âœ… ëª¨ë“  ê·¸ë£¹ì˜ ê±°ë¦¬ê°€ ì •ìƒì…ë‹ˆë‹¤!")
    
    # ë…¸ì´ì¦ˆ ì ë“¤ ì¶œë ¥
    if n_noise > 0:
        noise_indices = [i for i, l in enumerate(labels) if l == -1]
        st.write(f"- **ë…¸ì´ì¦ˆ**: {n_noise}ê°œ í™€ë“œ")
        for i, idx in enumerate(noise_indices[:3]):
            rgb = rgb_vectors[idx]
            st.write(f"  â€¢ í™€ë“œ {hold_data[idx]['id']}: RGB({rgb[0]:.0f}, {rgb[1]:.0f}, {rgb[2]:.0f})")
        if n_noise > 3:
            st.write(f"  ... ì™¸ {n_noise-3}ê°œ")
    
    # ê·¸ë£¹ ID í• ë‹¹
    for i, hold in enumerate(hold_data):
        hold["group"] = int(labels[i])
    
    return hold_data

def plot_2d(hold_data, vectors):
    fig, ax = plt.subplots(figsize=(8, 6))
    for i, vec in enumerate(vectors):
        h, s, v = hold_data[i]["dominant_hsv"]
        rgb = np.array(hsv_to_rgb(np.array([h, s, v], dtype=np.uint8))) / 255.0
        ax.scatter(vec[0], vec[1], color=rgb, s=80, edgecolors="k")
        ax.text(vec[0], vec[1], str(hold_data[i]["id"]), fontsize=8, ha="center", va="center", color="black")
    ax.set_title("Hold Clustering - HSV ìƒ‰ìƒí™˜ ì¢Œí‘œ ê¸°ë°˜")
    return fig

def plot_3d(hold_data, vectors):
    colors = ["rgb" + str(hsv_to_rgb(np.array(h["dominant_hsv"], dtype=np.uint8))) for h in hold_data]
    fig = px.scatter_3d(
        x=vectors[:, 0], y=vectors[:, 1], z=vectors[:, 2],
        color=colors,
        text=[str(h["id"]) for h in hold_data],
        title="3D Hold Clustering - HSV ì¢Œí‘œ ê¸°ë°˜"
    )
    return fig

def create_clustering_visualizations(hold_data, vectors):
    """ğŸš€ ê·¸ë£¹í•‘ ê²°ê³¼ ì‹œê°í™” - ë‹¤ì¤‘ ì°¨íŠ¸"""
    if len(hold_data) == 0:
        return None
    
    # ê·¸ë£¹ë³„ ìƒ‰ìƒ ë§¤í•‘
    groups = [h["group"] for h in hold_data if h["group"] is not None]
    unique_groups = sorted(set(groups))
    group_colors = px.colors.qualitative.Set3[:len(unique_groups)]
    group_color_map = {g: group_colors[i % len(group_colors)] for i, g in enumerate(unique_groups)}
    
    # 1. t-SNE 2D ì‹œê°í™”
    try:
        tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(hold_data)-1))
        vectors_2d = tsne.fit_transform(vectors)
    except:
        # t-SNE ì‹¤íŒ¨ ì‹œ PCA ì‚¬ìš©
        pca = PCA(n_components=2, random_state=42)
        vectors_2d = pca.fit_transform(vectors)
    
    # 2. ê·¸ë£¹ë³„ ìƒ‰ìƒ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=['t-SNE 2D ë¶„í¬', 'Hue ë¶„í¬', 'Saturation ë¶„í¬', 'Value ë¶„í¬'],
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # t-SNE 2D í”Œë¡¯ - ì‹¤ì œ í™€ë“œ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œ
    for i, hold in enumerate(hold_data):
        group = hold["group"] if hold["group"] is not None else -1
        
        # ğŸš€ ì‹¤ì œ í™€ë“œ ìƒ‰ìƒ ê³„ì‚°
        h, s, v = hold["dominant_hsv"]
        actual_color = hsv_to_rgb([h, s, v])
        color_rgb = f"rgb({actual_color[0]}, {actual_color[1]}, {actual_color[2]})"
        
        # í…Œë‘ë¦¬ ìƒ‰ìƒ (ê·¸ë£¹ êµ¬ë¶„ìš©)
        border_color = group_color_map.get(group, "#cccccc")
        
        fig.add_trace(
            go.Scatter(
                x=[vectors_2d[i, 0]], y=[vectors_2d[i, 1]],
                mode='markers+text',
                marker=dict(
                    color=color_rgb,  # ì‹¤ì œ í™€ë“œ ìƒ‰ìƒ
                    size=15,  # í¬ê¸° ì¦ê°€
                    line=dict(color=border_color, width=3),  # ê·¸ë£¹ë³„ í…Œë‘ë¦¬
                    opacity=0.8
                ),
                text=[str(hold["id"])],
                textposition="top center",
                textfont=dict(size=10, color="black"),
                name=f"Group {group}",
                showlegend=False,
                hovertemplate=f"<b>í™€ë“œ ID: {hold['id']}</b><br>" +
                            f"ê·¸ë£¹: {group}<br>" +
                            f"ì‹¤ì œ ìƒ‰ìƒ: {color_rgb}<br>" +
                            f"HSV: ({h:.0f}, {s:.0f}, {v:.0f})<br>" +
                            f"ìœ„ì¹˜: ({vectors_2d[i, 0]:.2f}, {vectors_2d[i, 1]:.2f})<extra></extra>"
            ),
            row=1, col=1
        )
    
    # HSV íˆìŠ¤í† ê·¸ë¨
    h_values = [h["dominant_hsv"][0] for h in hold_data]
    s_values = [h["dominant_hsv"][1] for h in hold_data]
    v_values = [h["dominant_hsv"][2] for h in hold_data]
    
    # Hue íˆìŠ¤í† ê·¸ë¨ (ê·¸ë£¹ë³„)
    for group in unique_groups:
        group_h_values = [h["dominant_hsv"][0] for h in hold_data if h["group"] == group]
        if group_h_values:
            fig.add_trace(
                go.Histogram(
                    x=group_h_values,
                    name=f"Group {group}",
                    marker_color=group_color_map[group],
                    opacity=0.7
                ),
                row=1, col=2
            )
    
    # Saturation íˆìŠ¤í† ê·¸ë¨
    for group in unique_groups:
        group_s_values = [h["dominant_hsv"][1] for h in hold_data if h["group"] == group]
        if group_s_values:
            fig.add_trace(
                go.Histogram(
                    x=group_s_values,
                    name=f"Group {group}",
                    marker_color=group_color_map[group],
                    opacity=0.7,
                    showlegend=False
                ),
                row=2, col=1
            )
    
    # Value íˆìŠ¤í† ê·¸ë¨
    for group in unique_groups:
        group_v_values = [h["dominant_hsv"][2] for h in hold_data if h["group"] == group]
        if group_v_values:
            fig.add_trace(
                go.Histogram(
                    x=group_v_values,
                    name=f"Group {group}",
                    marker_color=group_color_map[group],
                    opacity=0.7,
                    showlegend=False
                ),
                row=2, col=2
            )
    
    fig.update_layout(
        title="ğŸ¯ ê·¸ë£¹í•‘ ê²°ê³¼ ì‹œê°í™”",
        height=800,
        showlegend=True
    )
    
    return fig

def create_group_color_palette(hold_data):
    """ğŸ¨ ê·¸ë£¹ë³„ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ìƒì„±"""
    if len(hold_data) == 0:
        return None
    
    groups = [h["group"] for h in hold_data if h["group"] is not None]
    unique_groups = sorted(set(groups))
    
    fig = make_subplots(
        rows=1, cols=len(unique_groups) if len(unique_groups) > 0 else 1,
        subplot_titles=[f"ê·¸ë£¹ {g}" for g in unique_groups],
        specs=[[{"type": "scatter"} for _ in unique_groups]]
    )
    
    for i, group in enumerate(unique_groups):
        group_holds = [h for h in hold_data if h["group"] == group]
        
        # ê·¸ë£¹ ë‚´ ëª¨ë“  í™€ë“œì˜ ìƒ‰ìƒ í‘œì‹œ
        colors = []
        hold_ids = []
        positions = []
        
        for j, hold in enumerate(group_holds):
            h, s, v = hold["dominant_hsv"]
            actual_color = hsv_to_rgb([h, s, v])
            color_rgb = f"rgb({actual_color[0]}, {actual_color[1]}, {actual_color[2]})"
            
            colors.append(color_rgb)
            hold_ids.append(hold["id"])
            positions.append(j)
        
        fig.add_trace(
            go.Scatter(
                x=positions,
                y=[0] * len(positions),
                mode='markers+text',
                marker=dict(
                    color=colors,
                    size=25,
                    line=dict(color="black", width=2),
                    opacity=0.9
                ),
                text=[f"ID:{hid}" for hid in hold_ids],
                textposition="bottom center",
                textfont=dict(size=8, color="black"),
                name=f"Group {group}",
                showlegend=False,
                hovertemplate="<b>í™€ë“œ ID: %{text}</b><br>" +
                            f"ê·¸ë£¹: {group}<br>" +
                            "ìƒ‰ìƒ: %{marker.color}<extra></extra>"
            ),
            row=1, col=i+1
        )
        
        # ì¶• ì„¤ì •
        fig.update_xaxes(showgrid=False, showticklabels=False, range=[-0.5, len(group_holds)-0.5], row=1, col=i+1)
        fig.update_yaxes(showgrid=False, showticklabels=False, range=[-0.5, 0.5], row=1, col=i+1)
    
    fig.update_layout(
        title="ğŸ¨ ê·¸ë£¹ë³„ í™€ë“œ ìƒ‰ìƒ íŒ”ë ˆíŠ¸",
        height=200,
        showlegend=False
    )
    
    return fig

def create_enhanced_color_distance_matrix(hold_data):
    """ğŸš€ ê°•í™”ëœ ìƒ‰ìƒ ê±°ë¦¬ ë§¤íŠ¸ë¦­ìŠ¤ - HSV ê¸°ë°˜ ì •êµí•œ ê±°ë¦¬ ê³„ì‚°"""
    n = len(hold_data)
    distance_matrix = np.zeros((n, n))
    
    for i in range(n):
        for j in range(i+1, n):
            h1, s1, v1 = hold_data[i]["dominant_hsv"]
            h2, s2, v2 = hold_data[j]["dominant_hsv"]
            
            # ğŸš€ HSV ê¸°ë°˜ ì •êµí•œ ê±°ë¦¬ ê³„ì‚°
            # 1. Hue ê±°ë¦¬ (ì›í˜• ê±°ë¦¬ ê³ ë ¤)
            hue_diff = min(abs(h1 - h2), 179 - abs(h1 - h2))  # ì›í˜• ê±°ë¦¬
            hue_distance = hue_diff / 179.0  # ì •ê·œí™” (0-1)
            
            # 2. Saturation ê±°ë¦¬
            sat_distance = abs(s1 - s2) / 255.0  # ì •ê·œí™” (0-1)
            
            # 3. Value ê±°ë¦¬  
            val_distance = abs(v1 - v2) / 255.0  # ì •ê·œí™” (0-1)
            
            # ğŸš€ ê°€ì¤‘ í‰ê·  ê±°ë¦¬ (Hueì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            total_distance = (0.5 * hue_distance + 0.3 * sat_distance + 0.2 * val_distance)
            
            distance_matrix[i][j] = distance_matrix[j][i] = total_distance
    
    return distance_matrix

def create_color_similarity_heatmap(hold_data, vectors):
    """ğŸ”¥ í™€ë“œ ê°„ ìƒ‰ìƒ ìœ ì‚¬ë„ íˆíŠ¸ë§µ - ê°•í™”ëœ ë²„ì „"""
    if len(hold_data) == 0:
        return None
    
    # ğŸš€ ê°•í™”ëœ ìƒ‰ìƒ ê±°ë¦¬ ë§¤íŠ¸ë¦­ìŠ¤ ì‚¬ìš©
    distance_matrix = create_enhanced_color_distance_matrix(hold_data)
    
    # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬ë„ ë†’ìŒ)
    similarity_matrix = 1 - distance_matrix
    
    # í™€ë“œ IDì™€ ê·¸ë£¹ ì •ë³´ ì¤€ë¹„
    hold_ids = [str(h["id"]) for h in hold_data]
    hold_groups = [h["group"] if h["group"] is not None else -1 for h in hold_data]
    
    # ğŸš€ ë” ë„“ì€ ìƒ‰ìƒ ë²”ìœ„ ì‚¬ìš© (0.2-1.0)
    min_sim = np.min(similarity_matrix)
    max_sim = np.max(similarity_matrix)
    
    fig = go.Figure(data=go.Heatmap(
        z=similarity_matrix,
        x=hold_ids,
        y=hold_ids,
        colorscale='RdYlBu_r',  # ë¹¨ê°•-ë…¸ë‘-íŒŒë‘ (ì—­ìˆœ)
        zmin=min_sim,  # ë™ì  ë²”ìœ„
        zmax=max_sim,  # ë™ì  ë²”ìœ„
        hoverongaps=False,
        hovertemplate='<b>í™€ë“œ %{y} â†” í™€ë“œ %{x}</b><br>' +
                     'ìƒ‰ìƒ ìœ ì‚¬ë„: %{z:.3f}<br>' +
                     'ê·¸ë£¹ %{y}: ' + str(hold_groups[int('%{y}')-1] if '%{y}'.isdigit() and int('%{y}') <= len(hold_groups) else 'N/A') + '<br>' +
                     'ê·¸ë£¹ %{x}: ' + str(hold_groups[int('%{x}')-1] if '%{x}'.isdigit() and int('%{x}') <= len(hold_groups) else 'N/A') + '<br>' +
                     '<extra></extra>',
        colorbar=dict(title="ìƒ‰ìƒ ìœ ì‚¬ë„")
    ))
    
    # ê·¸ë£¹ë³„ êµ¬ë¶„ì„  ì¶”ê°€
    fig.update_layout(
        title="ğŸ”¥ í™€ë“œ ê°„ ìƒ‰ìƒ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ (ê°•í™”ëœ HSV ê±°ë¦¬)",
        xaxis_title="í™€ë“œ ID",
        yaxis_title="í™€ë“œ ID",
        height=600,
        width=600
    )
    
    return fig

def create_group_similarity_heatmap(hold_data):
    """ğŸ¯ ê·¸ë£¹ ê°„ ìƒ‰ìƒ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤"""
    if len(hold_data) == 0:
        return None
    
    # ê·¸ë£¹ë³„ í‰ê·  ìƒ‰ìƒ ê³„ì‚°
    groups = {}
    for hold in hold_data:
        group = hold["group"]
        if group is not None:
            if group not in groups:
                groups[group] = []
            groups[group].append(hold["dominant_hsv"])
    
    # ê° ê·¸ë£¹ì˜ í‰ê·  HSV ê³„ì‚°
    group_avg_colors = {}
    for group, hsv_list in groups.items():
        avg_h = np.mean([hsv[0] for hsv in hsv_list])
        avg_s = np.mean([hsv[1] for hsv in hsv_list])
        avg_v = np.mean([hsv[2] for hsv in hsv_list])
        group_avg_colors[group] = (avg_h, avg_s, avg_v)
    
    # ê·¸ë£¹ ê°„ ê±°ë¦¬ ê³„ì‚°
    group_ids = sorted(groups.keys())
    n_groups = len(group_ids)
    group_distance_matrix = np.zeros((n_groups, n_groups))
    
    for i, group1 in enumerate(group_ids):
        for j, group2 in enumerate(group_ids):
            if i != j:
                h1, s1, v1 = group_avg_colors[group1]
                h2, s2, v2 = group_avg_colors[group2]
                
                # HSV ê±°ë¦¬ ê³„ì‚°
                hue_diff = min(abs(h1 - h2), 179 - abs(h1 - h2))
                hue_distance = hue_diff / 179.0
                sat_distance = abs(s1 - s2) / 255.0
                val_distance = abs(v1 - v2) / 255.0
                
                total_distance = (0.5 * hue_distance + 0.3 * sat_distance + 0.2 * val_distance)
                group_distance_matrix[i][j] = total_distance
    
    # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
    group_similarity_matrix = 1 - group_distance_matrix
    
    fig = go.Figure(data=go.Heatmap(
        z=group_similarity_matrix,
        x=[f"ê·¸ë£¹ {g}" for g in group_ids],
        y=[f"ê·¸ë£¹ {g}" for g in group_ids],
        colorscale='RdYlBu_r',
        zmin=0,
        zmax=1,
        hoverongaps=False,
        hovertemplate='<b>ê·¸ë£¹ %{y} â†” ê·¸ë£¹ %{x}</b><br>' +
                     'ê·¸ë£¹ ê°„ ìƒ‰ìƒ ìœ ì‚¬ë„: %{z:.3f}<br>' +
                     '<extra></extra>',
        colorbar=dict(title="ê·¸ë£¹ ê°„ ìƒ‰ìƒ ìœ ì‚¬ë„")
    ))
    
    fig.update_layout(
        title="ğŸ¯ ê·¸ë£¹ ê°„ ìƒ‰ìƒ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤",
        xaxis_title="ê·¸ë£¹",
        yaxis_title="ê·¸ë£¹",
        height=500,
        width=500
    )
    
    return fig

def create_color_picker_style_palette(hold_data):
    """ğŸ¨ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒ‰ìƒ ì„ íƒê¸° - ì–´ë‘ì›€â†’ë°ìŒ(ê°€ë¡œ) Ã— ìƒ‰ìƒ(ì„¸ë¡œ)"""
    if len(hold_data) == 0:
        return None
    
    # ìƒ‰ìƒíŒ ë°°ê²½ ìƒì„±
    fig = go.Figure()
    
    # ğŸ¨ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ì„ Heatmapìœ¼ë¡œ ìƒì„±
    create_gradient_background_heatmap(fig)
    
    # ê·¸ë£¹ë³„ ìƒ‰ìƒ ë§¤í•‘
    groups = [h["group"] for h in hold_data if h["group"] is not None]
    unique_groups = sorted(set(groups))
    group_colors = px.colors.qualitative.Set3[:len(unique_groups)]
    group_color_map = {g: group_colors[i % len(group_colors)] for i, g in enumerate(unique_groups)}
    
    # ê° í™€ë“œë¥¼ ì •í™•í•œ ìœ„ì¹˜ì— í‘œì‹œ
    for i, hold in enumerate(hold_data):
        h, s, v = hold["dominant_hsv"]
        group = hold["group"] if hold["group"] is not None else -1
        
        # ì‹¤ì œ í™€ë“œ ìƒ‰ìƒ
        actual_color = hsv_to_rgb([h, s, v])
        color_rgb = f"rgb({actual_color[0]}, {actual_color[1]}, {actual_color[2]})"
        
        # í…Œë‘ë¦¬ ìƒ‰ìƒ (ê·¸ë£¹ êµ¬ë¶„ìš©)
        border_color = group_color_map.get(group, "#cccccc")
        
        fig.add_trace(
            go.Scatter(
                x=[v],  # Value (ê°€ë¡œì¶•)
                y=[h],  # Hue (ì„¸ë¡œì¶•)
                mode='markers+text',
                marker=dict(
                    color=color_rgb,
                    size=12,  # ì•½ê°„ ë” í° í¬ê¸°ë¡œ ì¡°ì •
                    line=dict(color=border_color, width=2),
                    opacity=1.0  # ì™„ì „ ë¶ˆíˆ¬ëª…
                ),
                text=[f"{hold['id']}"],
                textposition="top center",
                textfont=dict(size=8, color="white", family="Arial Black"),
                name=f"Group {group}",
                showlegend=False,
                hovertemplate=f"<b>í™€ë“œ ID: {hold['id']}</b><br>" +
                            f"ê·¸ë£¹: {group}<br>" +
                            f"ì‹¤ì œ ìƒ‰ìƒ: {color_rgb}<br>" +
                            f"Hue: {h:.1f}Â°<br>" +
                            f"Saturation: {s:.1f}<br>" +
                            f"Value: {v:.1f}<extra></extra>"
            )
        )
    
    # ì¶• ì„¤ì •
    fig.update_layout(
        title="ğŸ¨ ê·¸ë¼ë°ì´ì…˜ ìƒ‰ìƒ ì„ íƒê¸° - ê°€ë¡œ=ë°ê¸°(ì–´ë‘ì›€â†’ë°ìŒ), ì„¸ë¡œ=ìƒ‰ìƒ(ë¹¨ê°•â†’ë³´ë¼)",
        xaxis_title="Value (ë°ê¸°) - 0(ê²€ì •) â†’ 255(ë°ìŒ)",
        yaxis_title="Hue (ìƒ‰ìƒ) - 0Â°(ë¹¨ê°•) â†’ 60Â°(ë…¸ë‘) â†’ 120Â°(ì´ˆë¡) â†’ 180Â°(ë³´ë¼)",
        xaxis=dict(range=[0, 255], dtick=25, showgrid=True, gridcolor="white", gridwidth=0.5),
        yaxis=dict(range=[0, 179], dtick=15, showgrid=True, gridcolor="white", gridwidth=0.5),
        width=1200,  # ë” ë„“ê²Œ
        height=800,  # ë” ë†’ê²Œ
        plot_bgcolor="white",
        paper_bgcolor="white"
    )
    
    return fig

def create_simple_color_palette(hold_data):
    """ğŸ¨ ê°„ë‹¨í•œ ìƒ‰ìƒíŒ ì‹œê°í™” - ì˜¬ë°”ë¥¸ ì¶• ë°°ì¹˜ (ë°°ê²½ ì—†ëŠ” ë²„ì „)"""
    if len(hold_data) == 0:
        return None
    
    # ìƒ‰ìƒíŒ ë°°ê²½ ì—†ì´ ë°”ë¡œ í™€ë“œë“¤ë§Œ í‘œì‹œ
    fig = go.Figure()
    
    # ê·¸ë£¹ë³„ ìƒ‰ìƒ ë§¤í•‘
    groups = [h["group"] for h in hold_data if h["group"] is not None]
    unique_groups = sorted(set(groups))
    group_colors = px.colors.qualitative.Set3[:len(unique_groups)]
    group_color_map = {g: group_colors[i % len(group_colors)] for i, g in enumerate(unique_groups)}
    
    # ê° í™€ë“œë¥¼ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— í‘œì‹œ
    for i, hold in enumerate(hold_data):
        h, s, v = hold["dominant_hsv"]
        group = hold["group"] if hold["group"] is not None else -1
        
        # ì‹¤ì œ í™€ë“œ ìƒ‰ìƒ
        actual_color = hsv_to_rgb([h, s, v])
        color_rgb = f"rgb({actual_color[0]}, {actual_color[1]}, {actual_color[2]})"
        
        # í…Œë‘ë¦¬ ìƒ‰ìƒ (ê·¸ë£¹ êµ¬ë¶„ìš©)
        border_color = group_color_map.get(group, "#cccccc")
        
        fig.add_trace(
            go.Scatter(
                x=[v],  # Value (ê°€ë¡œì¶•) - ì–´ë‘ì›€â†’ë°ìŒ
                y=[h],  # Hue (ì„¸ë¡œì¶•) - ë¹¨ê°•â†’ë³´ë¼
                mode='markers+text',
                marker=dict(
                    color=color_rgb,
                    size=10,  # ì ë‹¹í•œ í¬ê¸°
                    line=dict(color=border_color, width=2),
                    opacity=1.0  # ì™„ì „ ë¶ˆíˆ¬ëª…
                ),
                text=[f"{hold['id']}"],
                textposition="top center",
                textfont=dict(size=8, color="white", family="Arial Black"),
                name=f"Group {group}",
                showlegend=False,
                hovertemplate=f"<b>í™€ë“œ ID: {hold['id']}</b><br>" +
                            f"ê·¸ë£¹: {group}<br>" +
                            f"ì‹¤ì œ ìƒ‰ìƒ: {color_rgb}<br>" +
                            f"Hue: {h:.1f}Â°<br>" +
                            f"Saturation: {s:.1f}<br>" +
                            f"Value: {v:.1f}<extra></extra>"
            )
        )
    
    # ì¶• ì„¤ì •
    fig.update_layout(
        title="ğŸ¨ ê°„ë‹¨í•œ í™€ë“œ ìƒ‰ìƒíŒ - ê°€ë¡œ=ë°ê¸°(ì–´ë‘ì›€â†’ë°ìŒ), ì„¸ë¡œ=ìƒ‰ìƒ(ë¹¨ê°•â†’ë³´ë¼)",
        xaxis_title="Value (ë°ê¸°) - 0(ê²€ì •) â†’ 255(ë°ìŒ)",
        yaxis_title="Hue (ìƒ‰ìƒ) - 0Â°(ë¹¨ê°•) â†’ 60Â°(ë…¸ë‘) â†’ 120Â°(ì´ˆë¡) â†’ 180Â°(ë³´ë¼)",
        xaxis=dict(range=[0, 255], dtick=25, showgrid=True, gridcolor="lightgray", gridwidth=1),
        yaxis=dict(range=[0, 179], dtick=15, showgrid=True, gridcolor="lightgray", gridwidth=1),
        width=1200,  # ë” ë„“ê²Œ
        height=800,  # ë” ë†’ê²Œ
        plot_bgcolor="white",
        paper_bgcolor="white"
    )
    
    return fig

def create_hsv_color_palette(hold_data):
    """ğŸ¨ HSV ìƒ‰ìƒí™˜ ê¸°ë°˜ ìƒ‰ìƒíŒ ì‹œê°í™” (ê°„ë‹¨í•œ ë²„ì „)"""
    if len(hold_data) == 0:
        return None
    
    # ìƒ‰ìƒíŒ ë°°ê²½ ìƒì„± (ìƒ‰ìƒ ì„ íƒê¸°ì™€ ê°™ì€ ìŠ¤íƒ€ì¼)
    fig = go.Figure()
    
    # ê·¸ë£¹ë³„ ìƒ‰ìƒ ë§¤í•‘
    groups = [h["group"] for h in hold_data if h["group"] is not None]
    unique_groups = sorted(set(groups))
    group_colors = px.colors.qualitative.Set3[:len(unique_groups)]
    group_color_map = {g: group_colors[i % len(group_colors)] for i, g in enumerate(unique_groups)}
    
    # ê° í™€ë“œë¥¼ ìƒ‰ìƒíŒì— í‘œì‹œ
    for i, hold in enumerate(hold_data):
        h, s, v = hold["dominant_hsv"]
        group = hold["group"] if hold["group"] is not None else -1
        
        # HSVë¥¼ 0-360, 0-100 ë²”ìœ„ë¡œ ë³€í™˜
        hue_360 = h * 2  # OpenCV HSVëŠ” 0-179 ë²”ìœ„
        sat_100 = s * 100 / 255  # OpenCV HSVëŠ” 0-255 ë²”ìœ„
        
        # ì‹¤ì œ í™€ë“œ ìƒ‰ìƒ
        actual_color = hsv_to_rgb([h, s, v])
        color_rgb = f"rgb({actual_color[0]}, {actual_color[1]}, {actual_color[2]})"
        
        # í…Œë‘ë¦¬ ìƒ‰ìƒ (ê·¸ë£¹ êµ¬ë¶„ìš©)
        border_color = group_color_map.get(group, "#cccccc")
        
        fig.add_trace(
            go.Scatter(
                x=[hue_360],
                y=[sat_100],
                mode='markers+text',
                marker=dict(
                    color=color_rgb,
                    size=20,
                    line=dict(color=border_color, width=3),
                    opacity=0.8
                ),
                text=[f"ID:{hold['id']}"],
                textposition="top center",
                textfont=dict(size=8, color="black"),
                name=f"Group {group}",
                showlegend=False,
                hovertemplate=f"<b>í™€ë“œ ID: {hold['id']}</b><br>" +
                            f"ê·¸ë£¹: {group}<br>" +
                            f"ì‹¤ì œ ìƒ‰ìƒ: {color_rgb}<br>" +
                            f"Hue: {hue_360:.1f}Â°<br>" +
                            f"Saturation: {sat_100:.1f}%<br>" +
                            f"Value: {v:.1f}<extra></extra>"
            )
        )
    
    # ì¶• ì„¤ì •
    fig.update_layout(
        title="ğŸ¨ HSV ìƒ‰ìƒí™˜ ê¸°ë°˜ í™€ë“œ ìƒ‰ìƒ ë¶„í¬",
        xaxis_title="Hue (0Â° - 360Â°)",
        yaxis_title="Saturation (0% - 100%)",
        xaxis=dict(range=[0, 360], dtick=30),
        yaxis=dict(range=[0, 100], dtick=20),
        width=800,
        height=600
    )
    
    return fig

def create_rgb_color_cube(hold_data):
    """ğŸ¨ RGB 3D ìƒ‰ìƒ íë¸Œ ì‹œê°í™” (ì›ë³¸ ìƒ‰ìƒ)"""
    if len(hold_data) == 0:
        return None
    
    # RGB ì¢Œí‘œ ì¤€ë¹„
    rgb_coords = []
    hold_ids = []
    group_labels = []
    colors = []
    
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        rgb = hsv_to_rgb([h, s, v])
        
        rgb_coords.append(rgb)
        hold_ids.append(hold["id"])
        group_labels.append(hold["group"] if hold["group"] is not None else -1)
        colors.append(f"rgb({rgb[0]}, {rgb[1]}, {rgb[2]})")
    
    # 3D ì‚°ì ë„
    fig = go.Figure(data=go.Scatter3d(
        x=[coord[0] for coord in rgb_coords],
        y=[coord[1] for coord in rgb_coords],
        z=[coord[2] for coord in rgb_coords],
        mode='markers+text',
        marker=dict(
            size=8,
            color=colors,
            opacity=0.8,
            line=dict(width=2, color='black')
        ),
        text=[f"ID:{hid}" for hid in hold_ids],
        textposition="top center",
        textfont=dict(size=8, color="black"),
        hovertemplate='<b>í™€ë“œ ID: %{text}</b><br>' +
                     'ê·¸ë£¹: %{marker.color}<br>' +
                     'RGB: (%{x:.0f}, %{y:.0f}, %{z:.0f})<br>' +
                     '<extra></extra>'
    ))
    
    fig.update_layout(
        title="ğŸ¨ RGB 3D ìƒ‰ìƒ íë¸Œì—ì„œì˜ í™€ë“œ ë¶„í¬",
        scene=dict(
            xaxis_title="Red (0-255)",
            yaxis_title="Green (0-255)",
            zaxis_title="Blue (0-255)",
            xaxis=dict(range=[0, 255]),
            yaxis=dict(range=[0, 255]),
            zaxis=dict(range=[0, 255])
        ),
        width=800,
        height=600
    )
    
    return fig

def create_pure_rgb_color_cube(hold_data):
    """ğŸ¨ ìˆœìˆ˜ 3D RGB ìƒ‰ìƒ íë¸Œ (ê·¸ë£¹ ì •ë³´ ì—†ì´ ì‹¤ì œ í‰ê·  ìƒ‰ìƒë§Œ)"""
    if len(hold_data) == 0:
        return None
    
    import plotly.graph_objects as go
    
    # RGB ì¢Œí‘œì™€ í™€ë“œ ì •ë³´ ì¤€ë¹„
    rgb_coords = []
    hold_ids = []
    hover_texts = []
    
    for hold in hold_data:
        # HSVì—ì„œ RGBë¡œ ë³€í™˜ëœ ê°’ ì‚¬ìš©
        h, s, v = hold["dominant_hsv"]
        rgb = hsv_to_rgb([h, s, v])
        
        rgb_coords.append(rgb)
        hold_ids.append(hold["id"])
        
        # í˜¸ë²„ í…ìŠ¤íŠ¸ (HSVâ†’RGB ë³€í™˜ëœ ê°’ í‘œì‹œ)
        hover_text = f"í™€ë“œ {hold['id']}<br>HSVâ†’RGB: ({rgb[0]:.0f}, {rgb[1]:.0f}, {rgb[2]:.0f})<br>ì›ë³¸ HSV: ({h:.0f}, {s:.0f}, {v:.0f})"
        hover_texts.append(hover_text)
    
    # 3D ì‚°ì ë„ ìƒì„±
    fig = go.Figure()
    
    # ğŸ¨ ê° í™€ë“œë¥¼ ì‹¤ì œ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œ (í…ìŠ¤íŠ¸ ì œê±°, ìƒ‰ìƒë§Œ ê°•ì¡°)
    fig.add_trace(go.Scatter3d(
        x=[coord[0] for coord in rgb_coords],  # Red
        y=[coord[1] for coord in rgb_coords],  # Green  
        z=[coord[2] for coord in rgb_coords],  # Blue
        mode='markers',  # í…ìŠ¤íŠ¸ ì œê±°, ë§ˆì»¤ë§Œ
        marker=dict(
            size=12,  # í¬ê¸° ì¦ê°€
            color=[f'rgb({coord[0]:.0f},{coord[1]:.0f},{coord[2]:.0f})' for coord in rgb_coords],  # ì‹¤ì œ RGB ìƒ‰ìƒ
            opacity=0.9,
            line=dict(width=2, color='rgba(0, 0, 0, 0.5)')  # ê²€ì€ í…Œë‘ë¦¬ë¡œ êµ¬ë¶„
        ),
        hovertemplate='%{hovertext}<extra></extra>',
        hovertext=hover_texts,
        name="í™€ë“œë“¤"
    ))
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title="ğŸ¨ ìˆœìˆ˜ 3D RGB ìƒ‰ìƒ íë¸Œ (HSVâ†’RGB ë³€í™˜)",
        scene=dict(
            xaxis_title="Red (0-255)",
            yaxis_title="Green (0-255)", 
            zaxis_title="Blue (0-255)",
            xaxis=dict(range=[0, 255], dtick=50, showgrid=True, gridcolor="white", gridwidth=0.5),
            yaxis=dict(range=[0, 255], dtick=50, showgrid=True, gridcolor="white", gridwidth=0.5),
            zaxis=dict(range=[0, 255], dtick=50, showgrid=True, gridcolor="white", gridwidth=0.5),
            aspectmode='cube'
        ),
        plot_bgcolor="black",
        paper_bgcolor="black",
        font=dict(color="white")
    )
    
    return fig

def create_lab_color_space_visualization(hold_data, selected_hold_id=None, eps=None):
    """ğŸ¨ Lab ìƒ‰ìƒ ê³µê°„ ì‹œê°í™”"""
    import plotly.graph_objects as go
    import numpy as np
    import cv2
    
    # HSV â†’ Lab ë³€í™˜
    lab_vectors = []
    rgb_colors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        hsv_arr = np.uint8([[[h, s, v]]])
        rgb_arr = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
        rgb_image = np.uint8([[[rgb_arr[0], rgb_arr[1], rgb_arr[2]]]])
        lab_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2Lab)[0][0]
        lab_vectors.append([lab_image[0], lab_image[1], lab_image[2]])
        rgb_colors.append(f"rgb({rgb_arr[0]}, {rgb_arr[1]}, {rgb_arr[2]})")
    
    lab_vectors = np.array(lab_vectors)
    
    # Lab ê³µê°„ì—ì„œ 3D ì‹œê°í™”
    fig = go.Figure()
    
    # ê·¸ë£¹ë³„ë¡œ ìƒ‰ìƒ êµ¬ë¶„
    groups = {}
    for i, hold in enumerate(hold_data):
        group_id = hold["group"]
        if group_id not in groups:
            groups[group_id] = {"indices": [], "colors": [], "lab": []}
        groups[group_id]["indices"].append(i)
        groups[group_id]["colors"].append(rgb_colors[i])
        groups[group_id]["lab"].append(lab_vectors[i])
    
    # ê° ê·¸ë£¹ë³„ë¡œ ì  ì¶”ê°€
    for group_id, group_data in groups.items():
        lab_points = np.array(group_data["lab"])
        fig.add_trace(go.Scatter3d(
            x=lab_points[:, 1],  # aì¶• (ë…¹ìƒ‰-ë¹¨ê°•)
            y=lab_points[:, 2],  # bì¶• (íŒŒë‘-ë…¸ë‘)
            z=lab_points[:, 0],  # Lì¶• (ëª…ë„)
            mode='markers+text',
            marker=dict(
                size=8,
                color=group_data["colors"],
                opacity=0.8
            ),
            text=[f"H{hold_data[i]['id']}" for i in group_data["indices"]],
            textposition="top center",
            textfont=dict(size=10),
            name=f'ê·¸ë£¹ {group_id} ({len(group_data["indices"])}ê°œ)',
            hovertemplate='í™€ë“œ ID: %{text}<br>L: %{z:.0f}<br>a: %{x:.0f}<br>b: %{y:.0f}<extra></extra>'
        ))
    
    fig.update_layout(
        title="ğŸ¨ Lab ìƒ‰ìƒ ê³µê°„ ì‹œê°í™” (L:ëª…ë„, a:ë…¹ìƒ‰-ë¹¨ê°•, b:íŒŒë‘-ë…¸ë‘)",
        scene=dict(
            xaxis_title="aì¶• (ë…¹ìƒ‰ â† â†’ ë¹¨ê°•)",
            yaxis_title="bì¶• (íŒŒë‘ â† â†’ ë…¸ë‘)",
            zaxis_title="Lì¶• (ëª…ë„)",
            aspectmode='cube'
        ),
        width=800,
        height=600
    )
    
    return fig

def create_cylindrical_hsv_visualization(hold_data, selected_hold_id=None, eps=None):
    """ğŸ¨ ì›í†µ ì¢Œí‘œê³„ HSV ì‹œê°í™”"""
    import plotly.graph_objects as go
    import numpy as np
    import cv2
    
    # HSV â†’ ì›í†µ ì¢Œí‘œê³„ ë³€í™˜
    cylindrical_vectors = []
    rgb_colors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        
        # ì›í†µ ì¢Œí‘œê³„ ë³€í™˜
        theta = np.radians(h)
        r = s
        z = v * 0.2  # Value ê°€ì¤‘ì¹˜ ê°ì†Œ
        
        x = r * np.cos(theta)
        y = r * np.sin(theta)
        
        cylindrical_vectors.append([x, y, z])
        
        # RGB ìƒ‰ìƒ ê³„ì‚°
        hsv_arr = np.uint8([[[h, s, v]]])
        rgb_arr = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
        rgb_colors.append(f"rgb({rgb_arr[0]}, {rgb_arr[1]}, {rgb_arr[2]})")
    
    cylindrical_vectors = np.array(cylindrical_vectors)
    
    # ì›í†µ ì¢Œí‘œê³„ì—ì„œ 3D ì‹œê°í™”
    fig = go.Figure()
    
    # ê·¸ë£¹ë³„ë¡œ ìƒ‰ìƒ êµ¬ë¶„
    groups = {}
    for i, hold in enumerate(hold_data):
        group_id = hold["group"]
        if group_id not in groups:
            groups[group_id] = {"indices": [], "colors": [], "coords": []}
        groups[group_id]["indices"].append(i)
        groups[group_id]["colors"].append(rgb_colors[i])
        groups[group_id]["coords"].append(cylindrical_vectors[i])
    
    # ê° ê·¸ë£¹ë³„ë¡œ ì  ì¶”ê°€
    for group_id, group_data in groups.items():
        coords = np.array(group_data["coords"])
        fig.add_trace(go.Scatter3d(
            x=coords[:, 0],  # X (Saturation * cos(Hue))
            y=coords[:, 1],  # Y (Saturation * sin(Hue))
            z=coords[:, 2],  # Z (Value * 0.2)
            mode='markers+text',
            marker=dict(
                size=8,
                color=group_data["colors"],
                opacity=0.8
            ),
            text=[f"H{hold_data[i]['id']}" for i in group_data["indices"]],
            textposition="top center",
            textfont=dict(size=10),
            name=f'ê·¸ë£¹ {group_id} ({len(group_data["indices"])}ê°œ)',
            hovertemplate='í™€ë“œ ID: %{text}<br>X: %{x:.1f}<br>Y: %{y:.1f}<br>Z: %{z:.1f}<extra></extra>'
        ))
    
    fig.update_layout(
        title="ğŸ¨ ì›í†µ ì¢Œí‘œê³„ HSV ì‹œê°í™” (Hue:ê°ë„, Saturation:ë°˜ì§€ë¦„, Value:ë†’ì´)",
        scene=dict(
            xaxis_title="X (Saturation Ã— cos(Hue))",
            yaxis_title="Y (Saturation Ã— sin(Hue))",
            zaxis_title="Z (Value Ã— 0.2)",
            aspectmode='cube'
        ),
        width=800,
        height=600
    )
    
    return fig

def create_custom_color_space_visualization(hold_data, selected_hold_id=None, eps=None):
    """ğŸ¨ ì»¤ìŠ¤í…€ ìƒ‰ìƒ ê³µê°„ ì‹œê°í™”"""
    import plotly.graph_objects as go
    import numpy as np
    import cv2
    
    # ì»¤ìŠ¤í…€ ìƒ‰ìƒ ê³µê°„ ë³€í™˜
    custom_vectors = []
    rgb_colors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        hsv_arr = np.uint8([[[h, s, v]]])
        rgb_arr = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
        
        # ì»¤ìŠ¤í…€ ë³€í™˜ ì ìš©
        custom_rgb = custom_color_space_transform([rgb_arr[0], rgb_arr[1], rgb_arr[2]])
        custom_vectors.append(custom_rgb)
        rgb_colors.append(f"rgb({rgb_arr[0]}, {rgb_arr[1]}, {rgb_arr[2]})")
    
    custom_vectors = np.array(custom_vectors)
    
    # ì»¤ìŠ¤í…€ ê³µê°„ì—ì„œ 3D ì‹œê°í™”
    fig = go.Figure()
    
    # ê·¸ë£¹ë³„ë¡œ ìƒ‰ìƒ êµ¬ë¶„
    groups = {}
    for i, hold in enumerate(hold_data):
        group_id = hold["group"]
        if group_id not in groups:
            groups[group_id] = {"indices": [], "colors": [], "coords": []}
        groups[group_id]["indices"].append(i)
        groups[group_id]["colors"].append(rgb_colors[i])
        groups[group_id]["coords"].append(custom_vectors[i])
    
    # ê° ê·¸ë£¹ë³„ë¡œ ì  ì¶”ê°€
    for group_id, group_data in groups.items():
        coords = np.array(group_data["coords"])
        fig.add_trace(go.Scatter3d(
            x=coords[:, 0],  # Rì¶• (í™•ì¥ë¨)
            y=coords[:, 1],  # Gì¶• (í™•ì¥ë¨)
            z=coords[:, 2],  # Bì¶• (í™•ì¥ë¨)
            mode='markers+text',
            marker=dict(
                size=8,
                color=group_data["colors"],
                opacity=0.8
            ),
            text=[f"H{hold_data[i]['id']}" for i in group_data["indices"]],
            textposition="top center",
            textfont=dict(size=10),
            name=f'ê·¸ë£¹ {group_id} ({len(group_data["indices"])}ê°œ)',
            hovertemplate='í™€ë“œ ID: %{text}<br>R: %{x:.0f}<br>G: %{y:.0f}<br>B: %{z:.0f}<extra></extra>'
        ))
    
    fig.update_layout(
        title="ğŸ¨ ì»¤ìŠ¤í…€ ìƒ‰ìƒ ê³µê°„ ì‹œê°í™” (ì£¼ìš” ìƒ‰ìƒ ê°„ ê±°ë¦¬ í™•ì¥)",
        scene=dict(
            xaxis_title="Rì¶• (í™•ì¥ë¨)",
            yaxis_title="Gì¶• (í™•ì¥ë¨)",
            zaxis_title="Bì¶• (í™•ì¥ë¨)",
            aspectmode='cube'
        ),
        width=800,
        height=600
    )
    
    return fig

def rgb_to_lch(rgb):
    """RGB â†’ LCh ë³€í™˜ (Hue wrap í•´ê²°)"""
    import cv2
    import numpy as np
    
    # RGB â†’ Lab ë³€í™˜
    rgb_image = np.uint8([[[rgb[0], rgb[1], rgb[2]]]])
    lab_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2Lab)[0][0]
    L, a, b = lab_image[0], lab_image[1], lab_image[2]
    
    # Lab â†’ LCh ë³€í™˜
    C = np.sqrt(a*a + b*b)  # Chroma
    h = np.arctan2(b, a)    # Hue (ë¼ë””ì•ˆ)
    
    # Hueë¥¼ cos, sinìœ¼ë¡œ ë³€í™˜í•˜ì—¬ wrap ë¬¸ì œ í•´ê²°
    cos_h = np.cos(h)
    sin_h = np.sin(h)
    
    return [L, C*cos_h, C*sin_h, C]

def ciede2000_distance_simple(rgb1, rgb2):
    """ê°„ë‹¨í•œ CIEDE2000 ê±°ë¦¬ ê³„ì‚°"""
    import cv2
    import numpy as np
    
    # RGB â†’ Lab ë³€í™˜
    lab1 = cv2.cvtColor(np.uint8([[[rgb1[0], rgb1[1], rgb1[2]]]]), cv2.COLOR_RGB2Lab)[0][0]
    lab2 = cv2.cvtColor(np.uint8([[[rgb2[0], rgb2[1], rgb2[2]]]]), cv2.COLOR_RGB2Lab)[0][0]
    
    # ê°„ë‹¨í•œ ê°€ì¤‘ì¹˜ ì ìš© (L*0.3, a*1.5, b*1.5)
    L1, a1, b1 = lab1[0]*0.3, lab1[1]*1.5, lab1[2]*1.5
    L2, a2, b2 = lab2[0]*0.3, lab2[1]*1.5, lab2[2]*1.5
    
    # ìœ í´ë¦¬ë“œ ê±°ë¦¬
    distance = np.sqrt((L1-L2)**2 + (a1-a2)**2 + (b1-b2)**2)
    return distance

def lch_cosine_dbscan_clustering(hold_data, vectors, eps=0.3):
    """ğŸ¨ LCh ë³€í™˜ + Cosine ê±°ë¦¬ DBSCAN"""
    from sklearn.cluster import DBSCAN
    import numpy as np
    
    # HSV â†’ RGB â†’ LCh ë³€í™˜
    lch_vectors = []
    rgb_colors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        hsv_arr = np.uint8([[[h, s, v]]])
        rgb_arr = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
        
        # LCh ë³€í™˜ (Hue wrap í•´ê²°)
        lch = rgb_to_lch([rgb_arr[0], rgb_arr[1], rgb_arr[2]])
        lch_vectors.append(lch)
        rgb_colors.append([rgb_arr[0], rgb_arr[1], rgb_arr[2]])
    
    lch_vectors = np.array(lch_vectors)
    
    # Cosine ê±°ë¦¬ë¡œ DBSCAN
    clustering = DBSCAN(eps=eps, min_samples=1, metric='cosine').fit(lch_vectors)
    
    # ê²°ê³¼ ì ìš©
    for i, hold in enumerate(hold_data):
        hold["group"] = int(clustering.labels_[i])
    
    print(f"ğŸ¨ LCh+Cosine í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ: {len(set(clustering.labels_))}ê°œ ê·¸ë£¹")
    return hold_data

def ciede2000_mds_dbscan_clustering(hold_data, vectors, eps=0.3):
    """ğŸ¨ CIEDE2000 + MDS + DBSCAN"""
    from sklearn.cluster import DBSCAN
    from sklearn.manifold import MDS
    import numpy as np
    
    # HSV â†’ RGB ë³€í™˜
    rgb_colors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        hsv_arr = np.uint8([[[h, s, v]]])
        rgb_arr = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
        rgb_colors.append([rgb_arr[0], rgb_arr[1], rgb_arr[2]])
    
    rgb_colors = np.array(rgb_colors)
    
    # CIEDE2000 ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
    n = len(rgb_colors)
    distance_matrix = np.zeros((n, n))
    
    for i in range(n):
        for j in range(n):
            if i != j:
                distance_matrix[i, j] = ciede2000_distance_simple(rgb_colors[i], rgb_colors[j])
    
    # MDSë¡œ 2D ë³€í™˜ (ê· ë“±í•œ ê±°ë¦¬ ë¶„í¬)
    mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)
    mds_coords = mds.fit_transform(distance_matrix)
    
    # MDS ì¢Œí‘œë¡œ DBSCAN
    clustering = DBSCAN(eps=eps, min_samples=1, metric='euclidean').fit(mds_coords)
    
    # ê²°ê³¼ ì ìš©
    for i, hold in enumerate(hold_data):
        hold["group"] = int(clustering.labels_[i])
    
    print(f"ğŸ¨ CIEDE2000+MDS í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ: {len(set(clustering.labels_))}ê°œ ê·¸ë£¹")
    return hold_data

def create_mds_visualization(hold_data, selected_hold_id=None, eps=None):
    """ğŸ¨ MDS 2D ì‹œê°í™” (ê· ë“±í•œ ê±°ë¦¬ ë¶„í¬)"""
    import plotly.graph_objects as go
    import numpy as np
    import cv2
    from sklearn.manifold import MDS
    
    # HSV â†’ RGB ë³€í™˜
    rgb_colors = []
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        hsv_arr = np.uint8([[[h, s, v]]])
        rgb_arr = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
        rgb_colors.append([rgb_arr[0], rgb_arr[1], rgb_arr[2]])
    
    rgb_colors = np.array(rgb_colors)
    
    # CIEDE2000 ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
    n = len(rgb_colors)
    distance_matrix = np.zeros((n, n))
    
    for i in range(n):
        for j in range(n):
            if i != j:
                distance_matrix[i, j] = ciede2000_distance_simple(rgb_colors[i], rgb_colors[j])
    
    # MDSë¡œ 2D ë³€í™˜
    mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)
    mds_coords = mds.fit_transform(distance_matrix)
    
    # 2D ì‹œê°í™”
    fig = go.Figure()
    
    # ê·¸ë£¹ë³„ë¡œ ìƒ‰ìƒ êµ¬ë¶„
    groups = {}
    for i, hold in enumerate(hold_data):
        group_id = hold["group"]
        if group_id not in groups:
            groups[group_id] = {"indices": [], "colors": [], "coords": []}
        groups[group_id]["indices"].append(i)
        groups[group_id]["colors"].append(f"rgb({rgb_colors[i][0]}, {rgb_colors[i][1]}, {rgb_colors[i][2]})")
        groups[group_id]["coords"].append(mds_coords[i])
    
    # ê° ê·¸ë£¹ë³„ë¡œ ì  ì¶”ê°€
    for group_id, group_data in groups.items():
        coords = np.array(group_data["coords"])
        fig.add_trace(go.Scatter(
            x=coords[:, 0],  # MDS Xì¶•
            y=coords[:, 1],  # MDS Yì¶•
            mode='markers+text',
            marker=dict(
                size=12,
                color=group_data["colors"],
                opacity=0.8,
                line=dict(width=2, color='white')
            ),
            text=[f"H{hold_data[i]['id']}" for i in group_data["indices"]],
            textposition="top center",
            textfont=dict(size=10, color='black'),
            name=f'ê·¸ë£¹ {group_id} ({len(group_data["indices"])}ê°œ)',
            hovertemplate='í™€ë“œ ID: %{text}<br>X: %{x:.2f}<br>Y: %{y:.2f}<extra></extra>'
        ))
    
    fig.update_layout(
        title="ğŸ¨ MDS 2D ì‹œê°í™” (CIEDE2000 ê±°ë¦¬ ê¸°ë°˜, ê· ë“±í•œ ë¶„í¬)",
        xaxis_title="MDS ì°¨ì› 1",
        yaxis_title="MDS ì°¨ì› 2",
        width=800,
        height=600,
        showlegend=True
    )
    
    return fig

def create_rgb_color_cube_with_groups(hold_data, selected_hold_id=None, eps=None):
    """ğŸ¯ RGB 3D ìƒ‰ìƒ íë¸Œ ì‹œê°í™” (ê·¸ë£¹ë³„ ìƒ‰ìƒ í‘œì‹œ)"""
    if len(hold_data) == 0:
        return None
    
    # ê·¸ë£¹ë³„ ìƒ‰ìƒ ì •ì˜
    group_colors = [
        'red', 'blue', 'green', 'yellow', 'purple', 'orange', 
        'pink', 'cyan', 'lime', 'magenta', 'brown', 'gray', 'black'
    ]
    
    # RGB ì¢Œí‘œì™€ ê·¸ë£¹ ì •ë³´ ì¤€ë¹„
    rgb_coords = []
    hold_ids = []
    group_labels = []
    group_colors_list = []
    hover_texts = []
    
    for hold in hold_data:
        h, s, v = hold["dominant_hsv"]
        rgb = hsv_to_rgb([h, s, v])  # HSVì—ì„œ RGBë¡œ ë³€í™˜
        group_id = hold["group"] if hold["group"] is not None else -1
        
        rgb_coords.append(rgb)
        hold_ids.append(hold["id"])
        group_labels.append(group_id)
        
        # ê·¸ë£¹ë³„ ìƒ‰ìƒ í• ë‹¹ (group_idê°€ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬)
        try:
            if isinstance(group_id, str) and group_id.startswith('g'):
                group_num = int(group_id[1:])  # 'g0' -> 0
            else:
                group_num = int(group_id)
            
            if group_num >= 0 and group_num < len(group_colors):
                group_colors_list.append(group_colors[group_num])
            else:
                group_colors_list.append('gray')  # ë…¸ì´ì¦ˆë‚˜ ë¯¸ë¶„ë¥˜ ê·¸ë£¹
        except (ValueError, TypeError):
            group_colors_list.append('gray')  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ íšŒìƒ‰
        
        # í˜¸ë²„ í…ìŠ¤íŠ¸ ìƒì„± (ì‹¤ì œ RGB ê°’ê³¼ HSV ê°’ ëª¨ë‘ í‘œì‹œ)
        h, s, v = hold["dominant_hsv"]
        hover_texts.append(f"í™€ë“œ ID: {hold['id']}<br>ê·¸ë£¹: G{group_id}<br>ì‹¤ì œ RGB: ({rgb[0]:.0f}, {rgb[1]:.0f}, {rgb[2]:.0f})<br>HSV: ({h:.0f}, {s:.0f}, {v:.0f})")
    
    # 3D ì‚°ì ë„ (ì„ íƒëœ í™€ë“œê°€ ìˆìœ¼ë©´ íˆ¬ëª…ë„ ë‚®ì¶¤)
    base_opacity = 0.4 if selected_hold_id is not None else 0.9
    
    fig = go.Figure(data=go.Scatter3d(
        x=[coord[0] for coord in rgb_coords],
        y=[coord[1] for coord in rgb_coords],
        z=[coord[2] for coord in rgb_coords],
        mode='markers',  # í…ìŠ¤íŠ¸ ì œê±°, ì‹¤ì œ ìƒ‰ìƒë§Œ í‘œì‹œ
        marker=dict(
            size=12,  # í¬ê¸° ì¦ê°€
            color=[f'rgb({coord[0]:.0f},{coord[1]:.0f},{coord[2]:.0f})' for coord in rgb_coords],  # ì‹¤ì œ RGB ìƒ‰ìƒ
            opacity=base_opacity,
            line=dict(width=2, color='rgba(0, 0, 0, 0.5)')
        ),
        hovertemplate='%{hovertext}<extra></extra>',
        hovertext=hover_texts,
        name='ëª¨ë“  í™€ë“œ'
    ))
    
    # ğŸš¨ ì„ íƒëœ í™€ë“œê°€ ìˆìœ¼ë©´ eps êµ¬ í‘œì‹œ
    if selected_hold_id is not None and eps is not None:
        # ì„ íƒëœ í™€ë“œ ì°¾ê¸°
        selected_hold = None
        selected_idx = None
        for i, hold in enumerate(hold_data):
            if hold["id"] == selected_hold_id:
                selected_hold = hold
                selected_idx = i
                break
        
        if selected_hold is not None:
            # ì„ íƒëœ í™€ë“œì˜ RGB ì¢Œí‘œ
            h, s, v = selected_hold["dominant_hsv"]
            selected_rgb = hsv_to_rgb([h, s, v])
            x_center, y_center, z_center = selected_rgb
            
            # eps êµ¬ ìƒì„± (ì™€ì´ì–´í”„ë ˆì„ - ë” ê°€ë²¼ìš´ í‘œí˜„)
            import numpy as np
            
            # êµ¬ì˜ ì™€ì´ì–´í”„ë ˆì„ì„ ê·¸ë¦¬ê¸° ìœ„í•œ ì›ë“¤ (ê²½ë„ì„  + ìœ„ë„ì„ )
            theta = np.linspace(0, 2 * np.pi, 30)
            phi = np.linspace(0, np.pi, 15)
            
            # ê²½ë„ì„  (ì„¸ë¡œ ì›ë“¤)
            for i in range(0, 360, 30):  # 30ë„ ê°„ê²©
                angle = np.radians(i)
                x_line = x_center + eps * np.cos(theta) * np.sin(angle)
                y_line = y_center + eps * np.sin(theta) * np.sin(angle)
                z_line = z_center + eps * np.cos(angle) * np.ones_like(theta)
                
                fig.add_trace(go.Scatter3d(
                    x=x_line,
                    y=y_line,
                    z=z_line,
                    mode='lines',
                    line=dict(color='rgba(100, 100, 255, 0.3)', width=2),
                    showlegend=False,
                    hoverinfo='skip'
                ))
            
            # ìœ„ë„ì„  (ê°€ë¡œ ì›ë“¤)
            for i in range(0, 180, 30):  # 30ë„ ê°„ê²©
                angle = np.radians(i)
                x_line = x_center + eps * np.cos(theta) * np.sin(angle)
                y_line = y_center + eps * np.sin(theta) * np.sin(angle)
                z_line = z_center + eps * np.cos(angle) * np.ones_like(theta)
                
                fig.add_trace(go.Scatter3d(
                    x=x_line,
                    y=y_line,
                    z=z_line,
                    mode='lines',
                    line=dict(color='rgba(100, 100, 255, 0.3)', width=2),
                    showlegend=False,
                    hoverinfo='skip'
                ))
            
            # ì„ íƒëœ í™€ë“œë¥¼ ë” í¬ê²Œ í‘œì‹œ (ë°ì€ ë…¸ë€ìƒ‰ - ëˆˆì— ë„ê²Œ)
            fig.add_trace(go.Scatter3d(
                x=[x_center],
                y=[y_center],
                z=[z_center],
                mode='markers+text',
                marker=dict(
                    size=18,
                    color='rgba(255, 255, 0, 1.0)',  # ë°ì€ ë…¸ë€ìƒ‰
                    opacity=1.0,
                    line=dict(width=4, color='black'),
                    symbol='diamond'  # ë‹¤ì´ì•„ëª¬ë“œ ëª¨ì–‘
                ),
                text=[f"ğŸ¯{selected_hold_id}"],
                textposition="top center",
                textfont=dict(size=12, color="black", family="Arial Black"),
                name=f'ğŸ¯ ì„ íƒëœ í™€ë“œ {selected_hold_id}',
                hovertemplate=f'ğŸ¯ ì„ íƒëœ í™€ë“œ {selected_hold_id}<br>ê·¸ë£¹ G{selected_hold["group"]}<br>RGB({x_center:.0f}, {y_center:.0f}, {z_center:.0f})<extra></extra>'
            ))
            
            # eps êµ¬ ì•ˆì— ìˆëŠ” í™€ë“œë“¤ í‘œì‹œ
            inside_holds = []
            outside_holds = []
            for i, hold in enumerate(hold_data):
                if i != selected_idx:
                    h, s, v = hold["dominant_hsv"]
                    hold_rgb = hsv_to_rgb([h, s, v])
                    dist = np.sqrt(np.sum((np.array(selected_rgb) - np.array(hold_rgb))**2))
                    
                    if dist <= eps:
                        inside_holds.append((hold["id"], hold["group"], dist, hold_rgb))
                    else:
                        outside_holds.append((hold["id"], hold["group"], dist, hold_rgb))
            
            # ğŸš¨ ê²€ì¦ ì •ë³´ë¥¼ streamlitì— í‘œì‹œ (return í›„ì— í‘œì‹œë˜ë„ë¡ ì €ì¥)
            import streamlit as st
            st.session_state['eps_validation_info'] = {
                'selected_hold_id': selected_hold["id"],
                'selected_group': selected_hold["group"],
                'selected_rgb': selected_rgb,
                'eps': eps,
                'inside_holds': inside_holds,
                'outside_holds': outside_holds
            }
            
            if inside_holds:
                inside_x = [rgb[0] for _, _, _, rgb in inside_holds]
                inside_y = [rgb[1] for _, _, _, rgb in inside_holds]
                inside_z = [rgb[2] for _, _, _, rgb in inside_holds]
                inside_texts = [f"í™€ë“œ{hold_id}<br>ê·¸ë£¹G{group_id}<br>ê±°ë¦¬{dist:.2f}" 
                               for hold_id, group_id, dist, _ in inside_holds]
                
                # ê°™ì€ ê·¸ë£¹ê³¼ ë‹¤ë¥¸ ê·¸ë£¹ êµ¬ë¶„
                inside_same_group = [(hold_id, group_id, dist, rgb) for hold_id, group_id, dist, rgb in inside_holds 
                                     if group_id == selected_hold["group"]]
                inside_diff_group = [(hold_id, group_id, dist, rgb) for hold_id, group_id, dist, rgb in inside_holds 
                                     if group_id != selected_hold["group"]]
                
                # ê°™ì€ ê·¸ë£¹ (ë°ì€ ì´ˆë¡ìƒ‰)
                if inside_same_group:
                    fig.add_trace(go.Scatter3d(
                        x=[rgb[0] for _, _, _, rgb in inside_same_group],
                        y=[rgb[1] for _, _, _, rgb in inside_same_group],
                        z=[rgb[2] for _, _, _, rgb in inside_same_group],
                        mode='markers+text',
                        marker=dict(
                            size=14,
                            color='rgba(100, 255, 100, 0.9)',  # ë°ì€ ì´ˆë¡ìƒ‰
                            opacity=1.0,
                            line=dict(width=3, color='darkgreen')
                        ),
                        text=[f"{hold_id}" for hold_id, _, _, _ in inside_same_group],
                        textposition="top center",
                        textfont=dict(size=10, color="darkgreen", family="Arial Black"),
                        hovertemplate='%{hovertext}<extra></extra>',
                        hovertext=[f"âœ…í™€ë“œ{hold_id}<br>ê·¸ë£¹G{group_id}<br>ê±°ë¦¬{dist:.2f}" 
                                  for hold_id, group_id, dist, _ in inside_same_group],
                        name=f'âœ… ê°™ì€ ê·¸ë£¹ ({len(inside_same_group)}ê°œ)'
                    ))
                
                # ë‹¤ë¥¸ ê·¸ë£¹ (ë°ì€ ë¹¨ê°„ìƒ‰ - ê²½ê³ )
                if inside_diff_group:
                    fig.add_trace(go.Scatter3d(
                        x=[rgb[0] for _, _, _, rgb in inside_diff_group],
                        y=[rgb[1] for _, _, _, rgb in inside_diff_group],
                        z=[rgb[2] for _, _, _, rgb in inside_diff_group],
                        mode='markers+text',
                        marker=dict(
                            size=14,
                            color='rgba(255, 100, 100, 0.9)',  # ë°ì€ ë¹¨ê°„ìƒ‰
                            opacity=1.0,
                            line=dict(width=3, color='darkred')
                        ),
                        text=[f"{hold_id}" for hold_id, _, _, _ in inside_diff_group],
                        textposition="top center",
                        textfont=dict(size=10, color="darkred", family="Arial Black"),
                        hovertemplate='%{hovertext}<extra></extra>',
                        hovertext=[f"âŒí™€ë“œ{hold_id}<br>ê·¸ë£¹G{group_id}<br>ê±°ë¦¬{dist:.2f}" 
                                  for hold_id, group_id, dist, _ in inside_diff_group],
                        name=f'âŒ ë‹¤ë¥¸ ê·¸ë£¹ ({len(inside_diff_group)}ê°œ)'
                    ))
    
    fig.update_layout(
        title="ğŸ¯ RGB 3D ìƒ‰ìƒ íë¸Œì—ì„œì˜ ê·¸ë£¹í•‘ ê²°ê³¼ (ê·¸ë£¹ë³„ ìƒ‰ìƒ í‘œì‹œ)",
        scene=dict(
            xaxis_title="Red (0-255)",
            yaxis_title="Green (0-255)",
            zaxis_title="Blue (0-255)",
            xaxis=dict(range=[0, 255]),
            yaxis=dict(range=[0, 255]),
            zaxis=dict(range=[0, 255]),
            aspectmode='cube'  # ì¶• ë¹„ìœ¨ì„ ì •ìœ¡ë©´ì²´ë¡œ ê³ ì •
        ),
        width=800,
        height=600
    )
    
    return fig

def create_color_category_statistics(hold_data):
    """ğŸ¨ ìƒ‰ìƒ ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ì •ë³´"""
    categories = set(h.get("color_category", "unknown") for h in hold_data)
    stats = []
    
    for category in sorted(categories):
        category_holds = [h for h in hold_data if h.get("color_category") == category]
        hsv_values = [h["dominant_hsv"] for h in category_holds]
        
        h_values = [hsv[0] for hsv in hsv_values]
        s_values = [hsv[1] for hsv in hsv_values]
        v_values = [hsv[2] for hsv in hsv_values]
        
        stats.append({
            "ì¹´í…Œê³ ë¦¬": category,
            "í™€ë“œìˆ˜": len(category_holds),
            "í™€ë“œID": [h["id"] for h in category_holds],
            "Hueí‰ê· ": round(np.mean(h_values), 1) if h_values else 0,
            "Hueë²”ìœ„": round(max(h_values) - min(h_values), 1) if h_values else 0,
            "Satí‰ê· ": round(np.mean(s_values), 1) if s_values else 0,
            "Satë²”ìœ„": round(max(s_values) - min(s_values), 1) if s_values else 0,
            "Valí‰ê· ": round(np.mean(v_values), 1) if v_values else 0,
            "Valë²”ìœ„": round(max(v_values) - min(v_values), 1) if v_values else 0
        })
    
    return stats

def create_group_statistics(hold_data):
    """ğŸ“Š ê·¸ë£¹ë³„ í†µê³„ ì •ë³´"""
    groups = [h["group"] for h in hold_data if h["group"] is not None and h["group"] >= 0]
    unique_groups = sorted(set(groups))
    
    stats = []
    for group in unique_groups:
        group_holds = [h for h in hold_data if h["group"] == group]
        hsv_values = [h["dominant_hsv"] for h in group_holds]
        
        h_values = [hsv[0] for hsv in hsv_values]
        s_values = [hsv[1] for hsv in hsv_values]
        v_values = [hsv[2] for hsv in hsv_values]
        
        stats.append({
            "group": group,
            "count": len(group_holds),
            "hold_ids": [h["id"] for h in group_holds],
            "hue_mean": np.mean(h_values),
            "hue_std": np.std(h_values),
            "sat_mean": np.mean(s_values),
            "sat_std": np.std(s_values),
            "val_mean": np.mean(v_values),
            "val_std": np.std(v_values),
            "hue_range": max(h_values) - min(h_values),
            "sat_range": max(s_values) - min(s_values),
            "val_range": max(v_values) - min(v_values)
        })
    
    return stats

# ============================================
# ğŸ¯ ë‚œì´ë„ ë° ìœ í˜• ì¶”ì • í•¨ìˆ˜
# ============================================

def estimate_difficulty(hold_data):
    """
    í™€ë“œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì œ ë‚œì´ë„ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.
    
    Args:
        hold_data: í™€ë“œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        dict: {
            'grade': ë‚œì´ë„ ë“±ê¸‰ (ì˜ˆ: "V3-V4"),
            'grade_level': ë‚œì´ë„ ë ˆë²¨ (ì˜ˆ: "ì¤‘ê¸‰"),
            'score': ë‚œì´ë„ ì ìˆ˜ (0-12),
            'confidence': ì‹ ë¢°ë„ (0-1),
            'factors': íŒë‹¨ ê·¼ê±°
        }
    """
    if not hold_data or len(hold_data) == 0:
        return {
            'grade': "ì•Œ ìˆ˜ ì—†ìŒ",
            'grade_level': "ì•Œ ìˆ˜ ì—†ìŒ",
            'score': 0,
            'confidence': 0.0,
            'factors': {}
        }
    
    score = 0
    factors = {}
    
    # 1. í™€ë“œ ê°œìˆ˜ ë¶„ì„
    num_holds = len(hold_data)
    factors['num_holds'] = num_holds
    if num_holds < 8:
        score += 3
        factors['num_holds_impact'] = "ì ìŒ (ì–´ë ¤ì›€)"
    elif num_holds < 12:
        score += 2
        factors['num_holds_impact'] = "ë³´í†µ"
    else:
        score += 1
        factors['num_holds_impact'] = "ë§ìŒ (ì‰¬ì›€)"
    
    # 2. í™€ë“œ í¬ê¸° ë¶„ì„
    areas = [h.get('area', 2000) for h in hold_data]
    avg_area = np.mean(areas)
    factors['avg_hold_size'] = f"{avg_area:.0f}pxÂ²"
    
    if avg_area < 1500:
        score += 3
        factors['hold_size_impact'] = "ì‘ìŒ (ì–´ë ¤ì›€)"
    elif avg_area < 2500:
        score += 2
        factors['hold_size_impact'] = "ì¤‘í˜•"
    else:
        score += 1
        factors['hold_size_impact'] = "í¼ (ì‰¬ì›€)"
    
    # 3. í™€ë“œ ê°„ê²© ë¶„ì„
    centers = np.array([h['center'] for h in hold_data])
    distances = []
    for i in range(len(centers)):
        for j in range(i + 1, len(centers)):
            dist = np.linalg.norm(centers[i] - centers[j])
            distances.append(dist)
    
    if distances:
        avg_distance = np.mean(distances)
        max_distance = np.max(distances)
        factors['avg_distance'] = f"{avg_distance:.0f}px"
        factors['max_distance'] = f"{max_distance:.0f}px"
        
        if avg_distance > 150:
            score += 3
            factors['distance_impact'] = "ë„“ìŒ (ì–´ë ¤ì›€)"
        elif avg_distance > 100:
            score += 2
            factors['distance_impact'] = "ë³´í†µ"
        else:
            score += 1
            factors['distance_impact'] = "ì¢ìŒ (ì‰¬ì›€)"
    
    # 4. ë†’ì´ ë¶„í¬ ë¶„ì„
    heights = [h['center'][1] for h in hold_data]
    height_range = max(heights) - min(heights)
    factors['height_range'] = f"{height_range:.0f}px"
    
    if height_range > 500:
        score += 2
        factors['height_impact'] = "ë†’ìŒ (ì–´ë ¤ì›€)"
    elif height_range > 300:
        score += 1
        factors['height_impact'] = "ë³´í†µ"
    else:
        factors['height_impact'] = "ë‚®ìŒ (ì‰¬ì›€)"
    
    # 5. ì‘ì€ í™€ë“œ ë¹„ìœ¨
    small_holds = [h for h in hold_data if h.get('area', 2000) < 1500]
    small_ratio = len(small_holds) / len(hold_data)
    factors['small_hold_ratio'] = f"{small_ratio * 100:.0f}%"
    
    if small_ratio > 0.6:
        score += 1
        factors['small_hold_impact'] = "ë§ìŒ (í¬ë¦¼í”„ í•„ìš”)"
    
    # ì ìˆ˜ â†’ ë‚œì´ë„ ë§¤í•‘
    factors['total_score'] = score
    
    if score <= 4:
        grade = "V0-V1"
        grade_level = "ì´ˆê¸‰"
        confidence = 0.55
    elif score <= 6:
        grade = "V2-V3"
        grade_level = "ì´ˆì¤‘ê¸‰"
        confidence = 0.65
    elif score <= 8:
        grade = "V4-V5"
        grade_level = "ì¤‘ê¸‰"
        confidence = 0.60
    elif score <= 10:
        grade = "V6-V7"
        grade_level = "ì¤‘ê³ ê¸‰"
        confidence = 0.50
    else:
        grade = "V8+"
        grade_level = "ê³ ê¸‰"
        confidence = 0.45
    
    return {
        'grade': grade,
        'grade_level': grade_level,
        'score': score,
        'confidence': confidence,
        'factors': factors
    }


def estimate_climb_type(hold_data):
    """
    í™€ë“œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì œ ìœ í˜•ì„ ì¶”ì •í•©ë‹ˆë‹¤.
    
    Args:
        hold_data: í™€ë“œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        dict: {
            'types': ìœ í˜• ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["ë°¸ëŸ°ìŠ¤", "ë‹¤ì´ë‚˜ë¯¹"]),
            'primary_type': ì£¼ìš” ìœ í˜•,
            'confidence': ì‹ ë¢°ë„ (0-1),
            'characteristics': íŠ¹ì§• ì„¤ëª…
        }
    """
    if not hold_data or len(hold_data) < 3:
        return {
            'types': [],
            'primary_type': "ì•Œ ìˆ˜ ì—†ìŒ",
            'confidence': 0.0,
            'characteristics': {}
        }
    
    types = []
    characteristics = {}
    
    centers = np.array([h['center'] for h in hold_data])
    areas = [h.get('area', 2000) for h in hold_data]
    
    # 1. ìˆ˜í‰/ìˆ˜ì§ ë¶„ì‚° ë¹„ìœ¨ (ë°¸ëŸ°ìŠ¤ vs ìº í¼ì‹±)
    horizontal_std = np.std(centers[:, 0])  # xì¶•
    vertical_std = np.std(centers[:, 1])    # yì¶•
    
    if vertical_std > 0:
        ratio = horizontal_std / vertical_std
        characteristics['horizontal_vertical_ratio'] = f"{ratio:.2f}"
        
        if ratio > 1.5:
            types.append("ë°¸ëŸ°ìŠ¤")
            characteristics['balance_note'] = "ìˆ˜í‰ ì´ë™ì´ ë§ì€ ë¬¸ì œ"
        elif ratio < 0.7:
            types.append("ìº í¼ì‹±")
            characteristics['campus_note'] = "ìˆ˜ì§ ìƒìŠ¹ ìœ„ì£¼ì˜ ë¬¸ì œ"
    
    # 2. í™€ë“œ ê°„ ìµœëŒ€ ê±°ë¦¬ (ë‹¤ì´ë‚˜ë¯¹)
    distances = []
    for i in range(len(centers)):
        for j in range(i + 1, len(centers)):
            dist = np.linalg.norm(centers[i] - centers[j])
            distances.append(dist)
    
    if distances:
        max_gap = np.max(distances)
        avg_distance = np.mean(distances)
        characteristics['max_gap'] = f"{max_gap:.0f}px"
        
        if max_gap > 200 and max_gap > avg_distance * 1.8:
            types.append("ë‹¤ì´ë‚˜ë¯¹")
            characteristics['dynamic_note'] = "í° ì í”„ êµ¬ê°„ ì¡´ì¬"
    
    # 3. ì‘ì€ í™€ë“œ ë¹„ìœ¨ (í¬ë¦¼í”„)
    small_holds = [h for h in hold_data if h.get('area', 2000) < 1500]
    small_ratio = len(small_holds) / len(hold_data)
    characteristics['small_hold_ratio'] = f"{small_ratio * 100:.0f}%"
    
    if small_ratio > 0.5:
        types.append("í¬ë¦¼í”„")
        characteristics['crimp_note'] = "ì‘ì€ í™€ë“œê°€ ë§ìŒ"
    
    # 4. í™€ë“œ ë°€ì§‘ë„ (í…Œí¬ë‹ˆì»¬)
    if len(hold_data) > 12 and np.mean(areas) < 2000:
        types.append("í…Œí¬ë‹ˆì»¬")
        characteristics['technical_note'] = "ì •êµí•œ ì›€ì§ì„ í•„ìš”"
    
    # 5. ìˆ˜í‰ ì´ë™ ê±°ë¦¬
    horizontal_range = np.max(centers[:, 0]) - np.min(centers[:, 0])
    vertical_range = np.max(centers[:, 1]) - np.min(centers[:, 1])
    characteristics['horizontal_range'] = f"{horizontal_range:.0f}px"
    characteristics['vertical_range'] = f"{vertical_range:.0f}px"
    
    if horizontal_range > vertical_range * 1.3:
        if "ë°¸ëŸ°ìŠ¤" not in types:
            types.append("íŠ¸ë˜ë²„ìŠ¤")
            characteristics['traverse_note'] = "ì¢Œìš° ì´ë™ì´ ë§ì€ ë¬¸ì œ"
    
    # ìœ í˜•ì´ ì—†ìœ¼ë©´ "ì¼ë°˜"
    if not types:
        types = ["ì¼ë°˜"]
        characteristics['general_note'] = "íŠ¹ë³„í•œ íŠ¹ì§•ì´ ì—†ëŠ” ê· í˜•ì¡íŒ ë¬¸ì œ"
    
    # ì‹ ë¢°ë„ ê³„ì‚° (ìœ í˜•ì´ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ê°ì†Œ)
    confidence = 0.6 if len(types) <= 2 else 0.5
    
    return {
        'types': types,
        'primary_type': types[0] if types else "ì•Œ ìˆ˜ ì—†ìŒ",
        'confidence': confidence,
        'characteristics': characteristics
    }


def analyze_problem(hold_data, group_id=None, wall_angle=None):
    """
    ğŸ§—â€â™€ï¸ AI ê¸°ë°˜ í´ë¼ì´ë° ë¬¸ì œ ë¶„ì„ (ë‚œì´ë„ + ìœ í˜• ì¶”ì •)
    
    Args:
        hold_data: ì „ì²´ í™€ë“œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        group_id: ë¶„ì„í•  ê·¸ë£¹ ID (Noneì´ë©´ ì „ì²´)
        wall_angle: ë²½ ê°ë„ ("overhang", "slab", "face") - ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        dict: {
            'difficulty': ë‚œì´ë„ ì •ë³´,
            'climb_type': ìœ í˜• ì •ë³´,
            'statistics': ê¸°ë³¸ í†µê³„
        }
    """
    # ê·¸ë£¹ í•„í„°ë§
    if group_id is not None:
        filtered_holds = [h for h in hold_data if h.get('group') == group_id]
    else:
        filtered_holds = hold_data
    
    if not filtered_holds or len(filtered_holds) < 3:
        return None
    
    # ğŸ¯ 1. ë‚œì´ë„ ë¶„ì„
    difficulty = analyze_difficulty(filtered_holds)
    
    # ğŸ§—â€â™€ï¸ 2. ë¬¸ì œ ìœ í˜• ë¶„ì„
    climb_type = analyze_climbing_type(filtered_holds, wall_angle)
    
    # ğŸ“Š 3. ê¸°ë³¸ í†µê³„
    centers = np.array([h['center'] for h in filtered_holds])
    areas = np.array([h.get('area', 2000) for h in filtered_holds])
    
    # ê±°ë¦¬ ë¶„ì„
    distances = []
    if len(filtered_holds) > 1:
        for i, h1 in enumerate(filtered_holds):
            for h2 in filtered_holds[i+1:]:
                dist = np.linalg.norm(np.array(h1['center']) - np.array(h2['center']))
                distances.append(dist)
    
    statistics = {
        'num_holds': len(filtered_holds),
        'avg_hold_size': f"{np.mean(areas):.0f}pxÂ²",
        'total_height': f"{np.max(centers[:, 1]) - np.min(centers[:, 1]):.0f}px",
        'total_width': f"{np.max(centers[:, 0]) - np.min(centers[:, 0]):.0f}px",
        'avg_distance': f"{np.mean(distances):.0f}px" if distances else "0px",
        'max_distance': f"{np.max(distances):.0f}px" if distances else "0px"
    }
    
    return {
        'difficulty': difficulty,
        'climb_type': climb_type,
        'statistics': statistics
    }

def analyze_difficulty(filtered_holds):
    """ğŸ¯ ë‚œì´ë„ ë¶„ì„ (ê°œì„  ë²„ì „)"""
    num_holds = len(filtered_holds)
    areas = np.array([h.get('area', 2000) for h in filtered_holds])
    centers = np.array([h['center'] for h in filtered_holds])
    
    # ê±°ë¦¬ ê³„ì‚°
    distances = []
    consecutive_distances = []  # ì¸ì ‘ í™€ë“œ ê°„ ê±°ë¦¬
    if num_holds > 1:
        # ëª¨ë“  í™€ë“œ ê°„ ê±°ë¦¬
        for i, h1 in enumerate(filtered_holds):
            for h2 in filtered_holds[i+1:]:
                dist = np.linalg.norm(np.array(h1['center']) - np.array(h2['center']))
                distances.append(dist)
        
        # ë†’ì´ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì—°ì† ê±°ë¦¬ ê³„ì‚°
        sorted_holds = sorted(filtered_holds, key=lambda h: h['center'][1], reverse=True)
        for i in range(len(sorted_holds) - 1):
            dist = np.linalg.norm(
                np.array(sorted_holds[i]['center']) - np.array(sorted_holds[i+1]['center'])
            )
            consecutive_distances.append(dist)
    
    avg_area = np.mean(areas)
    min_area = np.min(areas)
    max_distance = max(distances) if distances else 0
    avg_distance = np.mean(distances) if distances else 0
    avg_consecutive_distance = np.mean(consecutive_distances) if consecutive_distances else 0
    
    # í™€ë“œ í¬ê¸° ë¶„ì‚° (ì¼ê´€ì„±)
    area_std = np.std(areas)
    
    # ë†’ì´ ë³€í™”
    heights = [h['center'][1] for h in filtered_holds]
    height_range = max(heights) - min(heights) if num_holds > 1 else 0
    
    # ìˆ˜í‰ ë³€í™”
    horizontal_coords = [h['center'][0] for h in filtered_holds]
    horizontal_range = max(horizontal_coords) - min(horizontal_coords) if num_holds > 1 else 0
    
    difficulty_score = 0
    factors = {}
    
    # 1. í™€ë“œ í¬ê¸° ë¶„ì„ (ê°€ì¤‘ì¹˜ ì¦ê°€)
    small_hold_ratio = len([a for a in areas if a < 1200]) / num_holds
    if min_area < 600 or avg_area < 1000:
        difficulty_score += 5
        hold_size_level = "ë§¤ìš° ì‘ìŒ (í¬ë¦¼í”„)"
        factors['hold_size'] = f"ê·¹ì†Œí˜• í™€ë“œ (í‰ê·  {int(avg_area)}pxÂ²)"
    elif avg_area < 1500:
        difficulty_score += 4
        hold_size_level = "ì‘ìŒ"
        factors['hold_size'] = f"ì‘ì€ í™€ë“œ (í‰ê·  {int(avg_area)}pxÂ²)"
    elif avg_area < 2500:
        difficulty_score += 2
        hold_size_level = "ë³´í†µ"
        factors['hold_size'] = f"ë³´í†µ í¬ê¸° í™€ë“œ (í‰ê·  {int(avg_area)}pxÂ²)"
    elif avg_area < 4000:
        difficulty_score += 1
        hold_size_level = "í¼"
        factors['hold_size'] = f"í° í™€ë“œ (í‰ê·  {int(avg_area)}pxÂ²)"
    else:
        difficulty_score += 0
        hold_size_level = "ë§¤ìš° í¼ (ì¥¬ê·¸)"
        factors['hold_size'] = f"ë§¤ìš° í° í™€ë“œ (í‰ê·  {int(avg_area)}pxÂ²)"
    
    # 2. ì—°ì† í™€ë“œ ê°„ê²© ë¶„ì„ (ì‹¤ì œ ë“±ë°˜ ê²½ë¡œ)
    if avg_consecutive_distance > 200:
        difficulty_score += 5
        distance_level = "ë§¤ìš° í° ì í”„"
        factors['distance'] = f"ë‹¤ì´ë‚˜ë¯¹í•œ í° ì í”„ (í‰ê·  {int(avg_consecutive_distance)}px)"
    elif avg_consecutive_distance > 150:
        difficulty_score += 4
        distance_level = "í° ì í”„"
        factors['distance'] = f"í° ì í”„ í•„ìš” (í‰ê·  {int(avg_consecutive_distance)}px)"
    elif avg_consecutive_distance > 100:
        difficulty_score += 2
        distance_level = "ë³´í†µ ê°„ê²©"
        factors['distance'] = f"ë³´í†µ ê°„ê²© (í‰ê·  {int(avg_consecutive_distance)}px)"
    elif avg_consecutive_distance > 60:
        difficulty_score += 1
        distance_level = "ì¢ì€ ê°„ê²©"
        factors['distance'] = f"ì¢ì€ ê°„ê²© (í‰ê·  {int(avg_consecutive_distance)}px)"
    else:
        difficulty_score += 0
        distance_level = "ë§¤ìš° ì¢ì€ ê°„ê²©"
        factors['distance'] = f"ë§¤ìš° ì¢ì€ ê°„ê²© (í‰ê·  {int(avg_consecutive_distance)}px)"
    
    # 3. í™€ë“œ ê°œìˆ˜ ë¶„ì„ (ì ë‹¹í•œ ê°œìˆ˜ê°€ ì ë‹¹í•œ ë‚œì´ë„)
    if num_holds < 4:
        difficulty_score += 4
        holds_level = "ë§¤ìš° ì ìŒ"
        factors['num_holds'] = f"{num_holds}ê°œ - ê·¹ì†Œìˆ˜ í™€ë“œë¡œ ë§¤ìš° ì–´ë ¤ì›€"
    elif num_holds < 6:
        difficulty_score += 3
        holds_level = "ì ìŒ"
        factors['num_holds'] = f"{num_holds}ê°œ - ì ì€ í™€ë“œë¡œ ì–´ë ¤ì›€"
    elif num_holds < 10:
        difficulty_score += 1
        holds_level = "ë³´í†µ"
        factors['num_holds'] = f"{num_holds}ê°œ - ì ë‹¹í•œ ê°œìˆ˜"
    elif num_holds < 15:
        difficulty_score += 0
        holds_level = "ë§ìŒ"
        factors['num_holds'] = f"{num_holds}ê°œ - ë§ì€ í™€ë“œë¡œ ì‰¬ì›€"
    else:
        difficulty_score -= 1
        holds_level = "ë§¤ìš° ë§ìŒ"
        factors['num_holds'] = f"{num_holds}ê°œ - ë§¤ìš° ë§ì€ í™€ë“œë¡œ ì‰¬ì›€"
    
    # 4. ë†’ì´ ë³€í™” ë¶„ì„
    if height_range > 600:
        difficulty_score += 3
        height_level = "ë§¤ìš° í° ë³€í™”"
        factors['height'] = f"ë†’ì´ ë³€í™” {int(height_range)}px - ì²´ë ¥ ì†Œëª¨ í¼"
    elif height_range > 400:
        difficulty_score += 2
        height_level = "í° ë³€í™”"
        factors['height'] = f"ë†’ì´ ë³€í™” {int(height_range)}px - ë³´í†µ"
    elif height_range > 200:
        difficulty_score += 1
        height_level = "ë³´í†µ ë³€í™”"
        factors['height'] = f"ë†’ì´ ë³€í™” {int(height_range)}px - ì ë‹¹í•¨"
    else:
        height_level = "ì‘ì€ ë³€í™”"
        factors['height'] = f"ë†’ì´ ë³€í™” {int(height_range)}px - íŠ¸ë˜ë²„ìŠ¤"
    
    # 5. ìˆ˜í‰ ë³€í™” (íŠ¸ë˜ë²„ìŠ¤)
    if horizontal_range > 500 and height_range < 200:
        difficulty_score += 2
        factors['traverse'] = f"ê¸´ íŠ¸ë˜ë²„ìŠ¤ (ìˆ˜í‰ {int(horizontal_range)}px)"
    
    # 6. í™€ë“œ í¬ê¸° ì¼ê´€ì„±
    if area_std > 1000:
        difficulty_score += 1
        factors['consistency'] = "í™€ë“œ í¬ê¸° í¸ì°¨ê°€ ì»¤ì„œ ì ì‘ ì–´ë ¤ì›€"
    
    # V-ë“±ê¸‰ ë§¤í•‘ (ë” ì„¸ë°€í•˜ê²Œ)
    difficulty_score = max(0, difficulty_score)  # ìŒìˆ˜ ë°©ì§€
    
    if difficulty_score <= 2:
        grade = "V0"
        level = "ì…ë¬¸"
    elif difficulty_score <= 4:
        grade = "V1"
        level = "ì´ˆê¸‰"
    elif difficulty_score <= 6:
        grade = "V2"
        level = "ì´ˆê¸‰+"
    elif difficulty_score <= 8:
        grade = "V3"
        level = "ì´ˆì¤‘ê¸‰"
    elif difficulty_score <= 10:
        grade = "V4"
        level = "ì¤‘ê¸‰"
    elif difficulty_score <= 12:
        grade = "V5"
        level = "ì¤‘ê¸‰+"
    elif difficulty_score <= 14:
        grade = "V6"
        level = "ì¤‘ê³ ê¸‰"
    elif difficulty_score <= 16:
        grade = "V7"
        level = "ê³ ê¸‰"
    elif difficulty_score <= 18:
        grade = "V8"
        level = "ê³ ê¸‰+"
    else:
        grade = "V9+"
        level = "ì „ë¬¸ê°€"
    
    # ì‹ ë¢°ë„ ê³„ì‚° (ë” ë³´ìˆ˜ì )
    confidence = 0.3 + min(num_holds / 20, 0.3)  # 30% ~ 60%
    
    return {
        "grade": grade,
        "level": level,
        "score": difficulty_score,
        "confidence": confidence,
        "factors": factors,
        "details": {
            "hold_size": hold_size_level,
            "distance": distance_level,
            "num_holds": holds_level,
            "height_change": height_level
        }
    }

def analyze_climbing_type(filtered_holds, wall_angle=None):
    """ğŸ§—â€â™€ï¸ í´ë¼ì´ë° ë¬¸ì œ ìœ í˜• ë¶„ì„ (ê°œì„  ë²„ì „)"""
    
    num_holds = len(filtered_holds)
    centers = np.array([h['center'] for h in filtered_holds])
    areas = np.array([h.get('area', 2000) for h in filtered_holds])
    
    # ê¸°ë³¸ í†µê³„
    horizontal_coords = centers[:, 0]
    vertical_coords = centers[:, 1]
    horizontal_std = np.std(horizontal_coords) if num_holds > 1 else 0
    vertical_std = np.std(vertical_coords) if num_holds > 1 else 0
    horizontal_range = np.ptp(horizontal_coords) if num_holds > 1 else 0
    vertical_range = np.ptp(vertical_coords) if num_holds > 1 else 0
    avg_area = np.mean(areas)
    min_area = np.min(areas)
    
    # ê±°ë¦¬ ë¶„ì„
    distances = []
    consecutive_distances = []
    if num_holds > 1:
        # ëª¨ë“  ê±°ë¦¬
        for i, h1 in enumerate(filtered_holds):
            for h2 in filtered_holds[i+1:]:
                dist = np.linalg.norm(np.array(h1['center']) - np.array(h2['center']))
                distances.append(dist)
        
        # ì—°ì† ê±°ë¦¬ (ë†’ì´ ìˆœ)
        sorted_holds = sorted(filtered_holds, key=lambda h: h['center'][1], reverse=True)
        for i in range(len(sorted_holds) - 1):
            dist = np.linalg.norm(
                np.array(sorted_holds[i]['center']) - np.array(sorted_holds[i+1]['center'])
            )
            consecutive_distances.append(dist)
    
    max_distance = max(distances) if distances else 0
    avg_distance = np.mean(distances) if distances else 0
    avg_consecutive = np.mean(consecutive_distances) if consecutive_distances else 0
    
    types = []
    characteristics = {}
    confidence_factors = []
    
    # ğŸ¯ 1. ì´ë™ íŒ¨í„´ ë¶„ì„
    movement_ratio = horizontal_range / (vertical_range + 1)  # ìˆ˜í‰/ìˆ˜ì§ ë¹„ìœ¨
    
    # íŠ¸ë˜ë²„ìŠ¤ (ìˆ˜í‰ ì´ë™)
    if horizontal_range > 400 and vertical_range < 250:
        types.append("íŠ¸ë˜ë²„ìŠ¤")
        characteristics['traverse'] = f"ê¸´ íŠ¸ë˜ë²„ìŠ¤ (ìˆ˜í‰ {int(horizontal_range)}px)"
        confidence_factors.append("traverse_pattern")
    # ìˆ˜ì§ ë“±ë°˜
    elif vertical_range > 400 and horizontal_range < 250:
        types.append("ìˆ˜ì§ë“±ë°˜")
        characteristics['vertical'] = f"ìˆ˜ì§ ë“±ë°˜ (ë†’ì´ {int(vertical_range)}px)"
        confidence_factors.append("vertical_pattern")
    # ëŒ€ê°ì„  ì´ë™
    elif movement_ratio > 0.5 and movement_ratio < 2.0:
        types.append("ëŒ€ê°ì„ ")
        characteristics['diagonal'] = "ëŒ€ê°ì„  ì´ë™ì´ ë§ì€ ë¬¸ì œ"
        confidence_factors.append("diagonal_pattern")
    
    # ğŸ¯ 2. ë‹¤ì´ë‚˜ë¯¹ vs ìŠ¤íƒœí‹±
    dynamic_score = 0
    static_score = 0
    
    # ë‹¤ì´ë‚˜ë¯¹ (í° ì í”„)
    if max_distance > 220:
        dynamic_score += 4
        types.append("ë‹¤ì´ë…¸")
        characteristics['dyno'] = f"ë§¤ìš° í° ì í”„ (ìµœëŒ€ {int(max_distance)}px)"
        confidence_factors.append("dyno")
    elif max_distance > 180:
        dynamic_score += 3
        types.append("ë‹¤ì´ë‚˜ë¯¹")
        characteristics['dynamic'] = f"í° ì í”„ í•„ìš” (ìµœëŒ€ {int(max_distance)}px)"
        confidence_factors.append("dynamic")
    elif avg_consecutive > 120:
        dynamic_score += 2
        types.append("ë‹¤ì´ë‚˜ë¯¹")
        characteristics['dynamic'] = f"ë‹¤ì´ë‚˜ë¯¹í•œ ì´ë™ (í‰ê·  {int(avg_consecutive)}px)"
        confidence_factors.append("dynamic")
    
    # ìŠ¤íƒœí‹± (ì •ì , ë°¸ëŸ°ìŠ¤)
    if dynamic_score == 0 and num_holds >= 6:
        static_score += 2
        types.append("ìŠ¤íƒœí‹±")
        characteristics['static'] = "ì •ë°€í•œ ì›€ì§ì„ì´ í•„ìš”í•œ ìŠ¤íƒœí‹± ë¬¸ì œ"
        confidence_factors.append("static")
    
    # ë°¸ëŸ°ìŠ¤
    if movement_ratio > 1.2:
        types.append("ë°¸ëŸ°ìŠ¤")
        characteristics['balance'] = "ìˆ˜í‰ ì´ë™ì´ ë§ì•„ ë°¸ëŸ°ìŠ¤ ì¤‘ìš”"
        confidence_factors.append("balance")
    
    # ğŸ”„ 3. íŠ¹ìˆ˜ ë™ì‘ ë¶„ì„
    special_moves = []
    
    # ì½”ë””ë„¤ì´ì…˜ (ë§ì€ í™€ë“œ + ì ë‹¹í•œ ê±°ë¦¬)
    if num_holds >= 7 and 80 < avg_consecutive < 150:
        special_moves.append("ì½”ë””ë„¤ì´ì…˜")
        characteristics['coordination'] = f"{num_holds}ê°œ í™€ë“œë¡œ ì—°ì† ë™ì‘ í•„ìš”"
        confidence_factors.append("coordination")
    
    # ëŸ°ì§€ (í° ì í”„ + ì‘ì€ í™€ë“œ)
    if max_distance > 180 and min_area < 1500:
        special_moves.append("ëŸ°ì§€")
        characteristics['lunge'] = "ì‘ì€ í™€ë“œë¡œ ê¸´ ì í”„ í•„ìš”"
        confidence_factors.append("lunge")
    
    # ìº í¼ì‹± (ìˆ˜ì§ + í° ê°„ê²©)
    if vertical_range > horizontal_range * 1.3 and avg_consecutive > 100:
        special_moves.append("ìº í¼ì‹±")
        characteristics['campusing'] = "ìˆ˜ì§ ìƒìŠ¹ ìœ„ì£¼"
        confidence_factors.append("campusing")
    
    # ğŸ—ï¸ 4. í™€ë“œ íƒ€ì… ë¶„ì„
    hold_types = []
    
    # í¬ë¦¼í”„ (ì‘ì€ í™€ë“œ 60% ì´ìƒ)
    small_holds_ratio = len([a for a in areas if a < 1200]) / num_holds
    if small_holds_ratio > 0.7:
        hold_types.append("í¬ë¦¼í”„ ì¤‘ì‹¬")
        characteristics['crimp'] = f"í¬ë¦¼í”„ í™€ë“œ {int(small_holds_ratio*100)}%"
        confidence_factors.append("crimp")
    elif small_holds_ratio > 0.4:
        hold_types.append("í¬ë¦¼í”„")
        characteristics['crimp'] = f"í¬ë¦¼í”„ í™€ë“œ {int(small_holds_ratio*100)}%"
    
    # ì¥¬ê·¸ (í° í™€ë“œ 60% ì´ìƒ)
    large_holds_ratio = len([a for a in areas if a > 3500]) / num_holds
    if large_holds_ratio > 0.6:
        hold_types.append("ì¥¬ê·¸")
        characteristics['jug'] = f"ì¥¬ê·¸ í™€ë“œ {int(large_holds_ratio*100)}%"
        confidence_factors.append("jug")
    
    # í•€ì¹˜ (ê¸¸ì­‰í•œ í™€ë“œ)
    circularities = np.array([h.get('circularity', 0.7) for h in filtered_holds])
    low_circularity_ratio = len([c for c in circularities if c < 0.6]) / num_holds
    if low_circularity_ratio > 0.5:
        hold_types.append("í•€ì¹˜")
        characteristics['pinch'] = f"í•€ì¹˜ í™€ë“œ {int(low_circularity_ratio*100)}%"
        confidence_factors.append("pinch")
    
    # ìŠ¬ë¡œí¼ (ë³¼ë¡í•œ í™€ë“œ)
    convexities = np.array([h.get('convexity', 0.5) for h in filtered_holds])
    high_convexity_ratio = len([c for c in convexities if c > 0.7]) / num_holds
    if high_convexity_ratio > 0.4:
        hold_types.append("ìŠ¬ë¡œí¼")
        characteristics['sloper'] = f"ìŠ¬ë¡œí¼ í™€ë“œ {int(high_convexity_ratio*100)}%"
        confidence_factors.append("sloper")
    
    # ğŸ”ï¸ 5. ë²½ ê°ë„ë³„ íŠ¹ì„±
    wall_characteristics = {}
    if wall_angle:
        if wall_angle == "overhang":
            wall_characteristics['overhang'] = "ì˜¤ë²„í–‰ - ì²´ë ¥ ì†Œëª¨ í¼"
            if dynamic_score > 0:
                types.append("íŒŒì›Œí’€")
                characteristics['powerful'] = "ì˜¤ë²„í–‰ì—ì„œì˜ ë‹¤ì´ë‚˜ë¯¹ - í­ë°œì  í˜ í•„ìš”"
            else:
                types.append("ì§€êµ¬ë ¥")
                characteristics['endurance'] = "ì˜¤ë²„í–‰ì—ì„œì˜ ì§€ì† - ì§€êµ¬ë ¥ ì¤‘ìš”"
            confidence_factors.append("overhang")
        elif wall_angle == "slab":
            wall_characteristics['slab'] = "ìŠ¬ë© - ê· í˜•ê³¼ ì„¬ì„¸í•¨"
            if "ë°¸ëŸ°ìŠ¤" not in types:
                types.append("ë°¸ëŸ°ìŠ¤")
            types.append("í…Œí¬ë‹ˆì»¬")
            characteristics['technical'] = "ìŠ¬ë©ì—ì„œì˜ ì„¬ì„¸í•œ ë°œ ì‚¬ìš©"
            confidence_factors.append("slab")
        elif wall_angle == "face":
            wall_characteristics['face'] = "ì§ë²½ - ê· í˜•ì¡íŒ ë‚œì´ë„"
            confidence_factors.append("face")
    
    # ğŸ­ 6. ì£¼ìš” ìœ í˜• ê²°ì • (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
    primary_type = "ì¼ë°˜"
    
    if wall_angle == "overhang" and dynamic_score > 2:
        primary_type = "ì˜¤ë²„í–‰ ë‹¤ì´ë‚˜ë¯¹"
    elif wall_angle == "slab":
        primary_type = "ìŠ¬ë© ë°¸ëŸ°ìŠ¤"
    elif "ë‹¤ì´ë…¸" in types:
        primary_type = "ë‹¤ì´ë…¸"
    elif "ëŸ°ì§€" in special_moves:
        primary_type = "ëŸ°ì§€"
    elif "íŠ¸ë˜ë²„ìŠ¤" in types:
        primary_type = "íŠ¸ë˜ë²„ìŠ¤"
    elif "ìˆ˜ì§ë“±ë°˜" in types and "ìº í¼ì‹±" in special_moves:
        primary_type = "ìº í¼ì‹±"
    elif "í¬ë¦¼í”„ ì¤‘ì‹¬" in hold_types:
        primary_type = "í¬ë¦¼í”„"
    elif "ìŠ¬ë¡œí¼" in hold_types:
        primary_type = "ìŠ¬ë¡œí¼"
    elif "í•€ì¹˜" in hold_types:
        primary_type = "í•€ì¹˜"
    elif "ë‹¤ì´ë‚˜ë¯¹" in types:
        primary_type = "ë‹¤ì´ë‚˜ë¯¹"
    elif "ë°¸ëŸ°ìŠ¤" in types:
        primary_type = "ë°¸ëŸ°ìŠ¤"
    elif "ì½”ë””ë„¤ì´ì…˜" in special_moves:
        primary_type = "ì½”ë””ë„¤ì´ì…˜"
    elif len(types) > 0:
        primary_type = types[0]
    
    # ì‹ ë¢°ë„ ê³„ì‚° (ìš”ì†Œê°€ ë§ì„ìˆ˜ë¡ ë†’ìŒ)
    confidence = 0.4 + min(len(confidence_factors) * 0.08, 0.4)  # 40% ~ 80%
    
    return {
        "primary_type": primary_type,
        "types": list(set(types + special_moves + hold_types)),
        "confidence": min(confidence, 0.85),
        "characteristics": {**characteristics, **wall_characteristics},
        "analysis": {
            "dynamic_score": dynamic_score,
            "static_score": static_score,
            "special_moves": special_moves,
            "hold_types": hold_types,
            "wall_angle": wall_angle,
            "movement_pattern": {
                "horizontal_range": int(horizontal_range),
                "vertical_range": int(vertical_range),
                "movement_ratio": round(movement_ratio, 2)
            }
        }
    }

# ============================================================================
# ğŸ¨ ë£° ê¸°ë°˜ ìƒ‰ìƒ ë¶„ë¥˜ ì‹œìŠ¤í…œ (CLIP ëŒ€ì²´, ë¹ ë¥¸ ì†ë„)
# ============================================================================

def load_color_ranges(config_path="holdcheck/color_ranges.json"):
    """ìƒ‰ìƒ ë²”ìœ„ ì„¤ì • íŒŒì¼ ë¡œë“œ (ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜)"""
    global _color_ranges_cache
    
    if _color_ranges_cache is not None:
        return _color_ranges_cache
    
    # íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            _color_ranges_cache = json.load(f)
            print(f"âœ… ìƒ‰ìƒ ë²”ìœ„ ì„¤ì • ë¡œë“œ: {config_path}")
            return _color_ranges_cache
    
    # ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ìƒì„±
    _color_ranges_cache = get_default_color_ranges_data()
    save_color_ranges(_color_ranges_cache, config_path)
    print(f"âœ… ê¸°ë³¸ ìƒ‰ìƒ ë²”ìœ„ ìƒì„±: {config_path}")
    return _color_ranges_cache


def save_color_ranges(ranges, config_path="holdcheck/color_ranges.json"):
    """ìƒ‰ìƒ ë²”ìœ„ ì„¤ì • ì €ì¥"""
    os.makedirs(os.path.dirname(config_path), exist_ok=True)
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(ranges, f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ ìƒ‰ìƒ ë²”ìœ„ ì €ì¥: {config_path}")


def get_default_color_ranges_data():
    """ê¸°ë³¸ ìƒ‰ìƒ ë²”ìœ„ ë°ì´í„° (JSON ì§ë ¬í™” ê°€ëŠ¥)"""
    return {
        "version": "1.0",
        "last_updated": "2025-01-01",
        "feedback_count": 0,
        "colors": {
            "black": {
                "name": "ê²€ì •ìƒ‰",
                "priority": 1,
                "hsv_ranges": [
                    {"h": [0, 180], "s": [0, 255], "v": [0, 80]}  # ë§¤ìš° ì–´ë‘ì›€
                ],
                "rgb_conditions": [
                    {"type": "max_value", "threshold": 80},  # max(R,G,B) < 80
                    {"type": "achromatic", "brightness_max": 150, "channel_diff_max": 50}  # ë¬´ì±„ìƒ‰
                ]
            },
            "white": {
                "name": "í°ìƒ‰",
                "priority": 2,
                "hsv_ranges": [
                    {"h": [0, 180], "s": [0, 50], "v": [200, 255]}  # ë°ê³  ì±„ë„ ë‚®ìŒ
                ],
                "rgb_conditions": [
                    {"type": "min_value", "threshold": 180},  # min(R,G,B) > 180
                ]
            },
            "gray": {
                "name": "íšŒìƒ‰",
                "priority": 3,
                "hsv_ranges": [
                    {"h": [0, 180], "s": [0, 50], "v": [80, 200]}  # ì¤‘ê°„ ë°ê¸°, ë‚®ì€ ì±„ë„
                ],
                "rgb_conditions": [
                    {"type": "achromatic", "brightness_min": 80, "brightness_max": 180, "channel_diff_max": 50}
                ]
            },
            "red": {
                "name": "ë¹¨ê°„ìƒ‰",
                "priority": 4,
                "hsv_ranges": [
                    {"h": [0, 10], "s": [100, 255], "v": [100, 255]},  # ë¹¨ê°• (0ë„ ê·¼ì²˜)
                    {"h": [170, 180], "s": [100, 255], "v": [100, 255]}  # ë¹¨ê°• (180ë„ ê·¼ì²˜)
                ],
                "rgb_conditions": [
                    {"type": "dominant_channel", "channel": "r", "min_value": 150, "diff_threshold": 50}
                ]
            },
            "orange": {
                "name": "ì£¼í™©ìƒ‰",
                "priority": 5,
                "hsv_ranges": [
                    {"h": [10, 25], "s": [100, 255], "v": [100, 255]}  # ì£¼í™© (15ë„ ê·¼ì²˜)
                ],
                "rgb_conditions": [
                    {"type": "two_channel_high", "channels": ["r", "g"], "r_min": 150, "g_min": 80, "b_max": 120, "r_over_g": True}
                ]
            },
            "yellow": {
                "name": "ë…¸ë€ìƒ‰",
                "priority": 6,
                "hsv_ranges": [
                    {"h": [25, 40], "s": [100, 255], "v": [150, 255]}  # ë…¸ë‘ (30ë„ ê·¼ì²˜)
                ],
                "rgb_conditions": [
                    {"type": "two_channel_high", "channels": ["r", "g"], "r_min": 150, "g_min": 150, "b_max": 150, "similar": True}
                ]
            },
            "green": {
                "name": "ì´ˆë¡ìƒ‰",
                "priority": 7,
                "hsv_ranges": [
                    {"h": [40, 75], "s": [100, 255], "v": [100, 255]}  # ì´ˆë¡ (60ë„ ê·¼ì²˜) - ë¯¼íŠ¸ì™€ ê²¹ì¹¨ ë°©ì§€
                ],
                "rgb_conditions": [
                    {"type": "dominant_channel", "channel": "g", "min_value": 100, "diff_threshold": 30}
                ]
            },
            "mint": {
                "name": "ë¯¼íŠ¸ìƒ‰",
                "priority": 8,
                "hsv_ranges": [
                    {"h": [75, 105], "s": [100, 255], "v": [150, 255]}  # ì²­ë¡ (90ë„ ê·¼ì²˜) - ë²”ìœ„ í™•ì¥
                ],
                "rgb_conditions": [
                    {"type": "two_channel_high", "channels": ["g", "b"], "g_min": 150, "b_min": 150, "r_max": 150}
                ]
            },
            "blue": {
                "name": "íŒŒë€ìƒ‰",
                "priority": 9,
                "hsv_ranges": [
                    {"h": [105, 130], "s": [100, 255], "v": [100, 255]}  # íŒŒë‘ (120ë„ ê·¼ì²˜) - ë¯¼íŠ¸ì™€ ê²¹ì¹¨ ë°©ì§€
                ],
                "rgb_conditions": [
                    {"type": "dominant_channel", "channel": "b", "min_value": 100, "diff_threshold": 30}
                ]
            },
            "purple": {
                "name": "ë³´ë¼ìƒ‰",
                "priority": 10,
                "hsv_ranges": [
                    {"h": [130, 160], "s": [100, 255], "v": [100, 255]}  # ë³´ë¼ (145ë„ ê·¼ì²˜)
                ],
                "rgb_conditions": [
                    {"type": "two_channel_high", "channels": ["r", "b"], "r_min": 100, "b_min": 100, "g_diff": 20}
                ]
            },
            "pink": {
                "name": "ë¶„í™ìƒ‰",
                "priority": 11,
                "hsv_ranges": [
                    {"h": [160, 170], "s": [50, 150], "v": [180, 255]}  # ë¶„í™ (ë°ì€ ë¹¨ê°•)
                ],
                "rgb_conditions": [
                    {"type": "dominant_channel", "channel": "r", "min_value": 180, "g_min": 100, "b_min": 100}
                ]
            },
            "brown": {
                "name": "ê°ˆìƒ‰",
                "priority": 12,
                "hsv_ranges": [
                    {"h": [0, 10], "s": [80, 200], "v": [50, 150]}  # ì–´ë‘ìš´ ì£¼í™© - ì£¼í™©ê³¼ ê²¹ì¹¨ ë°©ì§€
                ],
                "rgb_conditions": [
                    {"type": "dominant_channel", "channel": "r", "min_value": 80, "max_value": 150, "dark": True}
                ]
            }
        }
    }


def rule_based_color_clustering(hold_data, vectors, config_path="holdcheck/color_ranges.json", 
                                confidence_threshold=0.7, use_hsv=True):
    """
    âš¡ ë£° ê¸°ë°˜ ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë§ (CLIP ëŒ€ì²´, ì´ˆê³ ì†)
    
    RGB/HSV ìƒ‰ìƒ ë²”ìœ„ë¡œ ì§ì ‘ ë¶„ë¥˜ - CLIPë³´ë‹¤ 10-20ë°° ë¹ ë¦„!
    ì‚¬ìš©ì í”¼ë“œë°±ìœ¼ë¡œ ì •í™•ë„ ì§€ì† ê°œì„  ê°€ëŠ¥
    
    Args:
        hold_data: í™€ë“œ ë°ì´í„° (dominant_rgb ë˜ëŠ” dominant_hsv í•„ìš”)
        vectors: ì‚¬ìš© ì•ˆ í•¨ (í˜¸í™˜ì„± ìœ ì§€)
        config_path: ìƒ‰ìƒ ë²”ìœ„ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’ (ë‚®ìœ¼ë©´ unknownìœ¼ë¡œ ë¶„ë¥˜)
        use_hsv: HSV ê³µê°„ ì‚¬ìš© ì—¬ë¶€ (ë” ì •í™•í•¨)
    
    Returns:
        hold_data: ê·¸ë£¹ ì •ë³´ê°€ ì¶”ê°€ëœ í™€ë“œ ë°ì´í„°
    """
    if len(hold_data) == 0:
        return hold_data
    
    import time
    start_time = time.time()
    
    print(f"\nâš¡ ë£° ê¸°ë°˜ ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘ (CLIP ì—†ìŒ, ì´ˆê³ ì†)")
    print(f"   í™€ë“œ ê°œìˆ˜: {len(hold_data)}ê°œ")
    print(f"   ìƒ‰ìƒ ê³µê°„: {'HSV' if use_hsv else 'RGB'}")
    
    # ìƒ‰ìƒ ë²”ìœ„ ë¡œë“œ
    ranges_data = load_color_ranges(config_path)
    colors_config = ranges_data["colors"]
    
    # ê° í™€ë“œë¥¼ ìƒ‰ìƒìœ¼ë¡œ ë¶„ë¥˜
    color_groups = {}
    classification_details = []
    
    for hold_idx, hold in enumerate(hold_data):
        # RGB/HSV ê°’ ê°€ì ¸ì˜¤ê¸°
        if "dominant_hsv" in hold:
            h, s, v = hold["dominant_hsv"]
        elif "dominant_rgb" in hold:
            rgb = hold["dominant_rgb"]
            hsv_arr = np.uint8([[[rgb[0], rgb[1], rgb[2]]]])
            hsv_bgr = cv2.cvtColor(hsv_arr, cv2.COLOR_RGB2HSV)[0][0]
            h, s, v = hsv_bgr
        else:
            h, s, v = 0, 0, 128  # ê¸°ë³¸ê°’
            rgb = [128, 128, 128]
        
        if "dominant_rgb" not in hold:
            hsv_arr = np.uint8([[[h, s, v]]])
            rgb_arr = cv2.cvtColor(hsv_arr, cv2.COLOR_HSV2RGB)[0][0]
            rgb = rgb_arr.tolist()
        else:
            rgb = hold["dominant_rgb"]
        
        # ìƒ‰ìƒ ë¶„ë¥˜ (ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ)
        if use_hsv:
            color_name, confidence, matched_rule = classify_color_by_hsv(
                h, s, v, rgb, colors_config
            )
        else:
            color_name, confidence, matched_rule = classify_color_by_rgb(
                rgb, colors_config
            )
        
        # ì‹ ë¢°ë„ ë‚®ìœ¼ë©´ unknown
        if confidence < confidence_threshold:
            color_name = "unknown"
        
        # í™€ë“œì— ì •ë³´ ì¶”ê°€ (CLIP í˜¸í™˜)
        hold["clip_color_name"] = color_name
        hold["clip_confidence"] = confidence
        hold["color_method"] = "rule_based"
        hold["matched_rule"] = matched_rule
        
        # ê·¸ë£¹í•‘
        if color_name not in color_groups:
            color_groups[color_name] = []
        color_groups[color_name].append(hold)
        
        classification_details.append({
            "hold_id": hold.get("id", hold_idx),
            "rgb": rgb,
            "hsv": [h, s, v],
            "color": color_name,
            "confidence": confidence,
            "rule": matched_rule
        })
    
    # ê·¸ë£¹ ID í• ë‹¹ (ìƒ‰ìƒ ì´ë¦„ ê¸°ì¤€ ì •ë ¬)
    color_order = ["black", "white", "gray", "red", "orange", "yellow", 
                   "lime", "green", "mint", "blue", "purple", "pink", "brown", "unknown"]
    
    group_idx = 0
    for color_name in color_order:
        if color_name in color_groups:
            for hold in color_groups[color_name]:
                hold["group"] = f"g{group_idx}"
            group_idx += 1
    
    elapsed = time.time() - start_time
    
    print(f"\nâœ… ë£° ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ (âš¡ {elapsed:.2f}ì´ˆ)")
    print(f"   ìƒì„±ëœ ê·¸ë£¹ ìˆ˜: {len(color_groups)}ê°œ")
    for color_name in color_order:
        if color_name in color_groups:
            count = len(color_groups[color_name])
            avg_conf = np.mean([h["clip_confidence"] for h in color_groups[color_name]])
            print(f"   {color_name}: {count}ê°œ í™€ë“œ (í‰ê·  ì‹ ë¢°ë„: {avg_conf:.2f})")
    
    return hold_data


def classify_color_simple_hsv(h, s, v):
    """ğŸ¨ ìƒì‹ì ì¸ HSV ê¸°ë°˜ ìƒ‰ìƒ ë¶„ë¥˜ (ëª…ë„ ìš°ì„  íŒë‹¨)"""
    
    # ğŸ”¥ 1ë‹¨ê³„: ëª…ë„ ìš°ì„  íŒë‹¨ (ê²€ì •/í°ìƒ‰ì€ ì±„ë„ ë¬´ê´€)
    if v < 90:
        # ë§¤ìš° ì–´ë‘ì›€ â†’ ê²€ì • (ì±„ë„ ë¬´ê´€!)
        return "black", 0.95
    elif v > 200 and s < 50:
        # ë§¤ìš° ë°ìŒ + ë‚®ì€ ì±„ë„ â†’ í°ìƒ‰
        return "white", 0.95
    
    # ğŸ”¥ 2ë‹¨ê³„: ì±„ë„ ê¸°ë°˜ ë¬´ì±„ìƒ‰ íŒë‹¨ (ì¤‘ê°„ ëª…ë„)
    if s < 30:
        # ì±„ë„ê°€ ë§¤ìš° ë‚®ìŒ â†’ íšŒìƒ‰
        return "gray", 0.90
    
    # 2ë‹¨ê³„: ìœ ì±„ìƒ‰ íŒë‹¨ (OpenCV HëŠ” 0-180)
    if (h >= 0 and h < 8) or (h >= 170):
        return "red", 0.90
    elif h >= 8 and h < 18:
        return "orange", 0.90
    elif h >= 18 and h < 30:
        return "yellow", 0.90
    elif h >= 30 and h < 45:
        return "lime", 0.90  # ì—°ë‘
    elif h >= 45 and h < 80:
        return "green", 0.90
    elif h >= 80 and h < 95:
        return "mint", 0.85  # ë¯¼íŠ¸/ì²­ë¡
    elif h >= 95 and h < 130:
        return "blue", 0.90
    elif h >= 130 and h < 150:
        return "purple", 0.90
    elif h >= 150 and h < 170:
        return "pink", 0.90
    else:
        # ê°ˆìƒ‰ íŒë‹¨ (ë‚®ì€ ì±„ë„ + ë‚®ì€ ëª…ë„)
        if s < 60 and v < 120:
            return "brown", 0.80
        return "unknown", 0.50

def classify_color_by_hsv(h, s, v, rgb, colors_config):
    """HSV ë²”ìœ„ ê¸°ë°˜ ìƒ‰ìƒ ë¶„ë¥˜ (ìƒì‹ì  ë¶„ë¥˜ ìš°ì„  ì‚¬ìš©)"""
    
    # ğŸ”¥ ë¨¼ì € ìƒì‹ì ì¸ HSV ë¶„ë¥˜ ì‹œë„
    color_name, confidence = classify_color_simple_hsv(h, s, v)
    if confidence > 0.80:  # ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
        return color_name, confidence, f"Simple HSV: H={h}, S={s}, V={v}"
    
    # ê¸°ì¡´ config ê¸°ë°˜ ë¶„ë¥˜ (ë°±ì—…)
    sorted_colors = sorted(colors_config.items(), key=lambda x: x[1].get("priority", 999))
    
    for color_name, config in sorted_colors:
        # HSV ë²”ìœ„ ì²´í¬
        if "hsv_ranges" in config:
            for hsv_range in config["hsv_ranges"]:
                h_min, h_max = hsv_range["h"]
                s_min, s_max = hsv_range["s"]
                v_min, v_max = hsv_range["v"]
                
                # HueëŠ” ì›í˜•ì´ë¯€ë¡œ íŠ¹ë³„ ì²˜ë¦¬
                h_match = False
                if h_min <= h_max:
                    h_match = h_min <= h <= h_max
                else:  # ì˜ˆ: [170, 10] (ë¹¨ê°•)
                    h_match = h >= h_min or h <= h_max
                
                if h_match and s_min <= s <= s_max and v_min <= v <= v_max:
                    confidence = calculate_confidence_hsv(h, s, v, hsv_range)
                    return color_name, confidence, f"HSV: H={h}, S={s}, V={v}"
        
        # RGB ì¡°ê±´ ì²´í¬ (ë³´ì¡°)
        if "rgb_conditions" in config:
            for condition in config["rgb_conditions"]:
                if check_rgb_condition(rgb, condition):
                    confidence = 0.8  # RGB ì¡°ê±´ì€ ì•½ê°„ ë‚®ì€ ì‹ ë¢°ë„
                    return color_name, confidence, f"RGB: {rgb}"
    
    # ë§¤ì¹­ ì‹¤íŒ¨ - ê°€ì¥ ê°€ê¹Œìš´ ìƒ‰ìƒ ì°¾ê¸°
    return find_nearest_color_hsv(h, s, v, colors_config)


def classify_color_by_rgb(rgb, colors_config):
    """RGB ì¡°ê±´ ê¸°ë°˜ ìƒ‰ìƒ ë¶„ë¥˜"""
    r, g, b = rgb
    
    sorted_colors = sorted(colors_config.items(), key=lambda x: x[1].get("priority", 999))
    
    for color_name, config in sorted_colors:
        if "rgb_conditions" in config:
            for condition in config["rgb_conditions"]:
                if check_rgb_condition(rgb, condition):
                    confidence = 0.85
                    return color_name, confidence, f"RGB: {rgb}"
    
    # ë§¤ì¹­ ì‹¤íŒ¨
    return "unknown", 0.5, "No match"


def check_rgb_condition(rgb, condition):
    """RGB ì¡°ê±´ ì²´í¬"""
    r, g, b = rgb
    cond_type = condition.get("type")
    
    if cond_type == "max_value":
        return max(r, g, b) < condition["threshold"]
    
    elif cond_type == "min_value":
        return min(r, g, b) > condition["threshold"]
    
    elif cond_type == "achromatic":
        brightness = max(r, g, b)
        channel_diff = max(r, g, b) - min(r, g, b)
        
        checks = []
        if "brightness_min" in condition:
            checks.append(brightness >= condition["brightness_min"])
        if "brightness_max" in condition:
            checks.append(brightness <= condition["brightness_max"])
        if "channel_diff_max" in condition:
            checks.append(channel_diff < condition["channel_diff_max"])
        
        return all(checks) if checks else False
    
    elif cond_type == "dominant_channel":
        channel = condition["channel"]
        min_val = condition.get("min_value", 0)
        diff_thresh = condition.get("diff_threshold", 30)
        
        channel_val = {"r": r, "g": g, "b": b}[channel]
        other_vals = [v for k, v in {"r": r, "g": g, "b": b}.items() if k != channel]
        
        return (channel_val >= min_val and 
                all(channel_val > ov + diff_thresh for ov in other_vals))
    
    elif cond_type == "two_channel_high":
        channels = condition["channels"]
        vals = {"r": r, "g": g, "b": b}
        
        checks = []
        for ch in channels:
            if f"{ch}_min" in condition:
                checks.append(vals[ch] >= condition[f"{ch}_min"])
            if f"{ch}_max" in condition:
                checks.append(vals[ch] <= condition[f"{ch}_max"])
        
        # ì¶”ê°€ ì¡°ê±´
        if condition.get("r_over_g"):
            checks.append(r > g)
        if condition.get("similar"):
            checks.append(abs(r - g) < 50)
        if "g_diff" in condition:
            checks.append(r > g + condition["g_diff"] and b > g + condition["g_diff"])
        
        return all(checks)
    
    return False


def calculate_confidence_hsv(h, s, v, hsv_range):
    """HSV ë§¤ì¹­ ì‹ ë¢°ë„ ê³„ì‚°"""
    h_min, h_max = hsv_range["h"]
    s_min, s_max = hsv_range["s"]
    v_min, v_max = hsv_range["v"]
    
    # ì¤‘ì‹¬ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„
    h_center = (h_min + h_max) / 2
    s_center = (s_min + s_max) / 2
    v_center = (v_min + v_max) / 2
    
    h_dist = min(abs(h - h_center), 180 - abs(h - h_center)) / 90  # ì •ê·œí™”
    s_dist = abs(s - s_center) / 127.5
    v_dist = abs(v - v_center) / 127.5
    
    # ê±°ë¦¬ ê¸°ë°˜ ì‹ ë¢°ë„
    avg_dist = (h_dist + s_dist + v_dist) / 3
    confidence = 1.0 - avg_dist * 0.3  # ìµœëŒ€ 0.3 ê°ì†Œ
    
    return max(0.5, min(1.0, confidence))


def find_nearest_color_hsv(h, s, v, colors_config):
    """ê°€ì¥ ê°€ê¹Œìš´ ìƒ‰ìƒ ì°¾ê¸° (í´ë°±)"""
    # ë¬´ì±„ìƒ‰ ì²´í¬
    if s < 50:
        if v < 80:
            return "black", 0.6, "Fallback: dark achromatic"
        elif v > 180:
            return "white", 0.6, "Fallback: bright achromatic"
        else:
            return "gray", 0.6, "Fallback: mid achromatic"
    
    # Hue ê¸°ë°˜ ë¶„ë¥˜
    if h < 10 or h > 170:
        return "red", 0.5, "Fallback: hue range"
    elif 10 <= h < 25:
        return "orange", 0.5, "Fallback: hue range"
    elif 25 <= h < 40:
        return "yellow", 0.5, "Fallback: hue range"
    elif 40 <= h < 80:
        return "green", 0.5, "Fallback: hue range"
    elif 80 <= h < 100:
        return "mint", 0.5, "Fallback: hue range"
    elif 100 <= h < 130:
        return "blue", 0.5, "Fallback: hue range"
    else:
        return "purple", 0.5, "Fallback: hue range"


def save_user_feedback(hold_data, feedback_list, config_path="holdcheck/color_ranges.json"):
    """
    ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥ ë° ìƒ‰ìƒ ë²”ìœ„ ìë™ ì¡°ì •
    
    Args:
        hold_data: í™€ë“œ ë°ì´í„°
        feedback_list: [{"hold_id": 0, "correct_color": "yellow", "predicted_color": "orange"}, ...]
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
    """
    global _color_feedback_data
    
    print(f"\nğŸ“ ì‚¬ìš©ì í”¼ë“œë°± ì €ì¥ ì¤‘... ({len(feedback_list)}ê°œ)")
    
    # í”¼ë“œë°± ë°ì´í„° ì¶”ê°€
    _color_feedback_data.extend(feedback_list)
    
    # ìƒ‰ìƒ ë²”ìœ„ ë¡œë“œ
    ranges_data = load_color_ranges(config_path)
    
    # í”¼ë“œë°± í†µê³„
    feedback_stats = {}
    for fb in feedback_list:
        pred = fb["predicted_color"]
        correct = fb["correct_color"]
        
        if pred != correct:
            key = f"{pred} -> {correct}"
            if key not in feedback_stats:
                feedback_stats[key] = []
            
            # í™€ë“œ ì°¾ê¸°
            hold = next((h for h in hold_data if h.get("id") == fb["hold_id"]), None)
            if hold:
                feedback_stats[key].append({
                    "rgb": hold.get("dominant_rgb"),
                    "hsv": hold.get("dominant_hsv")
                })
    
    print(f"   ì˜¤ë¶„ë¥˜ íŒ¨í„´:")
    for pattern, samples in feedback_stats.items():
        print(f"   {pattern}: {len(samples)}ê±´")
    
    # ìƒ‰ìƒ ë²”ìœ„ ìë™ ì¡°ì • (í•™ìŠµ)
    adjust_color_ranges(ranges_data, feedback_stats)
    
    # í”¼ë“œë°± ì¹´ìš´íŠ¸ ì¦ê°€
    ranges_data["feedback_count"] += len(feedback_list)
    ranges_data["last_updated"] = str(np.datetime64('now'))
    
    # ì €ì¥
    save_color_ranges(ranges_data, config_path)
    
    print(f"âœ… í”¼ë“œë°± ë°˜ì˜ ì™„ë£Œ! (ì´ {ranges_data['feedback_count']}ê±´)")
    
    # ìºì‹œ ì´ˆê¸°í™”
    global _color_ranges_cache
    _color_ranges_cache = None


def adjust_color_ranges(ranges_data, feedback_stats):
    """í”¼ë“œë°± ê¸°ë°˜ ìƒ‰ìƒ ë²”ìœ„ ìë™ ì¡°ì •"""
    colors_config = ranges_data["colors"]
    
    for pattern, samples in feedback_stats.items():
        if len(samples) < 3:  # ìµœì†Œ 3ê°œ ì´ìƒ
            continue
        
        pred_color, correct_color = pattern.split(" -> ")
        
        if correct_color not in colors_config:
            continue
        
        # ì˜¬ë°”ë¥¸ ìƒ‰ìƒì˜ HSV ë²”ìœ„ í™•ì¥
        hsv_samples = [s["hsv"] for s in samples if s["hsv"]]
        
        if hsv_samples:
            avg_h = np.mean([h for h, s, v in hsv_samples])
            avg_s = np.mean([s for h, s, v in hsv_samples])
            avg_v = np.mean([v for h, s, v in hsv_samples])
            
            print(f"   {correct_color} ë²”ìœ„ í™•ì¥: H={avg_h:.0f}, S={avg_s:.0f}, V={avg_v:.0f}")
            
            # ë²”ìœ„ì— ìƒˆ ìƒ˜í”Œ ì¶”ê°€ (ê°„ë‹¨í•œ ë°©ì‹)
            # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ í´ëŸ¬ìŠ¤í„°ë§ í•„ìš”
            current_ranges = colors_config[correct_color].get("hsv_ranges", [])
            
            # ê¸°ì¡´ ë²”ìœ„ì™€ ê²¹ì¹˜ì§€ ì•Šìœ¼ë©´ ìƒˆ ë²”ìœ„ ì¶”ê°€
            new_range = {
                "h": [max(0, int(avg_h - 10)), min(180, int(avg_h + 10))],
                "s": [max(0, int(avg_s - 30)), min(255, int(avg_s + 30))],
                "v": [max(0, int(avg_v - 30)), min(255, int(avg_v + 30))]
            }
            
            # ì¤‘ë³µ ì²´í¬ (ê°„ë‹¨íˆ)
            is_duplicate = any(
                abs(r["h"][0] - new_range["h"][0]) < 20 for r in current_ranges
            )
            
            if not is_duplicate:
                current_ranges.append(new_range)
                print(f"      ìƒˆ ë²”ìœ„ ì¶”ê°€ë¨!")


def draw_holds_on_image_with_highlights(image, hold_data, bboxes, problems):
    """
    ì´ë¯¸ì§€ì— í™€ë“œë¥¼ ê·¸ë¦¬ê³ , í”¼ë“œë°±ì´ ìˆëŠ” í™€ë“œëŠ” ê°•ì¡°í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
    
    Args:
        image (np.array): ì›ë³¸ ì´ë¯¸ì§€ (BGR í˜•ì‹).
        hold_data (list): ê° í™€ë“œì˜ ì •ë³´ (dict).
        bboxes (list): ê° í™€ë“œì˜ ë°”ìš´ë”© ë°•ìŠ¤ (x1, y1, x2, y2).
        problems (dict): hold_idë¥¼ í‚¤ë¡œ í•˜ê³ , ë¬¸ì œê°€ ìˆëŠ” í™€ë“œ ì •ë³´ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬.
                         ì˜ˆ: {0: {"predicted_color": "yellow", "correct_color": "orange"}}
    Returns:
        np.array: í™€ë“œì™€ ê°•ì¡° í‘œì‹œê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€.
    """
    display_image = image.copy()
    
    # ìƒ‰ìƒ ë§¤í•‘ (BGR í˜•ì‹)
    color_map = {
        "black": (0, 0, 0), "white": (255, 255, 255), "gray": (128, 128, 128),
        "red": (0, 0, 255), "orange": (0, 165, 255), "yellow": (0, 255, 255),
        "green": (0, 255, 0), "mint": (204, 255, 0), "blue": (255, 0, 0),
        "purple": (255, 0, 128), "pink": (204, 102, 255), "brown": (42, 42, 165),
        "unknown": (192, 192, 192) # íšŒìƒ‰
    }
    
    for i, hold in enumerate(hold_data):
        if i >= len(bboxes):
            continue # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì—†ëŠ” í™€ë“œëŠ” ê±´ë„ˆëœ€
            
        x1, y1, x2, y2 = map(int, bboxes[i])
        
        # í™€ë“œ ìƒ‰ìƒ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ unknown)
        color_name = hold.get("clip_color_name", "unknown")
        bbox_color = color_map.get(color_name, color_map["unknown"])
        
        # ë¬¸ì œê°€ ìˆëŠ” í™€ë“œì¸ì§€ í™•ì¸
        is_problematic = str(i) in problems # problems keys are strings
        
        if is_problematic:
            # ë¬¸ì œê°€ ìˆëŠ” í™€ë“œëŠ” ë¹¨ê°„ìƒ‰ ë‘êº¼ìš´ í…Œë‘ë¦¬ë¡œ ê°•ì¡°
            cv2.rectangle(display_image, (x1, y1), (x2, y2), (0, 0, 255), 4) # Red, thick
            # í…ìŠ¤íŠ¸ë„ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ
            text_color = (0, 0, 255) 
        else:
            # ì¼ë°˜ í™€ë“œëŠ” í•´ë‹¹ ìƒ‰ìƒ í…Œë‘ë¦¬
            cv2.rectangle(display_image, (x1, y1), (x2, y2), bbox_color, 2)
            text_color = bbox_color
            
        # í™€ë“œ IDì™€ ìƒ‰ìƒ ì´ë¦„ í‘œì‹œ
        text = f"ID:{i} {color_name}"
        cv2.putText(display_image, text, (x1, y1 - 10), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2, cv2.LINE_AA)
            
    return display_image


def export_feedback_dataset(output_path="holdcheck/color_feedback_dataset.json"):
    """í”¼ë“œë°± ë°ì´í„°ë¥¼ í•™ìŠµ ë°ì´í„°ì…‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° (AI ëª¨ë¸ í•™ìŠµìš©)"""
    global _color_feedback_data
    
    if not _color_feedback_data:
        print("âš ï¸ í”¼ë“œë°± ë°ì´í„° ì—†ìŒ")
        return
    
    dataset = {
        "version": "1.0",
        "total_samples": len(_color_feedback_data),
        "samples": _color_feedback_data
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… í”¼ë“œë°± ë°ì´í„°ì…‹ ë‚´ë³´ë‚´ê¸°: {output_path} ({len(_color_feedback_data)}ê°œ ìƒ˜í”Œ)")
