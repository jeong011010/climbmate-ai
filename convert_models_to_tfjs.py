"""
PyTorch YOLO + CLIP ëª¨ë¸ì„ TensorFlow.jsë¡œ ë³€í™˜
"""
import torch
import tensorflow as tf
import tensorflowjs as tfjs
import numpy as np
from ultralytics import YOLO
import clip
import os

def convert_yolo_to_tfjs():
    """YOLO ëª¨ë¸ì„ TensorFlow.jsë¡œ ë³€í™˜"""
    print("ğŸ”„ YOLO ëª¨ë¸ ë³€í™˜ ì‹œì‘...")
    
    try:
        # YOLO ëª¨ë¸ ë¡œë“œ
        yolo_path = "holdcheck/roboflow_weights/weights.pt"
        if not os.path.exists(yolo_path):
            print("âš ï¸  ì»¤ìŠ¤í…€ YOLO ëª¨ë¸ ì—†ìŒ, YOLOv8n ì‚¬ìš©")
            yolo_path = "yolov8n.pt"
        
        model = YOLO(yolo_path)
        
        # TorchScriptë¡œ ë³€í™˜
        print("  â†’ TorchScriptë¡œ ë³€í™˜ ì¤‘...")
        dummy_input = torch.randn(1, 3, 640, 640)
        traced = torch.jit.trace(model.model, dummy_input)
        
        # ONNXë¡œ ë³€í™˜
        print("  â†’ ONNXë¡œ ë³€í™˜ ì¤‘...")
        torch.onnx.export(
            traced,
            dummy_input,
            "models/yolo.onnx",
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        
        # ONNX â†’ TensorFlow
        print("  â†’ TensorFlowë¡œ ë³€í™˜ ì¤‘...")
        os.system("python -m tf2onnx.convert --opset 13 --onnx models/yolo.onnx --output models/yolo_tf")
        
        # TensorFlow â†’ TensorFlow.js
        print("  â†’ TensorFlow.jsë¡œ ë³€í™˜ ì¤‘...")
        os.system("tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model models/yolo_tf frontend/public/models/yolo")
        
        print("âœ… YOLO ëª¨ë¸ ë³€í™˜ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ YOLO ë³€í™˜ ì‹¤íŒ¨: {e}")
        return False

def convert_clip_to_tfjs():
    """CLIP ëª¨ë¸ì„ TensorFlow.jsë¡œ ë³€í™˜"""
    print("ğŸ”„ CLIP ëª¨ë¸ ë³€í™˜ ì‹œì‘...")
    
    try:
        # CLIP ëª¨ë¸ ë¡œë“œ
        print("  â†’ CLIP ëª¨ë¸ ë¡œë”© ì¤‘...")
        device = "cpu"
        model, preprocess = clip.load("ViT-B/32", device=device)
        
        # TorchScriptë¡œ ë³€í™˜
        print("  â†’ TorchScriptë¡œ ë³€í™˜ ì¤‘...")
        dummy_input = torch.randn(1, 3, 224, 224)
        traced = torch.jit.trace(model.visual, dummy_input)
        
        # ONNXë¡œ ë³€í™˜
        print("  â†’ ONNXë¡œ ë³€í™˜ ì¤‘...")
        torch.onnx.export(
            traced,
            dummy_input,
            "models/clip.onnx",
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        
        # ONNX â†’ TensorFlow
        print("  â†’ TensorFlowë¡œ ë³€í™˜ ì¤‘...")
        os.system("python -m tf2onnx.convert --opset 13 --onnx models/clip.onnx --output models/clip_tf")
        
        # TensorFlow â†’ TensorFlow.js
        print("  â†’ TensorFlow.jsë¡œ ë³€í™˜ ì¤‘...")
        os.system("tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model models/clip_tf frontend/public/models/clip")
        
        print("âœ… CLIP ëª¨ë¸ ë³€í™˜ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ CLIP ë³€í™˜ ì‹¤íŒ¨: {e}")
        return False

def create_lightweight_mock_models():
    """ê²½ëŸ‰ ëª¨ì˜ ëª¨ë¸ ìƒì„± (ë³€í™˜ ì‹¤íŒ¨ ì‹œ)"""
    print("ğŸ“¦ ê²½ëŸ‰ ëª¨ì˜ ëª¨ë¸ ìƒì„± ì¤‘...")
    
    os.makedirs("frontend/public/models/yolo", exist_ok=True)
    os.makedirs("frontend/public/models/clip", exist_ok=True)
    
    # ê°„ë‹¨í•œ ë”ë¯¸ ëª¨ë¸ ì •ë³´
    model_info = {
        "format": "tfjs-graph-model",
        "generatedBy": "mock",
        "convertedBy": "ClimbMate",
        "modelTopology": {
            "node": [],
            "library": {},
            "versions": {}
        },
        "weightsManifest": []
    }
    
    import json
    with open("frontend/public/models/yolo/model.json", "w") as f:
        json.dump(model_info, f)
    
    with open("frontend/public/models/clip/model.json", "w") as f:
        json.dump(model_info, f)
    
    print("âœ… ëª¨ì˜ ëª¨ë¸ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    print("=" * 80)
    print("ğŸš€ PyTorch ëª¨ë¸ â†’ TensorFlow.js ë³€í™˜ ì‹œì‘")
    print("=" * 80)
    print()
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("models", exist_ok=True)
    os.makedirs("frontend/public/models", exist_ok=True)
    
    # YOLO ë³€í™˜
    yolo_success = convert_yolo_to_tfjs()
    
    # CLIP ë³€í™˜
    clip_success = convert_clip_to_tfjs()
    
    # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ëª¨ì˜ ëª¨ë¸ ìƒì„±
    if not yolo_success or not clip_success:
        print()
        print("âš ï¸  ëª¨ë¸ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("âš ï¸  ê²½ëŸ‰ ëª¨ì˜ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.")
        create_lightweight_mock_models()
    
    print()
    print("=" * 80)
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("=" * 80)

